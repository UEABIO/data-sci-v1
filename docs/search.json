[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"end book, able :Import data RManipulate wrangle data appropriate format analysisCalculate summaries descriptive statisticsProduce informative data visualisationsProduce reports using R & MarkdownUse GitHub develop version control data reproducibility skillsUse General Generalized Linear Models produce mean estimates, uncertainty intervals statistical tests.","code":""},{"path":"index.html","id":"how-to-use-this-book","chapter":"Overview","heading":"0.1 How to use this book","text":"many chapters, provide code need use. can copy paste book, however, strongly encourage type code . seem much slower make errors, learn much quickly way.Additionally, also provide solutions many activities. -one going check whether tried figure rather going straight solution remember : copy paste without thinking, learn nothing.Finally, occasion make updates book fixing typos including additional detail activities book considered living document. Please tell find mistakes.","code":""},{"path":"index.html","id":"course-structure","chapter":"Overview","heading":"0.2 Course Structure","text":":one lecture per weekone workshop per weekThese timetabled -person sessions, check (Timetabler)[https://timetabler.uea.ac.uk/] -date information scheduling. However, lessons can accessed remotely Collaborate, everything need complete workshops available site.feel unwell, attend session -person need self-isolate don’t worry can access everything, follow along real time, work pace.Questions/issues/errors can posted (Yammer)[https://www.yammer.com/uea.ac.uk/] page.","code":""},{"path":"index.html","id":"workshops","chapter":"Overview","heading":"0.2.1 Workshops","text":"workshops best way learn, teach practical skills need become R wizard.\nFigure 0.1: courtesy Allison Horst\n","code":""},{"path":"index.html","id":"lectures","chapter":"Overview","heading":"0.2.2 Lectures","text":"Lectures recorded, Q&interactions best achieved can attend -person. worries concerns ability attend -person teaching sessions please let know.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"introduction-to-r-and-rstudio","chapter":"1 Introduction to R and RStudio","heading":"1 Introduction to R and RStudio","text":"R name programming language learn course.R name programming language learn course.RStudio convenient interface using throughout course order learn organise data, produce accurate data analyses & data visualisations.RStudio convenient interface using throughout course order learn organise data, produce accurate data analyses & data visualisations.R programming language write code , RStudio Integrated Development Environment (IDE) makes working R easier. Think knowing English using plain text editor like NotePad write book versus using word processor like Microsoft Word. , look good much harder without things like spell-checking formatting. similar way, can use R without R Studio recommend . key thing remember although work using RStudio course, actually using two pieces software means time--time, may separate updates.R RStudio can downloaded free onto personal computers(see Appendices), convenience use classroom space RStudio Cloud.RStudio Cloud cloud-based service can log remotely hosted servers host data analysis projects.advantage using RStudio Cloud extra packages functions need course already installed. can log-workspace computer long internet connection remember username password. can also \"visit\" projects help get stuck, hosted RStudio Cloud.Eventually may also add extra tools like GitHub RMarkdown data reproducibility, literate collaborative programming.end course hope tools confidently analyze real data, make informative beautiful data visuals, able analyze lots different types data.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"using-rstudio-cloud","chapter":"1 Introduction to R and RStudio","heading":"1.1 Using RStudio Cloud","text":"sessions run cloud-based software. make free account, join Workspace.signed - see two spaces:workspace - personal use (20hrs/month)workspace - personal use (20hrs/month)shared classroom - educational licence (limit)shared classroom - educational licence (limit)Make sure working classroom workspace - can distribute project work 'visit' projects needed.RStudio Cloud works exactly way RStudio, means download software. can access hosted cloud server projects browser connection (Chrome works best), computer.good reference guide RStudio Cloud","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"getting-to-know-rstudio","chapter":"1 Introduction to R and RStudio","heading":"1.2 Getting to know RStudio","text":"R Studio console can try code (appearing bottom left window), script editor (top left), window showing functions objects created \"Environment\" tab (top right window figure), window shows plots, files packages, help documentation (bottom right).\nFigure 1.1: RStudio interface\nlearn use features included R Studio throughout course, however, highly recommend watching RStudio Essentials 1 point.video lasts ~30 minutes gives tour main parts R Studio.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"consoles-vs.-scripts","chapter":"1 Introduction to R and RStudio","heading":"1.2.1 Consoles vs. scripts","text":"script window place enter run code easily edited saved future use. Usually Script Window shown top left RStudio. window shown, visible open previously saved R script, create new R Script. create new R Script clicking File > New File > R Script RStudio menu bar.script window place enter run code easily edited saved future use. Usually Script Window shown top left RStudio. window shown, visible open previously saved R script, create new R Script. create new R Script clicking File > New File > R Script RStudio menu bar.execute code R script, can either highlight code click Run, can highlight code press CTRL + Enter keyboard.execute code R script, can either highlight code click Run, can highlight code press CTRL + Enter keyboard.console: can enter code directly Console Window click Enter. commands run shown History Window top right RStudio. Though much difficult keep track work way.console: can enter code directly Console Window click Enter. commands run shown History Window top right RStudio. Though much difficult keep track work way.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"environment","chapter":"1 Introduction to R and RStudio","heading":"1.2.2 Environment","text":"Environment tab (top right) allows see objects workspace. create variables data frames, visual listing everything current workspace. start new project completely empty.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"plots-files-packages-help","chapter":"1 Introduction to R and RStudio","heading":"1.2.3 Plots, files, packages, help","text":"Plots - Plots panel, shows plots. buttons opening plot separate window exporting plot pdf jpeg (though can also code.)Plots - Plots panel, shows plots. buttons opening plot separate window exporting plot pdf jpeg (though can also code.)Files - files panel gives access file directory hard drive.Files - files panel gives access file directory hard drive.Packages - Shows list R packages installed harddrive indicates whether currently loaded. Packages loaded current session checked installed yet loaded unchecked. discuss packages later.Packages - Shows list R packages installed harddrive indicates whether currently loaded. Packages loaded current session checked installed yet loaded unchecked. discuss packages later.Help - Help menu R functions. can either type name function search window, use code search function nameHelp - Help menu R functions. can either type name function search window, use code search function name\nFigure 1.2: RStudio interface labelled\n","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"make-rstudio-your-own","chapter":"1 Introduction to R and RStudio","heading":"1.2.4 Make RStudio your own","text":"can personalise RStudio GUI much like.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"get-help","chapter":"1 Introduction to R and RStudio","heading":"1.3 Get Help!","text":"lot sources information using R . helpful places get help issue, just learn moreThe R help system - type help() put name package function querying inside bracketsThe R help system - type help() put name package function querying inside bracketsVignettes - type browseVignettes() console hit Enter, list available vignettes packages displayedVignettes - type browseVignettes() console hit Enter, list available vignettes packages displayedCheat Sheets - available RStudio.com. common packages associate cheat sheet covering basics use . Download/bookmark ones use commonly ggplot2, data transformation dplyr, Data tidying tidyr & Data import.Cheat Sheets - available RStudio.com. common packages associate cheat sheet covering basics use . Download/bookmark ones use commonly ggplot2, data transformation dplyr, Data tidying tidyr & Data import.Google - use Google constantly, continually forget even basic tasks. want remind round number, might type something like R round number - using particular package include search term wellGoogle - use Google constantly, continually forget even basic tasks. want remind round number, might type something like R round number - using particular package include search term wellAsk help - stuck, getting error message, think next, ask someone. , classmate. important show code, include error message. \"work\" helpful. \"code, data using, want X, problem get.\"Ask help - stuck, getting error message, think next, ask someone. , classmate. important show code, include error message. \"work\" helpful. \"code, data using, want X, problem get.\"\nmay daunting send code someone help.\n\nnatural common feel apprehensive, think code really bad. still feel ! learn share mistakes, eventually find funny look back early mistakes, laugh mistakes still occasionally make!\n","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"get-started","chapter":"1 Introduction to R and RStudio","heading":"1.4 Get Started","text":"Go RStudio Cloud enter Project labelled Day One - clone project provide project workspace.Follow instructions get used R command line, R works language.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"your-first-r-command","chapter":"1 Introduction to R and RStudio","heading":"1.5 Your first R command","text":"RStudio pane, navigate console (bottom left) type copy appear >Hit Enter keyboard.answer get?first line shows request made R, next line R's responseYou type > symbol: just R command prompt part actual command.important understand output formatted. Obviously, correct answer sum 10 + 20 30, surprisingly R printed part response. also printed [1] part, probably make lot sense right now. going see lot. can think [1] 30 R saying \"answer 1st question asked 30\".","code":"\n10 + 20\n30"},{"path":"introduction-to-r-and-rstudio.html","id":"operators","chapter":"1 Introduction to R and RStudio","heading":"1.5.1 Operators","text":"two types operators consider","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"arithmetic-operators","chapter":"1 Introduction to R and RStudio","heading":"1.5.1.1 Arithmetic Operators","text":"","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"logical-operators","chapter":"1 Introduction to R and RStudio","heading":"1.5.1.2 Logical Operators","text":"","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"typos","chapter":"1 Introduction to R and RStudio","heading":"1.5.2 Typos","text":"\ngo talk types calculations can R, things want point . first thing , R good software, still software. pretty stupid, stupid handle typos. takes faith meant type exactly type.\nSuppose forget hit shift key trying type +, result command ended 10 = 20 rather 10 + 20. Try replicate error message:Error 10 = 20 : invalid (do_set) left-hand side assignmentWhat's happened R attempted interpret 10 = 20 command, spits error message command make sense .human looks , looks keyboard sees + = key, pretty obvious command typo. R know , gets upset.Even subtle fact typos produce errors , happen correspond \"well-formed\" R commands. instance, suppose forget hit shift key trying type 10 + 20, also managed press key next one meant . resulting typo produce command 10 - 20. Clearly, R way knowing meant add 20 10, subtract 20 10, happens time :case, R produces right answer, wrong question.","code":"\n10 = 20\n10 - 20## [1] -10"},{"path":"introduction-to-r-and-rstudio.html","id":"more-simple-arithmetic","chapter":"1 Introduction to R and RStudio","heading":"1.5.3 More simple arithmetic","text":"One best ways get know R play , pretty difficult break worry much. Type whatever want console see happens.last line console looks like thisand blinking cursor next plus sign. means R still waiting finish. \"thinks\" still typing command, tried execute yet. words, plus sign actually another command prompt. different usual one (.e., > symbol) remind R going \"add\" whatever type now typed last time. example, type 20 hit enter, finishes command:Alternatively hit escape key, R forget trying return blank line.","code":"> 10+\n+ > 10 +\n+ 20\n[1] 30"},{"path":"introduction-to-r-and-rstudio.html","id":"try-some-simple-maths","chapter":"1 Introduction to R and RStudio","heading":"1.5.4 Try some simple maths","text":"Raise number power anotherAs sure everyone probably remember moment read , act multiplying number \\(x\\) \\(n\\) times called \"raising \\(x\\) \\(n\\)-th power\". Mathematically, written \\(x^n\\). values \\(n\\) special names: particular \\(x^2\\) called \\(x\\)-squared, \\(x^3\\) called \\(x\\)-cubed. , 4th power 5 calculated like :\\[5^4 = 5 \\times 5 \\times 5 \\times 5 \\]","code":"\n1+7\n13-10\n4*6\n12/3\n5^4"},{"path":"introduction-to-r-and-rstudio.html","id":"perform-some-combos","chapter":"1 Introduction to R and RStudio","heading":"1.5.5 Perform some combos","text":"Perform mathematical combos, noting order R performs calculations standard one., first calculate things inside Brackets (), calculate Orders (exponents) ^, Division / Multiplication *, Addition + Subtraction -.Notice different outputs two commands.Similarly want raise number fraction, need surround fraction parentheses ()first one calculates 16 raised power 1, divided answer two. second one raises 16 power half. big difference output.\ncursor console, can press arrow see previous commands.\n\ncan run , edit . Later look scripts, essential way re-use, store edit commands.\n","code":"\n3^2-5/2\n(3^2-5)/2\n16^1/2\n16^(1/2)"},{"path":"introduction-to-r-and-rstudio.html","id":"true-or-false-data","chapter":"1 Introduction to R and RStudio","heading":"1.6 \"TRUE or FALSE\" data","text":"Time make sidebar onto another kind data. Many concepts programming rely idea logical value. logical value assertion whether something true false. implemented R pretty straightforward way. two logical values, namely TRUE FALSE. Despite simplicity, logical values useful things. see work.","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"assessing-mathematical-truths","chapter":"1 Introduction to R and RStudio","heading":"1.6.1 Assessing mathematical truths","text":"George Orwell's classic book 1984, one slogans used totalitarian Party \"two plus two equals five\", idea political domination human freedom becomes complete possible subvert even basic truths.R!R subverted. rather firm opinions topic true, least regards basic mathematics. ask calculate 2 + 2, always gives answer, 5:course, far R just calculations. asked explicitly assert \\(2+2 = 4\\) true statement. want R make explicit judgement, can use command like :TRUEWhat done use equality operator, ==, force R make \"true false\" judgement.\ndifferent operator assignment operator = saw previously.\n\ncommon typo people make trying write logical commands R (languages, since \"= versus ==\" distinction important programming languages) accidentally type = really mean ==.\nOkay, see R thinks Party slogan:Take Big Brother! Anyway, worth look happens try force R believe two plus two five making assignment statement like 2 + 2 = 5 2 + 2 <- 5. , happens:R like much. recognises 2 + 2 variable (\"non-language object\" part saying), let try \"reassign\" . R pretty flexible, actually let quite remarkable things redefine parts R , just basic, primitive truths refuses give . change laws addition, change definition number 2.probably best.","code":"\n2 + 2## [1] 4\n2 + 2 == 4\n2+2 == 5## [1] FALSE\n2 + 2 = 5Error in 2 + 2 = 5 : target of assignment expands to non-language object"},{"path":"introduction-to-r-and-rstudio.html","id":"storing-outputs","chapter":"1 Introduction to R and RStudio","heading":"1.7 Storing outputs","text":"simple questions like ones happy just see answer, questions often complex . need take multiple steps, benefit able store answers recall use later steps. simple can assign outputs name:literally means please assign value 1+2 name . use assignment operator <- make assignment.\nNote shortcut key <- Alt + - (Windows) Option + - (Mac)\nperform action able two thingsYou able see top right-hand pane Environment tab now object called value 3.\nFigure 1.3: object now visible withe value 3 Environment Pane\nable look typing Console pressing EnterYou able look typing Console pressing EnterNote see outcome functions type object R console hit EnterNote see outcome functions type object R console hit EnterYou can now call object time R session perform calculations .happens assign value named object already exists R environment??? exampleThe value now 10.see previous assignment lost, gone forever replaced new value.can assign lots things objects, use calculations build objects.\nRemember: now change value b, value c change.\n\nObjects totally independent made.\n\nOverwriting objects new values means old value lost.\nvalue c?[1] 15When c created product b values 10 15 respectively.\nre-ran command c <- + b changing value b get value 17.Look environment tab - see starting fill now!\nRStudio default save objects memory close session.\n\nnext time logon. might seem nice able close things pick left , actually quite dangerous. messy, can cause lots problems work scripts later, !\n\nstop RStudio saving objects default go Tools > Project Options option change \"Save workspace .RData exit\" \"\" \"Never\".\n\nInstead going learn use scripts quickly re-run analyses working .\n","code":"\na <- 1+2\na\n3\n2 * a\n6\na <- 10\na\nb <- 5\nc <- a + b\nb <- 7\nb\nc"},{"path":"introduction-to-r-and-rstudio.html","id":"choosing-names","chapter":"1 Introduction to R and RStudio","heading":"1.7.1 Choosing names","text":"Use informative variable names. general rule, using meaningful names like orange apple preferred arbitrary ones like variable1 variable2. Otherwise hard remember contents different variables actually .Use informative variable names. general rule, using meaningful names like orange apple preferred arbitrary ones like variable1 variable2. Otherwise hard remember contents different variables actually .Use short variable names. Typing pain -one likes . much prefer use name like apple name like pink_lady_apple.Use short variable names. Typing pain -one likes . much prefer use name like apple name like pink_lady_apple.Use one conventional naming styles multi-word variable names. R lets use certain things legal names. Legal names must start letter number, can followed sequence letters, numbers, ., _. R like using spaces. Upper lower case names allowed, R case sensitive Apple apple different.Use one conventional naming styles multi-word variable names. R lets use certain things legal names. Legal names must start letter number, can followed sequence letters, numbers, ., _. R like using spaces. Upper lower case names allowed, R case sensitive Apple apple different.favourite naming convention snake_case short, lower case , spaces words separated _. easy read easy remember.favourite naming convention snake_case short, lower case , spaces words separated _. easy read easy remember.\nFigure 1.4: courtesy Allison Horst\n","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"error","chapter":"1 Introduction to R and RStudio","heading":"1.8 Error","text":"Things go wrong eventually, always ...R pedantic, even smallest typo can result failure typos impossilbe avoid. make mistakes. One type mistake make error. code fails run. common causes error :typostyposmissing commasmissing commasmissing bracketsmissing bracketsThere's nothing wrong making lots errors. trick panic get frustrated, read error message script carefully start debug...... sometimes need walk away come back later!\nTry typing command help() R console, open new tab bottom right.\n\nPut function package brackets get help specific topic\n\nFigure 1.5: courtesy Allison Horst\n","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"functions","chapter":"1 Introduction to R and RStudio","heading":"1.9 Functions","text":"Functions tools R. one helps us different task.Take example function use round number certain number digits - function called roundHere's example:start command function name round. name followed parentheses (). Within place arguments function, separated comma.arguments:x = 2.4326782647 (number like round)x = 2.4326782647 (number like round)digits = 2 (number decimal places like round )digits = 2 (number decimal places like round )Arguments inputs give function. arguments form name = value name specifies argument, value providing define input. first argument x number like round, value 2.4326782647. second argument digits like number rounded specify 2. limit many arguments function .\nCopy paste following code console.\nhelp documentation round()appear bottom right help panel. usage section, see round()takes following form:arguments section, explanations arguments. xis number vector wish round values. digits number decimal places used. description can see value supplied digits default 0 whole number rounding.Read 'Details' section find happens rounding last digit 5.try example just change required argument digits\nCopy paste following code console.\nNow can change additional arguments produce different set numbers.time R still rounded number, done set number 'decimal places'.Always remember use help documentation help understand arguments function requires.","code":"\nround(x  = 2.4326782647, digits = 2)\nhelp(round)\nround(x, digits = 0)\nround(x  = 2.4326782647)## [1] 2\nround(x  = 2.4326782647, digits = 2)## [1] 2.43"},{"path":"introduction-to-r-and-rstudio.html","id":"storing-the-output-of-functions","chapter":"1 Introduction to R and RStudio","heading":"1.9.1 Storing the output of functions","text":"need answer function later calculation. answer use assignment operator <-.example assign values two R objects can call inside R function though putting numbers directly.\nCopy paste following code console.\nvalue assigned R object rounded_number ?[1] 2.433","code":"\nnumber_of_digits <- 3\n\nmy_number <- 2.4326782647\n\nrounded_number <- round(x  = my_number, \n                        digits = number_of_digits)"},{"path":"introduction-to-r-and-rstudio.html","id":"more-fun-with-functions","chapter":"1 Introduction to R and RStudio","heading":"1.9.2 More fun with functions","text":"Copy paste :Looks like even give names arguments function still work. works function round expects us give number value first, argument rounding digits second. assumes know expected ordering within function, might case functions use lot. give arguments proper names can actually introduce order want.Try :gives different answer\nRemember naming arguments overrides position defaults\nknow argument orders defaults? Well get know lot functions work practice, can also use help() .","code":"\nround(2.4326782647, 2)\nround(digits = 2, x  = 2.4326782647)\nround(2, 2.4326782647)"},{"path":"introduction-to-r-and-rstudio.html","id":"packages","chapter":"1 Introduction to R and RStudio","heading":"1.10 Packages","text":"install R access range functions including options data wrangling statistical analysis. functions included default installation typically referred Base R useful cheat sheet shows many Base R functions hereHowever, power R extendable open source - anyone can create new package extends functions R.R package container various things including functions data. make easy complicated protocols using custom-built functions. Later see can write simple functions. Packages lot like new apps extending functionality phone can .RStudio Cloud already installed several add-packages, need use simple function library() load packages workspace. complete access custom functions contain.\nCopy paste following code console.\nggplot2 - one popular packages use R. \"grammar graphics\" packages dedicated making data visualisations, contains lots dedicated functions .ggplot2 - one popular packages use R. \"grammar graphics\" packages dedicated making data visualisations, contains lots dedicated functions .palmerpenguins - good example data-heavy package, contains functions, instead datasets can use.palmerpenguins - good example data-heavy package, contains functions, instead datasets can use.\ncommon source errors call function part package forgetting load package.\n\nR says something like \"Error \"function-name\": find X\" likely function misspelled package containing function loaded.\n","code":"\nlibrary(ggplot2)\nlibrary(palmerpenguins)"},{"path":"introduction-to-r-and-rstudio.html","id":"my-first-data-visualisation","chapter":"1 Introduction to R and RStudio","heading":"1.11 My first data visualisation","text":"run first data visualisation using functions data now loaded - produces plot using functions ggplot2 package data palmerpenguins package.Data visualisation core part data science, generating insights data - spend lot time course working data visualisations.Today use simple functions produce figure. specify data source, variables used x y axis type visual object produce, colouring species.\nCopy paste following code console.\n\nmay noticed R gave warning. big scary error, R wants aware something.\n\ncase two observations missing data (either bill length bill depth), plotted.\n\ngood thing take note warnings errors - provide useful information.\ncommand can also written , longer style new line argument function. style can easier read, makes easier write comments #. Copy longer command console hit Enter.Note R ignores anything comes # line code - means can add notes work.","code":"\nggplot(data = penguins,aes(x = bill_length_mm, y = bill_depth_mm)) + geom_point(aes(colour=species)) \nggplot(data = penguins, # calls ggplot function, data is penguins\n       aes(x = bill_length_mm, # sets x axis as bill length\n           y = bill_depth_mm)) + # sets y axis value as bill depth\n    geom_point(aes(colour=species)) # plot points coloured by penguin species"},{"path":"introduction-to-r-and-rstudio.html","id":"writing-scripts","chapter":"1 Introduction to R and RStudio","heading":"1.12 Writing scripts","text":"now typing words directly Console. fine short/simple calculations - soon complex, multi-step process becomes time consuming, error-prone boring. Scripts document containing commands (order want run), repeatable, shareable, annotated records done. short incredibly useful - big step towards open reproducible research.\nFigure 1.6: RStudio interface - top left script, botto left console\nopen pane top-left RStudio tab name Untitled1.\nscript way organising R commands, sequence, produce desired output.\n\nwrite script, nothing happens tell RUN, see commands appearing console.\n\nMake sure include commands need complete analysis, correct order.\n","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"organising-scripts","chapter":"1 Introduction to R and RStudio","heading":"1.12.1 Organising scripts","text":"Scripts work best well organised - well documented. Simple tricks consistent organisation can make work easier read reproduced others.bookmark Tidyverse Style Guide, opinionated way organising scripts code consistent style, maximises readability. Later course use benchmark assessing code writing.Annotating instructions provides others insights . vital aspect robust reproducible workflow. come back script, one week, one month one year now often wonder command . , useful make notes , useful case anyone else ever read script. Make comments helpful humans read.already seen signal comment # key. Everything line # ignored R treated command. also see marked different colour script.\nPut following comment script line 1.\ncan also use # produce Headers different levels, follow commented lines - = shown figure .\n(#fig:script outline)R script document outline. Push button five horizontal lines reveal R recognises headers subheaders\n","code":"\n# I really love R"},{"path":"introduction-to-r-and-rstudio.html","id":"loading-packages","chapter":"1 Introduction to R and RStudio","heading":"1.12.2 Loading packages","text":"use functions package script must loaded call functions data contain. sensible place put library calls packages top script. now,\nAdd commandslibrary(ggplot2) library(palmerpenguins) script.\n\nThink organise script using image guide\n\nPut comment next package explaining \"Hint use help() function\".\n\nUse document outline button help organise script.\n\nR Studio interpret Unicode present images can include scripts. necessary, fun way help organise scripts.\n","code":"\n# I really love R\n# _______________----\n\n# <U+0001F4E6> PACKAGES ----NAlibrary(ggplot2) # create elegant data visualisations\nlibrary(palmerpenguins) # Palmer Archipelago Penguin Data\n\n# ______________----"},{"path":"introduction-to-r-and-rstudio.html","id":"adding-more-code","chapter":"1 Introduction to R and RStudio","heading":"1.12.3 Adding more code","text":"\nAdd code script, underneath sections already \nsimilar code ran earlier, preceded plot_1 <-","code":"\n# DATA VISUAL ----\n\nplot_1 <- ggplot(data = penguins, # calls ggplot function, data is penguins\n           aes(x = bill_length_mm, # sets x axis as bill length\n               y = bill_depth_mm)) + # sets y axis value as bill depth\n          geom_point(aes(colour=species)) # geometric to plot\n\n# ______________----"},{"path":"introduction-to-r-and-rstudio.html","id":"running-your-script","chapter":"1 Introduction to R and RStudio","heading":"1.12.4 Running your script","text":"run commands script, need get Console. select copy/paste Console. couple faster shortcuts.Hit Run button top right script pane. Pressing run line code cursor sitting .Hit Run button top right script pane. Pressing run line code cursor sitting .Pressing Ctrl+Enter thing hitting Run buttonPressing Ctrl+Enter thing hitting Run buttonIf want run whole script one go press Ctrl+either click Run press Ctrl+EnterIf want run whole script one go press Ctrl+either click Run press Ctrl+EnterTry now.notice unlike making previous data visuals, immediately see graph, assigned output functions R object, instead default action R print output. Check \"Environment\" tab - able see plot_1 .see new plot made type plot_1 R console. add underneath script run !","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"making-an-output","chapter":"1 Introduction to R and RStudio","heading":"1.12.5 Making an output","text":"next trick make script outputs file. Underneath lines code generate figure add new function ggsave(). re-run script. find function (arguments contains), type help(ggsave) console.Check Files tab RStudio Cloud, now new file workspace called \"2022_10_01_5023Y_workshop_1_penguin_scatterplot.png\".Wow mouthful! made long filename? Well contains information help know future.DateDateModule codeModule codeShort description file contentsShort description file contents\nimportant naming conventions files.\n\nEverything . file extension information informing computer process contents file. .png stands \"Portable Graphics Format”, means data uncompressed image format.\n\nEverything . humans, good idea make sure naming convention.\n\nAvoid periods, spaces slashes, instead use YYYYMMDD underscores\n\ne.g. YYYYMMDD_short_image_description.fileextension\n","code":"\n# OUTPUT TO FILE ----\n\nggsave(filename = \"2022_10_01_5023Y_workshop_1_penguin_scatterplot.png\", \n       plot = plot_1, \n       dpi = 300, \n       width = 6, \n       height = 6)\n# _________________----"},{"path":"introduction-to-r-and-rstudio.html","id":"saving-your-script","chapter":"1 Introduction to R and RStudio","heading":"1.12.6 Saving your script","text":"script now contains code comments first workshop. need save .Alongside data, script precious part analysis. need save anything else, outputs etc. script can always used generate everything . Note colour script - name changes colour unsaved changes. Press Save button go File > Save . Give File sensible name like \"YYYYMMDD_5023Y_workshop_1_simple_commands\" bottom right pane Files now able see saved script, saved .R file extension indicating R Script.now safely quit R, log next time project, script waiting .","code":"\n# I really love R\n# _______________----\n\n# <U+0001F4E6> PACKAGES ----NAlibrary(ggplot2) # create elegant data visualisations\nlibrary(palmerpenguins) # Palmer Archipelago Penguin Data\n\n# ________________----\n# DATA VISUAL ----\n\nplot_1 <- ggplot(data = penguins, # calls ggplot function, data is penguins\n           aes(x = bill_length_mm, # sets x axis as bill length\n               y = bill_depth_mm)) + # sets y axis value as bill depth\n          geom_point(aes(colour=species)) # geometric to plot\n\n# ______________----\n\n# OUTPUT TO FILE ----\n\nggsave(filename = \"2022_10_01_5023Y_workshop_1_penguin_scatterplot.png\", \n       plot = plot_1, \n       dpi = 300, \n       width = 6, \n       height = 6)\n# _________________----"},{"path":"introduction-to-r-and-rstudio.html","id":"quitting","chapter":"1 Introduction to R and RStudio","heading":"1.13 Quitting","text":"Make sure saved changes R script - need make sure done!Make sure saved changes R script - need make sure done!want take look script let knowIf want take look script let knowIf spotted mistakes errors let knowIf spotted mistakes errors let knowClose RStudio Cloud BrowserClose RStudio Cloud BrowserComplete week's short quiz!Complete week's short quiz!","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"activity-1","chapter":"1 Introduction to R and RStudio","heading":"1.14 Activity 1","text":"","code":""},{"path":"introduction-to-r-and-rstudio.html","id":"complete-this-quiz","chapter":"1 Introduction to R and RStudio","heading":"1.14.1 Complete this Quiz","text":"get correct answer, answer box turn green. Sometimes work Internet Explorer Edge sure use Chrome Firefox.Question 1. output 5^4Question 2. answer get type 2+2 = 4 R console?TRUEFALSEErrorIf wanted R make judgement must use == = otherwise get Error messageQuestion 3. symbol use want assign value output function R objectQuestion 4. value ran following commands?Question 5. variable naming conventions written correctly?snake_casecamelCaseScreaming_Snake_Casekebab-caseQuestion 6. type R console want help round() function?Question 7. statements function arguments trueArguments inputs give functionValues R arguments must always defined userNaming arguments supersedes position functionThere limit number arguments function haveQuestion 8. Evaluate statement \"R Package can contain code functions, data, .\"TRUEFALSE","code":"\na <-  12*2\n\na <- 5"},{"path":"r-basics.html","id":"r-basics","chapter":"2 R Basics","heading":"2 R Basics","text":"load packages use function library(). Typically start analysis script loading packages need.tidyverse opinionated collection R packages designed data science. packages share underlying design philosophy, grammar, data structures. means functions across tidyverse designed work together make process data science easier.","code":""},{"path":"r-basics.html","id":"using-packages","chapter":"2 R Basics","heading":"2.1 Using packages","text":"Run code load tidyverse package. can regardless whether using computer cloud.get looks like error message - . just R telling done. read gives full list packages made available . One look familiar last week?ggplot2tibbletidyrdplyrNow loaded tidyverse package can use functions contains remember, need run library() function every time start R.order use package, must first install . following code installs package tidyverse, package use frequently.working computer, use code install tidyverse.need install package , however, time start R need load packages want use, similar way need install app phone , need open every time want use .\nget error message says something like \"WARNING: Rtools required build R packages\" may need download install extra bit software called Rtools.\n","code":"\nlibrary(tidyverse)\ninstall.packages(\"tidyverse\")"},{"path":"r-basics.html","id":"package-updates","chapter":"2 R Basics","heading":"2.2 Package updates","text":"addition updates R R Studio, creators packages also sometimes update code. can add functions package, can fix errors. One thing avoid unintentionally updating installed package. run install.packages() always install latest version package overwrite older versions may installed. Sometimes problem, however, sometimes find update means code longer works package changed substantially. possible revert back older version package try avoid anyway.\navoid accidentally overwriting package later version, never include install.packages() analysis scripts case , someone else runs code mistake. Remember, server already packages need course need install packages using machine.\n","code":""},{"path":"r-basics.html","id":"package-conflicts","chapter":"2 R Basics","heading":"2.3 Package conflicts","text":"thousands different R packages even functions. Unfortunately, sometimes different packages function names. example, packages dplyr MASS function named select(). load packages, R produce warning telling conflict.case, R telling function select() dplyr package hidden ('masked') another function name. try use select(), R use function package loaded recently - case use function MASS.want specify package want use particular function can use code format package::function, example:\nget naming conflicts?\n\nR open source software. Anyone can write submit useful R packages. result impossible make sure NEVER functions identical names.\n","code":"\nlibrary(dplyr)\nlibrary(MASS)package �dplyr� was built under R version 3.6.3\nAttaching package: �dplyr�\n\nThe following objects are masked from �package:stats�:\n\n    filter, lag\n\nThe following objects are masked from �package:base�:\n\n    intersect, setdiff, setequal, union\n\n\nAttaching package: �MASS�\n\nThe following object is masked from �package:dplyr�:\n\n    select\ndplyr::select()\nMASS::select()"},{"path":"r-basics.html","id":"objects","chapter":"2 R Basics","heading":"2.4 Objects","text":"large part coding involve creating manipulating objects. Objects contain stuff, made first R objects previous chapter. values contained object can numbers, words, result operations analyses.assign content object using <-.","code":""},{"path":"r-basics.html","id":"activity-1-create-some-objects","chapter":"2 R Basics","heading":"2.4.1 Activity 1: Create some objects","text":"Copy paste following code console, change code uses name age run . see name, age, today, new_year, data appear environment pane.command use need help understand function rnorm()?`\nFigure 2.1: Objects environment\nNote examples, name,age, new_year always contain values emily, 35, date New Year's Day 2021, however, today draw date operating system data randomly generated set data values objects static.side note, ever teach programming statistics, use age example every time update teaching materials get reminder fragility existence advancing age. 2021 update: now given updating age, remain forever 35.Importantly, objects can involved calculations can interact . example:Finally, can store result operations new object:\nmay find helpful read <- contains, e.g., name contains text emily.\nconstantly creating objects throughout course learn behave go along, however, now enough understand way saving values, values can numbers, text, result operations, can used operations create new variables.\nmay also see objects referred 'variables'. difference two programming terms, however, used synonymously frequently.\n","code":"\nname <- \"emily\"\nage <- 16 + 19 \ntoday <- Sys.Date()\nnew_year <- as.Date(\"2022-01-01\")\ndata <- rnorm(n = 10, mean = 15, sd = 3)\nage + 10\nnew_year - today\nmean(data)## [1] 45\n## Time difference of -216 days\n## [1] 16.63193\ndecade <- age + 10"},{"path":"r-basics.html","id":"vectors","chapter":"2 R Basics","heading":"2.5 Vectors","text":"working R objects containing single element data, commonly work vectors. vector sequence elements, data type. logical, numerical, character etc.function c lets 'concatenate' link separate elements together single vector.","code":"\nnumeric_vector <- c(1,2,3)\n\ncharacter_vector <- c(\"fruits\", \"vegetables\", \"seeds\")\n\nlogical_vector <- c(TRUE, TRUE, FALSE)"},{"path":"r-basics.html","id":"dataframes-and-tibbles","chapter":"2 R Basics","heading":"2.6 Dataframes and tibbles","text":"looked R objects contain:single elements datasingle elements datamultiple elements data type - vectorsmultiple elements data type - vectorsBut often import data R put object called tibble type dataframe.\ndataframe data structure organises data table. Dataframes can mix different types data . column dataframe different vector, row different element within vectors.\nquick go making tibble scratch.\nUse str() object vector find important information, like data type vector many elements contains.\nNow put vectors together, become variables new tibble using function tibble()go messing script figure functions .","code":"\n# make some variables/ vectors\nperson <- c(\"Mark\", \"Phil\", \"Becky\", \"Tony\")\n\nhobby <- c(\"kickboxing\", \"coding\", \"dog walking\", \"car boot sales\")\n\nawesomeness <- c(1,100,1,1)\n# make a tibble\nmy_data <- tibble(person, hobby, awesomeness)\nmy_data# A tibble: 4 x 3\n  person hobby          awesomeness\n  <chr>  <chr>                <dbl>\n1 Mark   kickboxing               1\n2 Phil   coding                 100\n3 Becky  dog walking              1\n4 Tony   car boot sales           1\n# Some R functions for looking at tibbles and dataframes\n\nhead(my_data, n=2)\ntail(my_data, n=1)\nnrow(my_data)\nncol(my_data)\ncolnames(my_data)\nview(my_data)\nglimpse(my_data)\nstr(my_data)"},{"path":"r-basics.html","id":"organising-data-in-wide-and-long-formats","chapter":"2 R Basics","heading":"2.7 Organising data in wide and long formats","text":"two main conventions dataframes R, wide long formats.wide data format repeat values first column, data relating \"measured thing\" found different columnsA wide data format repeat values first column, data relating \"measured thing\" found different columnsA long data format different column type thing measures data. variable unique column.long data format different column type thing measures data. variable unique column.\nFigure 2.2: visual representation long wide format data shapes\nneither wide long data correct , work long data clearer many distinct types variables data tools using tidyverse designed work long data.","code":""},{"path":"r-basics.html","id":"using-pivot-functions","chapter":"2 R Basics","heading":"2.8 Using pivot functions","text":"functions found part tidyverse can help us reshape data.tidyr::pivot_wider() - long wide formattidyr::pivot_wider() - long wide formattidyr::pivot_longer() - wide long formattidyr::pivot_longer() - wide long format\nFigure 2.3: Reshaping data pivot\nsave changes data format, must assign object, two optionsUse name original R object, overwrite original new formatUse name original R object, overwrite original new formatUse new name reformatted data R objects exist EnvironmentUse new name reformatted data R objects exist EnvironmentNeither correct aware .","code":"\n country <- c(\"x\", \"y\", \"z\")\n yr1960 <-  c(10, 20, 30)\n yr1970 <-  c(13, 23, 33)\n yr2010 <-  c(15, 25, 35)\n\ncountry_data <- tibble(country, yr1960, yr1970, yr2010)\ncountry_data\npivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")"},{"path":"r-basics.html","id":"overwrite-the-original-object","chapter":"2 R Basics","heading":"2.8.1 Overwrite the original object","text":"","code":"\ncountry_data <- pivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")"},{"path":"r-basics.html","id":"create-a-new-r-object","chapter":"2 R Basics","heading":"2.8.2 Create a new r object","text":"","code":"\nlong_country_data <- pivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")"},{"path":"r-basics.html","id":"looking-after-the-environment","chapter":"2 R Basics","heading":"2.9 Looking after the environment","text":"writing lot code may find environment pane (workspace) become cluttered many objects. can make difficult figure object need therefore run risk using wrong data frame. working new dataset, tried lots different code getting final version, good practice remember clear environment avoid using wrong object. can several way.remove individual objects, can type rm(object_name) console. Try now remove one objects created previous section.clear objects environment run rm(list = ls()) console.clear objects environment can also click broom icon environment pane.\nFigure 2.4: Clearing workspace\n","code":""},{"path":"r-basics.html","id":"global-options","chapter":"2 R Basics","heading":"2.10 Global options","text":"default, open R Studio show last working , including code objects created. might sound helpful, actually tends cause problems worth means risk accidentally using old version object. recommend changing settings time start R Studio, opens fresh copy. can clicking Tools - Global Options deselecting boxes looks like .\nFigure 2.5: Set options increase reproducibility\n\nRestore .RData workspace startup r mcq(c(\"checked\", answer = \"unchecked\"))\n\nSave workspace .RData exit r mcq(c(\"Always\", answer = \"Never\", \"Ask))\n","code":""},{"path":"r-basics.html","id":"r-sessions","chapter":"2 R Basics","heading":"2.11 R sessions","text":"open R start writing code, loading packages, creating objects, new session. addition clearing workspace, can sometimes useful start new session. happen automatically time start R computer, although sessions can persist cloud. find code working figure , might worth starting new session. clear environment detach loaded packages - think like restarting phone.","code":""},{"path":"r-basics.html","id":"activity-2","chapter":"2 R Basics","heading":"2.12 Activity 2","text":"Click 'Session - Restart R'.tried turning ? vital restart R regularly. Restarting R helps avoid accidentally using wrong data functions stored environment. Restarting R takes second several times per day! get used saving everything script, ’ll always happy restart R. help develop robust reproducible data analysis skills.\nFigure 2.6: truth programming\n\nmean can’t shouldn’t ever save work .RData/.rda files.\n\nbest consciously load exactly want load. Letting R silently save load everything may also include broken data objects.\n","code":""},{"path":"r-basics.html","id":"how-to-cite-r-and-rstudio","chapter":"2 R Basics","heading":"2.13 How to cite R and RStudio","text":"may way writing scientific report cite reference R, however, time comes important people built (free!) credit. provide separate citations R, RStudio, packages use.get citation version R using, simply run citation() function always provide recent citation.generate citation packages using, can also use citation() function name package wish cite.generate citation version RStudio using, can use RStudio.Version() function:Finally, example might look write-method section:Analysis conducted using R ver 4.0.0 (R Core Team, 2020), RStudio (Rstudio Team, 2020), tidyverse range packages (Wickham, 2017).noted, may , come back important give open-source community credit work.","code":"\ncitation()## \n## To cite R in publications use:\n## \n##   R Core Team (2019). R: A language and environment for statistical\n##   computing. R Foundation for Statistical Computing, Vienna, Austria.\n##   URL https://www.R-project.org/.\n## \n## A BibTeX entry for LaTeX users is\n## \n##   @Manual{,\n##     title = {R: A Language and Environment for Statistical Computing},\n##     author = {{R Core Team}},\n##     organization = {R Foundation for Statistical Computing},\n##     address = {Vienna, Austria},\n##     year = {2019},\n##     url = {https://www.R-project.org/},\n##   }\n## \n## We have invested a lot of time and effort in creating R, please cite it\n## when using it for data analysis. See also 'citation(\"pkgname\")' for\n## citing R packages.\ncitation(\"tidyverse\")## \n##   Wickham et al., (2019). Welcome to the tidyverse. Journal of Open\n##   Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686\n## \n## A BibTeX entry for LaTeX users is\n## \n##   @Article{,\n##     title = {Welcome to the {tidyverse}},\n##     author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n##     year = {2019},\n##     journal = {Journal of Open Source Software},\n##     volume = {4},\n##     number = {43},\n##     pages = {1686},\n##     doi = {10.21105/joss.01686},\n##   }\nRStudio.Version()"},{"path":"r-basics.html","id":"help-and-additional-resources","chapter":"2 R Basics","heading":"2.14 Help and additional resources","text":"\nFigure 2.7: truth programming\nGetting good programming really means getting good trying stuff , searching help online, finding examples code copy. difficulty exercises contained book can ask help Teams, however, learning problem-solve effectively key skill need develop throughout course.Use help documentation. struggling understand function works, remember ?function help() command.get error message, copy paste Google - likely someone else problem.Rememver ask help course Yammer pageIn addition course materials number excellent resources learning R:\nR Cookbook\nStackOverflow\nR Data Science\nSearch use #rstats hashtag Twitter\nR CookbookStackOverflowR Data ScienceSearch use #rstats hashtag Twitter","code":""},{"path":"r-basics.html","id":"debugging-tips","chapter":"2 R Basics","heading":"2.15 Debugging tips","text":"large part coding trying figure code work true whether novice expert. progress course keep record mistakes make fixed . chapter provide number common mistakes look undoubtedly make (fix!) new mistakes .loaded correct packages functions trying use? One common mistake write code load package, e.g., library(tidyverse) forget run .made typo? Remember data DATA t.test t_test.package conflict? tried specifying package function package::function?definitely error? red text R means error - sometimes just giving message information.","code":""},{"path":"r-basics.html","id":"activity-7-test-yourself","chapter":"2 R Basics","heading":"2.16 Activity 7: Test yourself","text":"Question 1. never include code install.packages() analysis scripts? use library() insteadPackages already part Base RYou (someone else) may accidentally install package update stops code workingYou already latest version packageRemember, run install.packages() always install latest version package overwrite older versions package may installed.Question 2. following code produce?dataset 10 numbers mean 6 SD 50A dataset 6 numbers mean 50 SD 10A dataset 50 numbers mean 10 SD 6A dataset 50 numbers mean 10 SD 6The default form rnorm() rnorm(n, mean, sd). need help remembering argument function , look help documentation running ?rnormQuestion 3. two packages functions name want specify exactly package use, code use?package::functionfunction::packagelibrary(package)install.packages(package)use form package::function, example dplyr::select. Remember first load packages R warn functions name - remember look !Question 4. following likely argument? read_csv()35<-Question 5. easy way spot functions look computersbracketsnumbers.Question 6. job <- send output function /objectassignmentargument.Question 7. vector must always contain elements data type (e.g logical, character, numeric) FALSETRUE.Question 8. dataframe/tibble must always contain elements data type FALSETRUE","code":"\nrnorm(6, 50, 10)"},{"path":"loading-data.html","id":"loading-data","chapter":"3 Loading data","heading":"3 Loading data","text":"workshop work loading data. curated cleaned dataset can work generating insights data.biologist used asking questions gathering data. also important learn aspects research process. includes responsible data management (understanding data files & spreadsheet organisation, keeping data safe) data analysis.chapter look structure data files, read R. also continue develop reproducible scripts. means writing scripts well organised easy read, also making sure scripts complete capable reproducing analysis start finish.Transparency reproducibility key values scientific research, analyse data reproducible way means others can understand check work. also means important person can benefit work, ! return analysis even short break, thanking earlier self worked clear reproducible way, can pick right left .","code":""},{"path":"loading-data.html","id":"meet-the-penguins","chapter":"3 Loading data","heading":"3.1 Meet the Penguins","text":"data, taken palmerpenguins (Horst et al. (2020)) package originally published Gorman et al. (2014). course work real data shared researchers.palmer penguins data contains size measurements, clutch observations, blood isotope ratios three penguin species observed three islands Palmer Archipelago, Antarctica study period three years.data collected 2007 - 2009 Dr. Kristen Gorman Palmer Station Long Term Ecological Research Program, part US Long Term Ecological Research Network. data imported directly Environmental Data Initiative (EDI) Data Portal, available use CC0 license (“Rights Reserved”) accordance Palmer Station Data Policy. gratefully acknowledge Palmer Station LTER US LTER Network. Special thanks Marty Downs (Director, LTER Network Office) help regarding data license & use. intrepid package co-author, Dr. Gorman, action collecting penguin data:map study site","code":""},{"path":"loading-data.html","id":"activity-1-organising-our-workspace","chapter":"3 Loading data","heading":"3.2 Activity 1: Organising our workspace","text":"can begin working data, need set-.Go RStudio Cloud open Penguins R projectGo RStudio Cloud open Penguins R projectCreate following folders using + New Folder button Files tab\ndata\noutputs\nscripts\nCreate following folders using + New Folder button Files tabdataoutputsscripts\nR case-sensitive type everything EXACTLY printed \nseparate subfolders within project helps keep things tidy, means harder lose things, lets easily tell R exactly go retrieve data.next step workflow well organised project space. RStudio Cloud lot hard work , new data project can set Project space.define project series linked questions uses one (sometimes several) datasets. example coursework assignment particular module project, series linked experiments particular research project might project.Project contain several files, possibly organised sub-folders containing data, R scripts final outputs. might want keep information (wider reading) gathered relevant project.\nFigure 3.1: example typical R project set-\nWithin project notice already one file .Rproj. R project file, useful feature, interacts R tell working specific place computer (case cloud server dialed ). means R automatically treat location project file 'working directory' makes importing exporting easier1.\nimportant NEVER move .Rproj file, may prevent workspace opening properly.\n","code":""},{"path":"loading-data.html","id":"activity-2-access-our-data","chapter":"3 Loading data","heading":"3.3 Activity 2: Access our data","text":"Now project workspace, ready import data.Use link open page browser data openUse link open page browser data openRight-click Save download csv format computer (Make note file downloaded e.g. Downloads)Right-click Save download csv format computer (Make note file downloaded e.g. Downloads)Compare data looks \"raw\" format open data ExcelCompare data looks \"raw\" format open data ExcelAt first glance data might look quite strange messy. stored CSV comma-separated values file. CSV files plain text files can store large amounts data, can readily imported spreadsheet storage database.files simplest form database, coloured cells, formulae, text formatting. row row data, value row (previously separate columns) separated comma.file format helps us maintain ethos Keep Raw Data Raw -many cases, captured collected data may unique impossible reproduce, measurements lab field observations. reason, protected possible loss. Every time change made raw data file threatens integrity information.practice, means use data file data entry storage. data manipulation, cleaning analysis happens R, using transparent reproducible scripts.\navoid saving files Excel format nasty habit formatting even losing data file gets large enough.\n\n[https://www.theguardian.com/politics/2020/oct/05/-excel-may--caused-loss--16000-covid-tests--england].\n\nneed add data csv file, can always open Excel-like program add information, remember save original csv format afterwards.\n\nFigure 3.2: Top image: Penguins data viewed Excel, Bottom image: Penguins data native csv format\nraw format, line CSV separated commas different values. open spreadsheet program like Excel automatically converts comma-separated values tables columns.\nprobably used working Excel (.xls .xlsx) file formats, widely supported, CSV files, simple text formats supported data interfaces. also proprietary (e.g. Excel format owned Microsoft), working .csv format data open accessible.\n","code":""},{"path":"loading-data.html","id":"activity-3-upload-our-data","chapter":"3 Loading data","heading":"3.4 Activity 3: Upload our data","text":"data now Downloads folder computerThe data now Downloads folder computerWe need upload data remote cloud-server (RStudio Cloud), select upload files server button Files tabWe need upload data remote cloud-server (RStudio Cloud), select upload files server button Files tabPut file data folder - make mistake select tickbox file, go cogs button choose option Move.Put file data folder - make mistake select tickbox file, go cogs button choose option Move.\nFigure 3.3: Highlighted buttons upload files, options\n","code":""},{"path":"loading-data.html","id":"activity-4-make-a-script","chapter":"3 Loading data","heading":"3.5 Activity 4: Make a script","text":"now create new R script file write instructions store comments manipulating data, developing tables figures. Use File > New Script menu item select R Script.Add following:load following add-package R script, just underneath comments. Tidyverse actually one package, bundle many different packages play well together - example includes ggplot2 used last session, call separatelyAdd following script:Save file inside scripts folder call 01_import_penguins_data.R\nClick document outline button (top right script pane). show use \n\n#TITLES----\n\nAllows us build series headers subheaders, useful using longer scripts.\n","code":"\n#___________________________----\n# SET UP ----\n## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----\n\n### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. “Ecological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).” PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ------\n#__________________________----\n# PACKAGES ----\nlibrary(tidyverse) # tidy data packages\nlibrary(janitor) # cleans variable names\nlibrary(lubridate) # make sure dates are processed properly\n#__________________________----"},{"path":"loading-data.html","id":"activity-5-read-in-data","chapter":"3 Loading data","heading":"3.6 Activity 5: Read in data","text":"Now can read data. use function readr::read_csv() allows us read .csv files. also functions allow read .xlsx files formats, however course use .csv files.First, create object called penguins_data contains data penguins_raw.csv file.First, create object called penguins_data contains data penguins_raw.csv file.Add following script, check document outline:Add following script, check document outline:\nalso function called read.csv(). careful use function instead read_csv() different ways naming columns.\n","code":"\n# IMPORT DATA ----\npenguins <- read_csv (\"data/penguins_raw.csv\")\n\nhead(penguins) # check the data has loaded, prints first 10 rows of dataframe\n#__________________________----"},{"path":"loading-data.html","id":"filepaths","chapter":"3 Loading data","heading":"3.7 Filepaths","text":"example read_csv() function requires provide filepath (\"quotes\"), order tell R file wish read located example two components\"data/\" - specifies directory look file\"data/\" - specifies directory look file\"penguins_raw.csv\" - specifies name format file\"penguins_raw.csv\" - specifies name format file","code":""},{"path":"loading-data.html","id":"directories","chapter":"3 Loading data","heading":"3.7.1 Directories","text":"directory refers folder computer relationships folders. term “directory” considers relationship folder folders within around . Directories hierarchical means can exist within folders well folders exist within .\nidea directories files ? alone File Found\n\"parent\" directory folder contains subdirectory. example downloads folder directory, parent directory subdirectories files contained within .","code":""},{"path":"loading-data.html","id":"home-directory","chapter":"3 Loading data","heading":"3.7.2 Home directory","text":"home directory computer directory defined operating system. home directory primary directory user account computer. files default stored home directory.Windows, home directory typically C:\\Users\\-username.Windows, home directory typically C:\\Users\\-username.Mac Linux, home directory typically /home/-username.Mac Linux, home directory typically /home/-username.","code":""},{"path":"loading-data.html","id":"working-directory","chapter":"3 Loading data","heading":"3.7.3 Working directory","text":"working directory refers directory computer tool assumes starting place filepaths","code":""},{"path":"loading-data.html","id":"absolute-vs-relative-filepaths","chapter":"3 Loading data","heading":"3.7.4 Absolute vs Relative filepaths","text":"got working R?use programming language, specify filepaths order program find files read-output files.Absolute file path path contains entire path file directory starting Home directory ending file directory wish access e.g./home/-username/project/data/penguins_raw.csvThe main drawbacks using absolute file paths :share files, another user won’t directory structure , need recreate file pathsIf share files, another user won’t directory structure , need recreate file pathsif alter directory structure, ’ll need rewrite pathsif alter directory structure, ’ll need rewrite pathsan absolute file path likely longer relative path, backslashes need edited, scope error.absolute file path likely longer relative path, backslashes need edited, scope error.different computers can different path constructions, scripts use absolute filepaths reproducible.Relative filepath path relative working directory location computer.use RStudio Projects, wherever .Rproj file located set working directory. means .Rproj file located project folder relative path data :data/penguins_raw.csvThis filepath shorter means share project someone else script run without editing.\nusing RStudio Cloud, remember working Linux OS cloud server, different absolute filepath - scripts project working right now work using relative filepaths\n","code":""},{"path":"loading-data.html","id":"activity-5-check-your-script","chapter":"3 Loading data","heading":"3.8 Activity 5: Check your script","text":"","code":"\n#___________________________----\n# SET UP ----\n## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----\n\n### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. “Ecological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).” PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ------\n#__________________________----\n\n# PACKAGES ----\nlibrary(tidyverse) # tidy data packages\nlibrary(janitor) # cleans variable names\nlibrary(lubridate) # make sure dates are processed properly\n#__________________________----\n\n# IMPORT DATA ----\npenguins <- read_csv (\"data/penguins_raw.csv\")\n\nhead(penguins) # check the data has loaded, prints first 10 rows of dataframe\n#__________________________----"},{"path":"loading-data.html","id":"activity-7-test-yourself-1","chapter":"3 Loading data","heading":"3.9 Activity 7: Test yourself","text":"Question 1. order make R project reproducible filepath use?Absolute filepathRelative filepathQuestion 2. acceptable include raw datafile?Highlighting blocks cellsExcel formulaeA column observational notes fielda mix ddmmyy yymmdd date formatsQuestion 3. always first set functions script? ?()Question 4. reading data R useread_csv()read.csv()Question 5. format penguins data ?wide datalong dataEach column unique variable row unique observation data long (tidy) formatQuestion 6. working directory projects default set location ?data filesthe .Rproj fileyour R scriptQuestion 7. Using filepath \"data/penguins_raw.csv\" example ofan absolute filepatha relative filepathQuestion 8. operator need use wish assign output read_csv function R object (rather just print dataframe console)?","code":""},{"path":"data-wrangling-part-one.html","id":"data-wrangling-part-one","chapter":"4 Data wrangling part one","heading":"4 Data wrangling part one","text":"may surprise learn scientists actually spend far time cleaning preparing data spend actually analysing . means completing tasks cleaning bad values, changing structure dataframes, reducing data subset observations, producing data summaries.Many people seem operate assumption option data cleaning painstaking time-consuming cutting pasting data within spreadsheet program like Excel. witnessed students colleagues waste days, weeks, even months manually transforming data Excel, cutting, copying, pasting data. Fixing data hand terrible use time, error-prone reproducible. Additionally, age can easily collect massive datasets online, able organise, clean, prepare hand.short, thrive scientist learn key data wrangling skills. Although every dataset presents unique challenges, systematic principles follow make analyses easier, less error-prone, efficient, reproducible.chapter see data science skills allow efficiently get answers nearly question might want ask data. learning properly make computer hard boring work , can focus bigger issues.","code":""},{"path":"data-wrangling-part-one.html","id":"load-your-workspace","chapter":"4 Data wrangling part one","heading":"4.1 Load your workspace","text":"workspace ready work Palmer penguins data.Load workspace now.Think basic checks start work today.","code":""},{"path":"data-wrangling-part-one.html","id":"checklist","chapter":"4 Data wrangling part one","heading":"4.1.1 Checklist","text":"objects already Environment pane? , use rm(list=ls())objects already Environment pane? , use rm(list=ls())Re-run script last time line 1 last lineRe-run script last time line 1 last lineCheck warning error messagesCheck warning error messagesAdd code today's session script goAdd code today's session script go","code":""},{"path":"data-wrangling-part-one.html","id":"activity-1-change-column-names","chapter":"4 Data wrangling part one","heading":"4.2 Activity 1: Change column names","text":"going learn organise data using tidy format2. using tidyverse packages Wickham (2021). opinionated, highly effective method generating reproducible analyses wide-range data manipulation tools. Tidy data easy format computers read.'tidy' refers specific structure lets us manipulate visualise data ease. tidy dataset variable one column row contains one observation. cell table/spreadsheet contains values. One observation might make tidy data quite long - generates lot rows data - might remember tidy data can referred long-format data (opposed wide data).know data R, know columns names imported. still know whether values imported correctly, whether captured rows.","code":""},{"path":"data-wrangling-part-one.html","id":"open-your-script-from-last-time-and-add-these-new-lines-at-the-bottom.","chapter":"4 Data wrangling part one","heading":"4.2.1 Open your script from last time and add these new lines at the bottom.","text":"run colnames() get identities column dataframeStudy name: identifier year sets observations madeStudy name: identifier year sets observations madeRegion: area observation recordedRegion: area observation recordedIsland: specific island observation recordedIsland: specific island observation recordedStage: Denotes reproductive stage penguinStage: Denotes reproductive stage penguinIndividual ID: unique ID individualIndividual ID: unique ID individualClutch completion: study nest observed full clutch e.g. 2 eggsClutch completion: study nest observed full clutch e.g. 2 eggsDate egg: date study nest observed 1 eggDate egg: date study nest observed 1 eggCulmen length: length dorsal ridge bird's bill (mm)Culmen length: length dorsal ridge bird's bill (mm)Culmen depth: depth dorsal ridge bird's bill (mm)Culmen depth: depth dorsal ridge bird's bill (mm)Flipper Length: length bird's flipper (mm)Flipper Length: length bird's flipper (mm)Body Mass: Bird's mass (g)Body Mass: Bird's mass (g)Sex: Denotes sex birdSex: Denotes sex birdDelta 15N : ratio stable Nitrogen isotopes 15N:14N blood sampleDelta 15N : ratio stable Nitrogen isotopes 15N:14N blood sampleDelta 13C: ratio stable Carbon isotopes 13C:12C blood sampleDelta 13C: ratio stable Carbon isotopes 13C:12C blood sample","code":"\n# CHECK DATA----\n# check the data\ncolnames(penguins)\n#__________________________----"},{"path":"data-wrangling-part-one.html","id":"clean-column-names","chapter":"4 Data wrangling part one","heading":"4.2.2 Clean column names","text":"Often might want change names variables. might non-intuitive, long. data couple issues:names contain spacesSome names contain spacesSome names capitalised lettersSome names capitalised lettersSome names contain bracketsSome names contain bracketsThis dataframe like correct quickly. R case-sensitive also like spaces brackets variable names","code":"\n# CLEAN DATA ----\n\n# clean all variable names to snake_case using the clean_names function from the janitor package\n# note we are using assign <- to overwrite the old version of penguins with a version that has updated names\n# this changes the data in our R workspace but NOT the original csv file\n\npenguins <- janitor::clean_names(penguins) # clean the column names\n\ncolnames(penguins) # quickly check the new variable names##  [1] \"study_name\"        \"sample_number\"     \"species\"          \n##  [4] \"region\"            \"island\"            \"stage\"            \n##  [7] \"individual_id\"     \"clutch_completion\" \"date_egg\"         \n## [10] \"culmen_length_mm\"  \"culmen_depth_mm\"   \"flipper_length_mm\"\n## [13] \"body_mass_g\"       \"sex\"               \"delta_15_n_o_oo\"  \n## [16] \"delta_13_c_o_oo\"   \"comments\""},{"path":"data-wrangling-part-one.html","id":"rename-columns-manually","chapter":"4 Data wrangling part one","heading":"4.2.3 Rename columns (manually)","text":"clean_names function quickly converts variable names snake case. N C blood isotope ratio names still quite long though, clean dplyr::rename() \"new_name\" = \"old_name\".","code":"\n# shorten the variable names for N and C isotope blood samples\n\npenguins <- rename(penguins,\n         \"delta_15n\"=\"delta_15_n_o_oo\",  # use rename from the dplyr package\n         \"delta_13c\"=\"delta_13_c_o_oo\")"},{"path":"data-wrangling-part-one.html","id":"glimpse-check-data-format","chapter":"4 Data wrangling part one","heading":"4.2.4 glimpse: check data format","text":"run glimpse() get several lines output. number observations \"rows\", number variables \"columns\". Check csv file - . next lines see variable names type data.can see dataset 345 rows (including headers) 17 variables\nalso provides information type data column<chr> - means character text data<chr> - means character text data<dbl> - means numerical data<dbl> - means numerical data","code":"\nglimpse(penguins)"},{"path":"data-wrangling-part-one.html","id":"rename-text-values","chapter":"4 Data wrangling part one","heading":"4.2.5 Rename text values","text":"Sometimes may want rename values variables order make shorthand easier follow. changing values columns, column names.\nchecked code block worked? Inspect new tibble check variables renamed wanted.\n","code":"\n# use mutate and case_when for a statement that conditionally changes the names of the values in a variable\npenguins <- penguins %>% \n  mutate(species = case_when(species == \"Adelie Penguin (Pygoscelis adeliae)\" ~ \"Adelie\",\n                             species == \"Gentoo penguin (Pygoscelis papua)\" ~ \"Gentoo\",\n                             species == \"Chinstrap penguin (Pygoscelis antarctica)\" ~ \"Chinstrap\"))"},{"path":"data-wrangling-part-one.html","id":"dplyr-verbs","chapter":"4 Data wrangling part one","heading":"4.3 dplyr verbs","text":"section introduced commonly used data wrangling functions, come dplyr package (part tidyverse). functions likely become familiar .","code":""},{"path":"data-wrangling-part-one.html","id":"select","chapter":"4 Data wrangling part one","heading":"4.3.1 Select","text":"wanted create dataset includes certain variables, can use select() function dplyr package.example might wish create simplified dataset contains species, sex, flipper_length_mm body_mass_g.Run code select columnsAlternatively tell R columns want e.g.Note select() change original penguins tibble. spits new tibble directly console.save new tibble, stored. want keep , must create new object.run new code, see anything console, see new object appear Environment pane.","code":"\n# DPLYR VERBS ----\n\nselect(.data = penguins, # the data object\n       species, sex, flipper_length_mm, body_mass_g) # the variables you want to select\nselect(.data = penguins,\n       -study_name, -sample_number)\nnew_penguins <- select(.data = penguins, \n       species, sex, flipper_length_mm, body_mass_g)"},{"path":"data-wrangling-part-one.html","id":"filter","chapter":"4 Data wrangling part one","heading":"4.3.2 Filter","text":"previously used select() select certain variables, now use filter() select certain rows observations. example Adelie penguins.can equivalence operator ==Filter quite complicate function, uses several differe operators assess way apply filter.\nTable 4.1: Boolean expressions\nwanted select Penguin species except Adelies, use 'equals'.asYou can include multiple expressions within filter() pull rows evaluate TRUE conditions.example code pull observations Adelie penguins flipper length measured greater 190mm.","code":"\nfilter(.data = new_penguins, species == \"Adelie Penguin (Pygoscelis adeliae)\")\nfilter(.data = new_penguins, species != \"Adelie\")\nfilter(.data = new_penguins, species %in% c(\"Chinstrap\", \"Gentoo\"))\nfilter(.data = new_penguins, species == \"Adelie\", flipper_length_mm > 190)"},{"path":"data-wrangling-part-one.html","id":"arrange","chapter":"4 Data wrangling part one","heading":"4.3.3 Arrange","text":"function arrange() sorts rows table according columns supplied. exampleThe data now arranged alphabetical order sex. observations female penguins listed males.can also reverse desc()can also sort one column, think code ?","code":"\narrange(.data = new_penguins, sex)\narrange(.data = new_penguins, desc(sex))\narrange(.data = new_penguins,\n        sex,\n        desc(species),\n        desc(flipper_length_mm))"},{"path":"data-wrangling-part-one.html","id":"mutate","chapter":"4 Data wrangling part one","heading":"4.3.4 Mutate","text":"Sometimes need create new variable exist dataset. example might want figure flipper length factoring body mass.create new variables use function mutate().Note , want save new column must save object. mutating new column attaching new_penguins data oject.","code":"\nnew_penguins <- mutate(.data = new_penguins,\n                       body_mass_kg = body_mass_g/1000)"},{"path":"data-wrangling-part-one.html","id":"pipes","chapter":"4 Data wrangling part one","heading":"4.4 Pipes","text":"Pipes look like : %>% Pipes allow send output one function straight another function. Specifically, send result function %>% first argument function %>%. usual, easier show, rather tell look example.reason function called pipe 'pipes' data next function. wrote code previously, first argument function dataset wanted work . use pipes automatically take data previous line code need specify .Take penguins data \nSelect species, sex flipper length columns \nFilter keep observations labelled sex equals male \nArrange data HIGHEST LOWEST flipper lengths.\nR version 4 onwards now \"native pipe\" |>\n\nrequire tidyverse magrittr package packages load use.\n\ncoursebook chosen continue use tidyverse pipe %>% time likely much familiar tutorials, website usages. native pipe also behaves \"slightly\" differently, cause confusion.\n\nwant read operational differences, site good job explaining\n","code":"\n# this example uses brackets to nest and order functions\narrange(.data = filter(.data = select(.data = penguins, species, sex, flipper_length_mm), sex == \"MALE\"), desc(flipper_length_mm))\n# this example uses sequential R objects to make the code more readable\nobject_1 <- select(.data = penguins, species, sex, flipper_length_mm)\nobject_2 <- filter(.data = object_1, sex == \"MALE\")\narrange(object_2, desc(flipper_length_mm))\n# this example is human readable without intermediate objects\npenguins %>% \n  select(species, sex, flipper_length_mm) %>% \n  filter(sex == \"MALE\") %>% \n  arrange(desc(flipper_length_mm))"},{"path":"data-wrangling-part-one.html","id":"a-few-more-handy-functions","chapter":"4 Data wrangling part one","heading":"4.5 A few more handy functions","text":"","code":""},{"path":"data-wrangling-part-one.html","id":"check-for-duplication","chapter":"4 Data wrangling part one","heading":"4.5.1 Check for duplication","text":"easy inputting data make mistakes, copy something twice example, someone lot copy-pasting assemble spreadsheet (yikes!). can check pretty quicklyGreat!","code":"\n# check for duplicate rows in the data\npenguins %>% \n  duplicated() %>% # produces a list of TRUE/FALSE statements for duplicated or not\n  sum() # sums all the TRUE statements[1] 0"},{"path":"data-wrangling-part-one.html","id":"summarise","chapter":"4 Data wrangling part one","heading":"4.5.2 Summarise","text":"can also explore data obvious typos checking implausibly small large values, simple use summarise function.minimum weight penguins 2.7kg, max 6.3kg - outrageous. min come 27g might suspicious. use summarise calculate metrics future.\nfirst data insight, difference smallest adult penguin dataset nearly half size largest penguin.\n","code":"\n# use summarise to make calculations\npenguins %>% \n  summarise(min=min(body_mass_g, na.rm=TRUE), \n            max=max(body_mass_g, na.rm=TRUE))"},{"path":"data-wrangling-part-one.html","id":"group-by","chapter":"4 Data wrangling part one","heading":"4.5.3 Group By","text":"Many data analysis tasks can approached using “split-apply-combine” paradigm: split data groups, apply analysis group, combine results. dplyr makes easy group_by() function. summarise example able find max-min body mass values penguins dataset. wanted break grouping species penguin. group_by() comes .Now know little data, max weight Gentoo penguins much larger two species. fact, minimum weight Gentoo penguin far max weight two species.","code":"\npenguins %>% \n  group_by(species) %>%  # subsequent functions are perform \"by group\"\n  summarise(min=min(body_mass_g, na.rm=TRUE), \n            max=max(body_mass_g, na.rm=TRUE))"},{"path":"data-wrangling-part-one.html","id":"distinct","chapter":"4 Data wrangling part one","heading":"4.5.4 Distinct","text":"can also look typos asking R produce distinct values variable. useful categorical data, expect distinct categoriesHere someone mistyped e.g. 'FMALE' obvious. thing (probably changed names) species.","code":"\npenguins %>% \n  distinct(sex)"},{"path":"data-wrangling-part-one.html","id":"missing-values-na","chapter":"4 Data wrangling part one","heading":"4.5.5 Missing values: NA","text":"multiple ways check missing values dataBut tell us , fortunately function summary easily","code":"\n# Get a sum of how many observations are missing in our dataframe\npenguins %>% \n  is.na() %>% \n  sum()"},{"path":"data-wrangling-part-one.html","id":"summary","chapter":"4 Data wrangling part one","heading":"4.6 Summary","text":"provides quick breakdown max min numeric variables, well list many missing observations one. can see appear two missing observations measurements body mass, bill lengths, flipper lengths several blood measures. know sure without inspecting data , likely two birds missing multiple measurements, several measured blood drawn.leave NA's alone now, useful know many .now got clean & tidy dataset, handful first insights data.","code":"\n# produce a summary of our data\nsummary(penguins)\n#__________________________----"},{"path":"data-wrangling-part-one.html","id":"finished","chapter":"4 Data wrangling part one","heading":"4.7 Finished","text":"lot work! remember remember functions, remember chapter data wrangling future. Also bookmark RStudio Cheatsheets Page.Finally, make sure saved changes made script 💾 & make sure workspace set save objects environment sessions.want script record work progress, confused cluttered R Environment.","code":""},{"path":"data-wrangling-part-one.html","id":"activity-reorganise-this-script","chapter":"4 Data wrangling part one","heading":"4.8 Activity: Reorganise this script","text":"Using link take text copy/paste new R script save YYYY_MM_DD_workshop_4_jumbled_script.RAll correct lines code, comments document markers present, correct order. Can unscramble produce sensible output clear document outline?","code":""},{"path":"data-wrangling-part-one.html","id":"submit-when-you-are-finished","chapter":"4 Data wrangling part one","heading":"4.8.1 Submit when you are finished","text":"want check answers (just completely stuck) click submitting","code":""},{"path":"data-wrangling-part-two.html","id":"data-wrangling-part-two","chapter":"5 Data wrangling part two","heading":"5 Data wrangling part two","text":"","code":""},{"path":"data-wrangling-part-two.html","id":"load-your-workspace-1","chapter":"5 Data wrangling part two","heading":"5.1 Load your workspace","text":"workspace ready work Palmer penguins data. Load workspace now.Think basic checks start work today.","code":""},{"path":"data-wrangling-part-two.html","id":"checklist-1","chapter":"5 Data wrangling part two","heading":"5.1.1 Checklist","text":"objects already Environment pane? , use rm(list=ls())objects already Environment pane? , use rm(list=ls())Re-run script last time line 1 last lineRe-run script last time line 1 last lineCheck warning error messagesCheck warning error messagesAdd code today's session script goAdd code today's session script go","code":""},{"path":"data-wrangling-part-two.html","id":"more-summary-tools","chapter":"5 Data wrangling part two","heading":"5.2 More summary tools","text":"often want make calculations aobut groups observations, mean median. often interested comparing responses among groups. example, previously found number distinct penguins entire dataset.\nAdd new lines code script try . Comment # add short descriptions achieving \nNow consider groups subsets observations, find number penguins species sex.progress, learning use data wrangling tools. also gaining insights data.Question many female Adelie penguins dataset?Question many Gentoo penguins sex recorded?using summarise group_by lot! powerful functions:group_by adds grouping information data object, subsequent calculations happen group-specific basis.group_by adds grouping information data object, subsequent calculations happen group-specific basis.summarise data aggregation function thart calculates summaries one variables, separately groups defined group_bysummarise data aggregation function thart calculates summaries one variables, separately groups defined group_by","code":"\npenguins %>% \n  summarise(n_distinct(individual_id))\npenguins %>% \n  group_by(species, sex) %>% \n  summarise(n_distinct(individual_id))"},{"path":"data-wrangling-part-two.html","id":"using-summarise","chapter":"5 Data wrangling part two","heading":"5.2.1 Using summarise()","text":"summarise() whole list useful functions producing descriptive statisticsmin max calculate minimum maximum values numeric vectormin max calculate minimum maximum values numeric vectormean median calculate averages numeric vectormean median calculate averages numeric vectorsd var calculate standard deviation variance numeric vectorsd var calculate standard deviation variance numeric vectorUsing summarise can calculate mean flipper bill lengths penguins:\nNote - provide informative names left side =\n\nperforming calculations summarise important set na.rm = TRUE, removes missing values calculation\n\nhappens try produce calculations include NA? e.g NA + 4 NA * 5\ncan use several functions summarise. means can string several calculations together single step, generate insights data.190 unique IDs 344 total observations appear roughly twice many observations unique individuals. sex ratio roughly even (48% female) average flipper length 201 mm.","code":"\npenguins %>% \n  summarise(\n    mean_flipper_length = mean(flipper_length_mm, na.rm=TRUE),\n     mean_culmen_length = mean(culmen_length_mm, na.rm=TRUE))\npenguins %>% \n  summarise(n=n(), # number of rows of data\n            num_penguins = n_distinct(individual_id), # number of unique individuals\n            mean_flipper_length = mean(flipper_length_mm, na.rm=TRUE), # mean flipper length\n            prop_female = sum(sex == \"FEMALE\", na.rm=TRUE) / n()) # proportion of observations that are coded as female"},{"path":"data-wrangling-part-two.html","id":"summarize-across-columns","chapter":"5 Data wrangling part two","heading":"5.2.2 Summarize across columns","text":"across two arguments, .cols .fns..cols argument lets select columns wish apply functions toThe .cols argument lets select columns wish apply functions toThe .fns argument applies required function selected columns..fns argument applies required function selected columns.example calculates means & numeric variables dataset.example slightly complicated way running n_distinct summarise. .cols() looks column contains word \"penguin\" runs n_distinct()command ","code":"\n# Across ----\n# The mean of ALL numeric columns in the data, where(is.numeric == TRUE) hunts for numeric columns\n\npenguins %>% \n  summarise(across(.cols = where(is.numeric), \n                   .fns = ~ mean(., na.rm=TRUE)))\n# number of distinct penguins, as only one column contains the word penguin\n# the argument contains looks for columns that match a character expression\n\npenguins %>% \n  summarise(across(.cols = contains(\"individual\"), \n                   .fns = ~n_distinct(.)))"},{"path":"data-wrangling-part-two.html","id":"group_by-revisited","chapter":"5 Data wrangling part two","heading":"5.2.3 group_by revisited","text":"group_by function provides ability separate summary functions according subgroups wish make. real magic happens pair summarise mutate.example, grouping individual penguin ids, summarising n - can see many times penguin monitored course study.\nRemember actions group_by \"invisible\". Subsequent functions applied \"grouped \" manner - dataframe looks unchanged.\n","code":"\npenguin_stats <- penguins %>% \n  group_by(individual_id) %>% \n  summarise(num=n())"},{"path":"data-wrangling-part-two.html","id":"more-than-one-grouping-variable","chapter":"5 Data wrangling part two","heading":"5.2.4 More than one grouping variable","text":"need calculate one variable time?\nproblem can submit several arguments:can calculate mean flipper length penguins six combinationsNow first row summary table shows us mean flipper length (mm) female Adelie penguins. eight rows total, six unique combinations two rows sex penguins recorded(NA)","code":"\npenguins_grouped <- penguins %>% \n  group_by(sex, species)\npenguins_grouped %>% \nsummarise(mean_flipper = mean(flipper_length_mm, na.rm=TRUE))"},{"path":"data-wrangling-part-two.html","id":"using-group_by-with-mutate","chapter":"5 Data wrangling part two","heading":"5.2.5 using group_by with mutate","text":"far used group_by summarise function, always case.\nmutate used group_by, calculations occur 'group'. example:calculating group centered mean, new variable contains difference observation mean whichever group observation .","code":"\n# Using mutate and group_by ----\ncentered_penguins <- penguins %>% \n  group_by(sex, species) %>% \n  mutate(flipper_centered = flipper_length_mm-mean(flipper_length_mm, na.rm=TRUE))\n\ncentered_penguins %>% \n  select(flipper_centered)\n# Each row now returns a value for EACH penguin of how much greater/lesser than the group average (sex and species) its flipper is. "},{"path":"data-wrangling-part-two.html","id":"remove-group_by","chapter":"5 Data wrangling part two","heading":"5.2.6 remove group_by","text":"occasion may need remove grouping information dataset. often required string pipes together, need work using grouping structure, revert back whole dataset againLook grouped dataframe, can see information groups top data:Look output - can see information groups now removed data.","code":"# A tibble: 344 x 10\n# Groups:   sex, species [8]\n   species island culmen_length_mm culmen_depth_mm flipper_length_~ body_mass_g\n   <chr>   <chr>           <dbl>         <dbl>            <dbl>       <dbl>\n 1 Adelie  Torge~           39.1          18.7              181        3750\n 2 Adelie  Torge~           39.5          17.4              186        3800\n 3 Adelie  Torge~           40.3          18                195        3250\n# Run this command will remove the groups - but this is only saved if assigned BACK to an object\n\ncentered_penguins <- centered_penguins %>% \n  ungroup()\n\ncentered_penguins"},{"path":"data-wrangling-part-two.html","id":"working-with-character-strings","chapter":"5 Data wrangling part two","heading":"5.3 Working with character strings","text":"Datasets often contain words, call words \"(character) strings\".Often quite want , can manipulate much like. Functions package stringr, fantastic. number different types manipulations endless!","code":"\n# Stringr ----\n\nstr_replace_all(names(penguins), c(\"e\"= \"E\"))\n# replace all character \"e\" with \"E\""},{"path":"data-wrangling-part-two.html","id":"more-stringr","chapter":"5 Data wrangling part two","heading":"5.3.1 More stringr","text":"can also trim leading trailing empty spaces str_trim. often problematic difficult spot e.g.can easily imagine scenario data manually input, trailing leading spaces left . difficult spot eye - problematic far R concerned different values. can use function distinct return names different levels can find dataframe.pipe data throught str_trim function remove gaps, pipe distinct - removing whitespace, R now recognises just one level data.quick example extract partial strings according pattern use str_detect. Combined filter possible subset dataframe searching strings match provided information, penguin IDs start \"N1\"","code":"\npenguins %>% \n  mutate(species=str_to_upper(species))\n# Capitalise all letters\npenguins %>% \n  mutate(species=str_remove_all(species, \"e\"))\n# remove every character \"e\" from selected variables\ndf2 <- tibble(label=c(\"penguin\", \" penguin\", \"penguin \")) \ndf2 # make a test dataframe\ndf2 %>% \n  distinct()\ndf2 %>% \n  mutate(label=str_trim(label, side=\"both\")) %>% \n  distinct()\npenguins %>% \n  filter(str_detect(individual_id, \"N1\"))"},{"path":"data-wrangling-part-two.html","id":"separate","chapter":"5 Data wrangling part two","heading":"5.3.2 separate","text":"Sometimes string might contain two pieces information one. confirm tidy data principles. can easily separate information separate() tidyr package.First produce made-dataWe started one variable called label split two variables, treatment replicate, split made - occurs.\nopposite function unite()","code":"\ndf <- tibble(label=c(\"a-1\", \"a-2\", \"a-3\")) \n#make a one column tibble\ndf\ndf %>% \n  separate(label, # name of variable\n           c(\"treatment\", \"replicate\"), # new column names\n           sep=\"-\") # the character to mark where the separation occurs"},{"path":"data-wrangling-part-two.html","id":"changing-data-formats","chapter":"5 Data wrangling part two","heading":"5.4 Changing data formats","text":"previous worksheet, used glimpse() check format variables. One variables date_egg helpful format. read character string, means intrinsic order values attached dates. likely happened \"/\" symbols. clearly non-numerical symbols variables, R default treating character variables.Luckily can fix using mutate() str_remove_all()Check codeQuestion now mean date_egg variable treated numeric? ryesnoData formats set reading data first time, wish change , need explicitly using mutate()\n.numeric(), .character(), .logical() functions convert data formats, work \"illegal\" characters. may need remove first, examples .\n","code":"\n# DATES ----\npenguins %>% \n  mutate(date_egg = str_remove_all(date_egg, \"/\"))\n# add the as.numeric() function\npenguins %>% \n  mutate(date_egg = as.numeric(str_remove_all(date_egg, \"/\"))) %>% \n  glimpse()"},{"path":"data-wrangling-part-two.html","id":"working-with-dates","chapter":"5 Data wrangling part two","heading":"5.5 Working with dates","text":"now know can change data formats easily, treating date strictly numeric problematic, account number days months number months year.Additionally lot different ways write date:13-10-201913-10-201910-13-201910-13-201913-10-1913-10-1913th Oct 201913th Oct 20192019-10-132019-10-13This variability makes difficult tell software read information, luckily can use functions lubridate package.Depending interpret date ordering file, can use ymd(), ydm(), mdy(), dmy()Question appropriate function use date_egg variable?\nget warning dates parsed, might find date inconsistently entered dataset.\n\nPay attention warning error messages\nuse mutate function dplyr create new variable called date_egg_proper based output converting characters date_egg date format. original variable left intact, specified \"new\" variable also called date_egg overwritten original variable.established date data, able perform calculations. date range across data collected.","code":"\npenguins <- penguins %>%\n  mutate(date_egg_proper = lubridate::dmy(date_egg))\npenguins %>% \n  summarise(min_date=min(date_egg_proper),\n            max_date=max(date_egg_proper))"},{"path":"data-wrangling-part-two.html","id":"calculations-with-dates","chapter":"5 Data wrangling part two","heading":"5.5.1 Calculations with dates","text":"many times penguin measured, across total time period?Cool can also convert intervals days weeks, months years dweeks(1), dmonths(1), dyears(1).cool functions, check RStudio cheat sheet information. Date type data common datasets, learning work useful skill.","code":"\npenguins %>% \n  group_by(individual_id) %>% \n  summarise(first_observation=min(date_egg_proper), \n            last_observation=max(date_egg_proper), \n            study_duration = last_observation-first_observation, \n            n=n())\npenguins %>% \n  group_by(individual_id) %>% \n  summarise(first_observation=min(date_egg_proper), \n            last_observation=max(date_egg_proper), \n            study_duration_years = (last_observation-first_observation)/lubridate::dyears(1), \n            n=n()) %>% \n    arrange(desc(study_duration_years))"},{"path":"data-wrangling-part-two.html","id":"factors","chapter":"5 Data wrangling part two","heading":"5.6 Factors","text":"R, factors class data allow ordered categories fixed set acceptable values.Typically, convert column character numeric class factor want set intrinsic order values (“levels”) can displayed non-alphabetically plots tables, use linear model analyses (later).Another common use factors standardise legends plots fluctuate certain values temporarily absent data.make barplot, order values x axis typically alphabetical order character dataTo convert character numeric column class factor, can use function forcats package. convert class factor also perform allow certain ordering levels - example using forcats::fct_relevel() lets manually specify level order.\nfunction as_factor() simply converts class without capabilities.base R function factor() converts column factor allows manually specify order levels, character vector levels = argument.use mutate() fct_relevel() convert column flipper_range class character class factor.Now call plot, can see x axis categories match intrinsic order specified factor levels.","code":"\npenguins <- penguins %>% \n  mutate(flipper_range = case_when(flipper_length_mm <= 190 ~ \"small\",\n                                   flipper_length_mm >190 & flipper_length_mm < 213 ~ \"medium\",\n                                   flipper_length_mm >= 213 ~ \"large\"))\npenguins %>% \n  ggplot(aes(x = flipper_range))+\n  geom_bar()\npenguins <- penguins %>% \n  mutate(flipper_range = fct_relevel(flipper_range))\nlevels(penguins$flipper_range)## [1] \"large\"  \"medium\" \"small\"\n# Correct the code in your script with this version\npenguins <- penguins %>% \n  mutate(flipper_range = fct_relevel(flipper_range, \"small\", \"medium\", \"large\"))\npenguins %>% \n  ggplot(aes(x = flipper_range))+\n  geom_bar()"},{"path":"data-wrangling-part-two.html","id":"finished-1","chapter":"5 Data wrangling part two","heading":"5.7 Finished","text":"Make sure saved script 💾 given filename \"01_import_penguins_data.R\" \"scripts\" folder.Make sure saved script 💾 given filename \"01_import_penguins_data.R\" \"scripts\" folder.Make sure workspace set save objects environment sessions.Make sure workspace set save objects environment sessions.workspace look like ?workspace look like ?\nFigure 5.1: neat project layout\n\nFigure 5.2: scripts file subdirectory\n","code":""},{"path":"data-wrangling-part-two.html","id":"activity-test-yourself","chapter":"5 Data wrangling part two","heading":"5.8 Activity: Test yourself","text":"Question 1. order subset data rows use function select()filter()group_by()Question 2. order subset data columns use function select()filter()group_by()Question 3. order make new column use function group_by()select()mutate()arrange()Question 4. operator use send output line code next line? Question 5. outcome following line code?penguins dataframe object reduced include Adelie penguins now onA new filtered dataframe Adelie penguins printed consoleUnless output series functions \"assigned\" object using <- saved, results immediately printed. code modified order create new filtered object penguins_filteredQuestion 5. main point data \"pipe\"?code runs fasterThe code easier readQuestion 6. naming convention outputted function `janitor::clean_names() \nsnake_casecamelCaseSCREAMING_SNAKE_CASEkebab-caseQuestion 7. package provides useful functions manipulating character strings?stringrggplot2lubridateforcatsQuestion 8. package provides useful functions manipulating dates?stringrggplot2lubridateforcatsQuestion 9. specify character variable factor, ordering default ?numericalalphabeticalorder dataframe","code":"\npenguins %>% \n  filter(species == \"Adelie\")\npenguins_filtered <- penguins %>% \n  filter(species == \"Adelie\")"},{"path":"data-visualisation-with-ggplot2.html","id":"data-visualisation-with-ggplot2","chapter":"6 Data visualisation with ggplot2","heading":"6 Data visualisation with ggplot2","text":"","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"intro-to-grammar","chapter":"6 Data visualisation with ggplot2","heading":"6.1 Intro to grammar","text":"ggplot2 package widely used valued simple, consistent approach making data visuals.'grammar graphics' relates different components plot function like different parts linguistic grammar. example, plots require axes, x y axes form one part ‘language’ plot. Similarly, plots data represented axes, often points, lines bars. visual way data represented forms another component grammar graphics. Furthermore, colour, shape size points lines can used encode additional information plot. information usually clarified key, legend, can also considered part ‘grammar’.philosophy ggplot much better explained package author, Hadley Wickham (Wickham et al. (2022)). now, just need aware ggplots constructed specifying different components want display, based underlying information data frame.\nFigure 6.1: example can produce ggplot\n","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"before-we-start","chapter":"6 Data visualisation with ggplot2","heading":"6.2 Before we start","text":"workspace ready work Palmer penguins data. Load workspace now.Think basic checks start work today.","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"checklist-2","chapter":"6 Data visualisation with ggplot2","heading":"6.2.1 Checklist","text":"objects already Environment pane? , use rm(list=ls())\nToday going make NEW R script project space previously working. part organising workspace analysis workflow well documented easy follow\nOpen new R script - moving data wrangling data visualisationOpen new R script - moving data wrangling data visualisationSave file scripts folder call 02_visualisation_penguins.RSave file scripts folder call 02_visualisation_penguins.RAdd following script run :Add following script run :find Environment fills objects script 1\nsource() function handy way allowing different scripts different parts R project, allow access objects built elsewhere. way building analysis stages.\n\ncommand work remembered save name script exactly put script inside subfolder called scripts.\n\nproject look like one ?\n\nFigure 6.2: neat project layout\n\nFigure 6.3: sucessfully saved 02_visualisation_penguins.R visible \n","code":"\n# LOAD R OBJECTS AND FUNCTIONS ----\nsource(\"scripts/01_import_penguins_data.R\")\n# import tidied penguins data and functions\n#__________________________----"},{"path":"data-visualisation-with-ggplot2.html","id":"what-if-source-isnt-working","chapter":"6 Data visualisation with ggplot2","heading":"6.2.2 What if source isn't working?","text":"source working, figure project set-can complete worksheet put following commands top script instead source(\"scripts/01_import_penguins_data.R\")","code":"\n#___________________________----\n# SET UP ----\n## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----\n\n### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. “Ecological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).” PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ------\n#__________________________----\n\n# PACKAGES ----\nlibrary(tidyverse) # tidy data packages\nlibrary(janitor) # cleans variable names\nlibrary(lubridate) # make sure dates are processed properly\n#__________________________----\n\n# IMPORT DATA ----\npenguins <- read_csv (\"data/penguins_raw.csv\")\n\npenguins <- janitor::clean_names(penguins) # clean variable names\n#__________________________----"},{"path":"data-visualisation-with-ggplot2.html","id":"building-a-plot","chapter":"6 Data visualisation with ggplot2","heading":"6.3 Building a plot","text":"start building plot going use penguin data working previously. First must specify data frame contains relevant data plot. can two ways:‘sending penguins data set ggplot function’:specifying dataframe within ggplot() functionThe output identical\nRunning command produce empty grey panel. need specify different columns data frame represented plot.\n","code":"\n# Building a ggplot step by step ----\n## Render a plot background ----\npenguins %>% \n  ggplot()\nggplot(data = penguins)"},{"path":"data-visualisation-with-ggplot2.html","id":"aesthetics---aes","chapter":"6 Data visualisation with ggplot2","heading":"6.3.1 Aesthetics - aes()","text":"can call different columns data dataset based column names. Column names given ‘aesthetic’ elements ggplot function, wrapped aes() function.want scatter plot, point x y coordinate. want x axis represent flipper length ( x = flipper_length_mm ), y axis represent body mass ( y = body_mass_g ).give specifications separated comma. Quotes required giving variables within aes().\ninterested quotes aren’t required can read non-standard evaluation.\nfar grid lines x y axis. ggplot() knows variables required plot, thus scale, information display data points.","code":"\n## Set axes ----\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))"},{"path":"data-visualisation-with-ggplot2.html","id":"geometric-representations---geom","chapter":"6 Data visualisation with ggplot2","heading":"6.4 Geometric representations - geom()","text":"Given want scatter plot, need specify geometric representation data point form, using geom_point(). many geometric object types.\nFigure 2.1: geom shapes\nadding layer (hence + sign) points plot. can think similar e.g. Adobe Photoshop uses layers images can reordered modified individually. add plots layer layer order geoms may important final aesthetic design.ggplot, layer added plot according position code. first show full breakdown components layer. layer requires information ondataaestheticsgeometric typeany summary datapositionThis quite complicate way write new layers - usual see simpler compact approachNow scatter plot! row (except two rows missing data) penguins data set now x coordinate, y coordinate, designated geometric representation (point).can see smaller penguins tend smaller flipper lengths.","code":"\n## Add a geom ----\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  layer(                # layer inherits data and aesthetic arguments from previous\n    geom=\"point\",       # draw point objects\n    stat=\"identity\",    # each individual data point gets a geom (no summaries)\n    position=position_identity()) # data points are not moved in any way e.g. we could specify jitter or dodge if we want to avoid busy overlapping data\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  geom_point() # geom_point function will always draw points, and unless specified otherwise the arguments for position and stat are both \"identity\"."},{"path":"data-visualisation-with-ggplot2.html","id":"and","chapter":"6 Data visualisation with ggplot2","heading":"6.4.1 %>% and +","text":"ggplot2, early component tidyverse package, written pipe introduced. + sign ggplot2 functions similar way pipe functions tidyverse: allowing code written left right.","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"colour","chapter":"6 Data visualisation with ggplot2","heading":"6.4.2 Colour","text":"colors lines points can set directly using colour=\"red\", replacing “red” color name. colors filled objects, like bars, can set using fill=\"red\".However current plot informative colour used convey information species penguin.order achieve need use aes() , make colour conditional upon variable., aes() function containing relevant column name, given within geom_point() function.\ncommon mistake get confused use (use) aes()\n\nspecifying fixed aesthetic e.g. red everything go inside aes() instead specify e.g. colour = \"red\" shape =21.\n\nwish modify aethetic according variable data go inside aes() e.g. aes(colour = species)\n\nmay (may ) noticed grammar ggplot (tidyverse general) accepts British/Americanization spelling!!!\ndata visualisations can start gain insights data quickly, can see Gentoo penguins tend larger longer flippers\nAdd carriage returns (new lines) %>% + symbols.\n\ncases, R blind white space new lines, simply make code readable, allow us add readable comments.\n","code":"\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  geom_point(colour=\"red\")\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  geom_point(aes(colour=species))"},{"path":"data-visualisation-with-ggplot2.html","id":"more-layers","chapter":"6 Data visualisation with ggplot2","heading":"6.4.3 More layers","text":"can see relationship body size flipper length. want model relationship trend line? can add another ‘layer’ plot, using different geometric representation data. case trend line, fact summary data rather representation point.geom_smooth() function draws trend line data. default behaviour draw local regression line (curve) points, however can hard interpret. want add straight line based linear model (‘lm’) relationship x y.first encounter linear models course, learn lot later .example may notice assigning colour variable (species) geometric layers. means option simplify code. Aesthetics set \"top layer\" ggplot() inherited subsequent layers.\nNote - trend line blocking certain points, ‘top layer’ plot. geom layers appear early command drawn first, can obscured geom layers come .\n\nhappens switch order geom_point() geom_smooth() functions ? notice trend line?\n","code":"\n## Add a second geom ----\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  geom_point(aes(colour=species))+\n  geom_smooth(method=\"lm\",    #add another layer of data representation.\n              se=FALSE,\n              aes(colour=species)) # note layers inherit information from the top ggplot() function but not previous layers - if we want separate lines per species we need to either specify this again *or* move the color aesthetic to the top layer. \npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g,\n             colour=species))+ ### now colour is set here it will be inherited by ALL layers\n  geom_point()+\n  geom_smooth(method=\"lm\",    #add another layer of data representation.\n              se=FALSE)"},{"path":"data-visualisation-with-ggplot2.html","id":"co-ordinate-space","chapter":"6 Data visualisation with ggplot2","heading":"6.4.4 Co-ordinate space","text":"ggplot automatically pick scale axis, type coordinate space. plots Cartesian (linear X vs linear Y) coordinate space.plot, let’s say want x y origin set 0. can add xlim() ylim() functions, define limits axes:, can control coordinate space using coord() functions. Say want flip x y axes, add coord_flip():","code":"\n## Set axis limits ----\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g,\n             colour=species))+ \n  geom_point()+\n  geom_smooth(method=\"lm\",    \n              se=FALSE)+\n  xlim(0,240) + ylim(0,7000)\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g,\n             colour=species))+ \n  geom_point()+\n  geom_smooth(method=\"lm\",    \n              se=FALSE)+\n  xlim(0,240) + ylim(0,7000)+\n  coord_flip()"},{"path":"data-visualisation-with-ggplot2.html","id":"labels","chapter":"6 Data visualisation with ggplot2","heading":"6.5 Labels","text":"default, axis labels column names gave aesthetics aes(). can change axis labels using xlab() ylab() functions. Given column names often short can cryptic, functionality particularly important effectively communicating results.","code":"\n## Custom labels ----\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g,\n             colour=species))+ \n  geom_point()+\n  geom_smooth(method=\"lm\",    \n              se=FALSE)+\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\")"},{"path":"data-visualisation-with-ggplot2.html","id":"titles-and-subtitles","chapter":"6 Data visualisation with ggplot2","heading":"6.5.1 Titles and subtitles","text":"","code":"\n## Add titles ----\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g,\n             colour=species))+ \n  geom_point()+\n  geom_smooth(method=\"lm\",    \n              se=FALSE)+\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       title= \"Penguin Size, Palmer Station LTER\",\n       subtitle= \"Flipper length and body mass for three penguin species\")"},{"path":"data-visualisation-with-ggplot2.html","id":"themes","chapter":"6 Data visualisation with ggplot2","heading":"6.6 Themes","text":"Finally, overall appearance plot can modified using theme() functions. default theme grey background.\nmay prefer theme_classic(), theme_minimal() even theme_void(). Try .\nlot customisation available theme() function. look making custom themes later lessons\n\ncan also try installing running even wider range pre-built themes install R package ggthemes.\n\nFirst need run install.packages(\"ggthemes\") command. Remember one times command written script typed directly console. rude send someone script install packages computer - think library() polite request instead!\n\naccess range themes available type help(ggthemes) follow documentation find can .\n","code":"\n## Custom themes ----\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g,\n             colour=species))+ \n  geom_point()+\n  geom_smooth(method=\"lm\",    \n              se=FALSE)+\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       title= \"Penguin Size, Palmer Station LTER\",\n       subtitle= \"Flipper length and body mass for three penguin species\")+\n  theme_void()"},{"path":"data-visualisation-with-ggplot2.html","id":"more-geom-shapes","chapter":"6 Data visualisation with ggplot2","heading":"6.7 More geom shapes","text":"","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"jitter","chapter":"6 Data visualisation with ggplot2","heading":"6.7.1 Jitter","text":"geom_jitter() command adds random scatter points can reduce -plotting. Compare two plots:","code":"\n## geom point\n\nggplot(data = penguins, aes(x = species, y = culmen_length_mm)) +\n  geom_point(aes(color = species),\n              alpha = 0.7, \n              show.legend = FALSE) \n\n## More geoms ----\nggplot(data = penguins, aes(x = species, y = culmen_length_mm)) +\n  geom_jitter(aes(color = species),\n              width = 0.1, # specifies the width, change this to change the range of scatter\n              alpha = 0.7, # specifies the amount of transparency in the points\n              show.legend = FALSE) # don't leave a legend in a plot, if it doesn't add value"},{"path":"data-visualisation-with-ggplot2.html","id":"boxplots","chapter":"6 Data visualisation with ggplot2","heading":"6.7.2 Boxplots","text":"Box plots, ‘box & whisker plots’ another essential tool data analysis. Box plots summarize distribution set values displaying minimum maximum values, median (.e. middle-ranked value), range middle 50% values (inter-quartile range).\nwhisker line extending IQR box define Q3 + (1.5 x IQR), Q1 - (1.5 x IQR) respectively. can watch short video learn box plots .create box plot data use (prizes ) geom_boxplot()\nNote specifying colour variables using aes() geometric shapes support internal colour \"fill\" external colour \"colour\". Try changing aes fill colour code , note happens.\npoints indicate outlier values [.e., greater Q3 + (1.5 x IQR)].can overlay boxplot scatter plot entire dataset, fully communicate raw summary data. reduce width jitter points slightly.\nexample switched using show.legend=FALSE inside geom layer using theme(legend.position=\"none\"). ? example reducing redundant code. specify show.legend=FALSE every geom layer plot, theme function applies every layer. Save code, save time, reduce errors!\n","code":"\nggplot(data = penguins, aes(x = species, y = culmen_length_mm)) +\n  geom_boxplot(aes(fill = species),\n              alpha = 0.7, \n              width = 0.5, # change width of boxplot\n              show.legend = FALSE)\nggplot(data = penguins, aes(x = species, y = culmen_length_mm)) +\n  geom_boxplot(aes(fill = species), # note fill is \"inside\" colour and colour is \"edges\" - try it for yourself\n              alpha = 0.2, # fainter boxes so the points \"pop\"\n              width = 0.5, # change width of boxplot\n              outlier.shape=NA)+\n  geom_jitter(aes(colour = species),\n                width=0.2)+\n  theme(legend.position = \"none\")"},{"path":"data-visualisation-with-ggplot2.html","id":"density-and-histogram","chapter":"6 Data visualisation with ggplot2","heading":"6.7.3 Density and histogram","text":"Compare following two sets code:first might struggle see/understand difference two charts. shapes roughly .first block code produced frequency histogram, bar represents actual number observations made within 'bin', second block code shows 'relative density' within bin. density histogram area curve sub-group sum 1. allows us compare distributions shapes sub-groups different sizes. example far fewer Adelie penguins dataset, density histogram occupy area graph two species.","code":"\npenguins %>% \n    ggplot(aes(x=culmen_length_mm, fill=species),\n           position = \"identity\")+\n    geom_histogram(bins=50)\npenguins %>% \n    ggplot(aes(x=culmen_length_mm, fill=species))+\n    geom_histogram(bins=50, \n                   aes(y=..density..),\n                   position = \"identity\")"},{"path":"data-visualisation-with-ggplot2.html","id":"more-colours","chapter":"6 Data visualisation with ggplot2","heading":"6.8 More Colours","text":"two main differences comes colors ggplot2. arguments, color fill, can specified single color \nassigned variables.already seen tutorial, variables inside aesthetics encoded variables outside properties unrelated variables.","code":"\npenguins %>% \n    ggplot(aes(x=culmen_length_mm))+\n    geom_histogram(bins=50, \n                   aes(y=..density..,\n                       fill=species), \n                   position = \"identity\",\n                   colour=\"black\")"},{"path":"data-visualisation-with-ggplot2.html","id":"choosing-and-using-colour-palettes","chapter":"6 Data visualisation with ggplot2","heading":"6.8.1 Choosing and using colour palettes","text":"can specify colours want assign variables number different ways.ggplot2, colors assigned variables modified via scale_color_* scale_fill_* functions. order use color data, importantly need know dealing categorical continuous variable. color palette chosen depending type variable:sequential diverging color palettes used continuous variablessequential diverging color palettes used continuous variablesqualitative color palettes (unordered) categorical variables:qualitative color palettes (unordered) categorical variables:can pick sets colours assign categorical variable. number specified colours match number categories. can use wide number preset colour names can use hexadecimals.can also use range inbuilt colour palettes:\ncan explore schemes available command RColorBrewer::display.brewer.()\nalso many, many extensions provide additional colour palettes. favourite packages include ggsci wesanderson","code":"\n## Custom colours ----\n\npenguin_colours <- c(\"darkolivegreen4\", \"darkorchid3\", \"goldenrod1\")\n\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  geom_point(aes(colour=species))+\n  scale_color_manual(values=penguin_colours)+\n  theme_minimal()\npenguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  geom_point(aes(colour=species))+\n  scale_color_brewer(palette=\"Set1\")+\n  theme_minimal()"},{"path":"data-visualisation-with-ggplot2.html","id":"accessibility","chapter":"6 Data visualisation with ggplot2","heading":"6.9 Accessibility","text":"","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"colour-blindness","chapter":"6 Data visualisation with ggplot2","heading":"6.9.1 Colour blindness","text":"easy get carried away colour palettes, remember times figures must accessible. One way check accessible figures use colour blindness checker colorBlindness","code":"\n## Check accessibility ----\n\nlibrary(colorBlindness)\ncolorBlindness::cvdPlot() # will automatically run on the last plot you made"},{"path":"data-visualisation-with-ggplot2.html","id":"guides-to-visual-accessibility","chapter":"6 Data visualisation with ggplot2","heading":"6.9.2 Guides to visual accessibility","text":"Using colours tell categories apart can useful, can see example , choose carefully. aesthetics can access geoms include shape, size - can combine complimentary ways enhance accessibility plots. hierarchy \"interpretability\" different types data","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"facets","chapter":"6 Data visualisation with ggplot2","heading":"6.10 Facets","text":"Adding combinations different aesthetics allows layer information onto 2D plot, sometimes though things just become busy. point becomes difficult see trends differences plot want break single plot sub-plots; called ‘faceting’. Facets commonly used much data display clearly single plot. revisit faceting , however now, let’s try facet plot according sex.use tilde symbol ‘~’ indicate column name form facet.","code":"\n## Facetting ----\npenguins %>% \n  drop_na(sex) %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g,\n             colour=species))+ \n  geom_point()+\n  geom_smooth(method=\"lm\",    \n              se=FALSE)+\n  facet_wrap(~sex)"},{"path":"data-visualisation-with-ggplot2.html","id":"patchwork","chapter":"6 Data visualisation with ggplot2","heading":"6.11 Patchwork","text":"many times might want combine separate figures multi-panel plots. Probably easiest way patchwork package (Pedersen (2020)).","code":"\n## Patchwork ----\nlibrary(patchwork)\n\np1 <- penguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = culmen_length_mm))+\n  geom_point(aes(colour=species))+\n  scale_color_manual(values=penguin_colours)+\n  theme_minimal()\n\np2 <- penguins %>% \n  ggplot(aes(x=culmen_depth_mm, \n             y = culmen_length_mm))+\n  geom_point(aes(colour=species))+\n  scale_color_manual(values=penguin_colours)+\n  theme_minimal()\n\np3 <- penguins %>%     \n  group_by(sex,species) %>% \n    summarise(n=n()) %>% \n     drop_na(sex) %>% \n     ggplot(aes(x=species, y=n)) + \n  geom_col(aes(fill=sex), \n               width=0.8,\n               position=position_dodge(width=0.9), \n               alpha=0.6)+\n     scale_fill_manual(values=c(\"darkorange1\", \"azure4\"))+\n     theme_classic()\n\n (p1+p2)/p3+\n  plot_layout(guides = \"collect\") "},{"path":"data-visualisation-with-ggplot2.html","id":"activity-replicate-this-figure","chapter":"6 Data visualisation with ggplot2","heading":"6.12 Activity: Replicate this figure","text":"\nclose can get replicating figure ?\n\nMake NEW script assignment - replicate_figure.R\n\nMake sure use tips links end chapter, done save file submit!\n","code":"\npal <- c(\"#FF8C00\", \"#A034F0\", \"#159090\")\n\npenguins %>% \n  ggplot(aes(x = species,\n             y = body_mass_g,\n             fill = species,\n             colour = species))+\n  geom_violin(alpha = 0.2)+\n  geom_boxplot(width = 0.2,\n               alpha = 0.6)+\n  scale_fill_manual(values = pal)+\n  scale_colour_manual(values = pal)+\n  theme_classic()+\n  theme(legend.position = \"none\")+\n    labs(\n    x = \"\",\n    y = \"Body mass (g)\",\n    title = \"Body mass of brush-tailed penguins\",\n    subtitle = \"Box and violin plot of body mass by species\")"},{"path":"data-visualisation-with-ggplot2.html","id":"saving","chapter":"6 Data visualisation with ggplot2","heading":"6.13 Saving","text":"One easiest ways save figure made ggsave() function. default save last plot made screen.specify output path figures folder, provide file name. decided call plot plot (imaginative!) want save .PNG image file. can also specify resolution (dpi 300 good enough computer screens).\ngot far still time try one following:\n\n\nMaking another type figure using penguins dataset, use reading use inspiration.\n\n\nMaking another type figure using penguins dataset, use reading use inspiration.\n\n\nUse data\n\n\nUse data\n","code":"\n# OUTPUT FIGURE TO FILE\n\nggsave(\"outputs/YYYYMMDD_ggplot_workshop_final_plot.png\", dpi=300)"},{"path":"data-visualisation-with-ggplot2.html","id":"quitting-1","chapter":"6 Data visualisation with ggplot2","heading":"6.14 Quitting","text":"\nMake sure saved script! Remember Download image file RStudio Cloud onto computer.\n\nrun SessionInfo() end script gather packages versions using. useful cite R versions packages writing reports later.\n","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"finished-2","chapter":"6 Data visualisation with ggplot2","heading":"6.15 Finished","text":"Make sure saved scripts 💾 \"scripts\" folder.Make sure saved scripts 💾 \"scripts\" folder.Make sure workspace set save objects environment sessions.Make sure workspace set save objects environment sessions.","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"what-we-learned","chapter":"6 Data visualisation with ggplot2","heading":"6.15.1 What we learned","text":"learnedThe anatomy ggplotsThe anatomy ggplotsHow add geoms different layersHow add geoms different layersHow use colour, colour palettes, facets, labels themesHow use colour, colour palettes, facets, labels themesPutting together multiple figuresPutting together multiple figuresHow save export imagesHow save export images","code":""},{"path":"data-visualisation-with-ggplot2.html","id":"further-reading-guides-and-tips-on-data-visualisation","chapter":"6 Data visualisation with ggplot2","heading":"6.15.2 Further Reading, Guides and tips on data visualisation","text":"R Cheat SheetsR Cheat SheetsFundamentals Data Visualization: book tells everything need know presenting figures accessbility clarityFundamentals Data Visualization: book tells everything need know presenting figures accessbility clarityBeautiful Plotting R: incredibly handy ggplot guide build improve figuresBeautiful Plotting R: incredibly handy ggplot guide build improve figuresThe ggplot2 book: original Hadley Wickham book ggplot2The ggplot2 book: original Hadley Wickham book ggplot2","code":""},{"path":"markdown.html","id":"markdown","chapter":"7 Markdown","heading":"7 Markdown","text":"R Markdown widely-used tool creating automated, reproducible, share-worthy outputs, reports. can generate static interactive outputs, Word, pdf, html, Powerpoint slides, many formats.R Markdown script combines R code text script actually becomes output document. can create entire formatted document, including narrative text (can dynamic change based data), tables, figures, bullets/numbers, bibliographies, etc.Documents produced Rmarkdown, allow analyses included easily - make link raw data, analysis & published report completely reproducible.Rmarkdown can make reproducible html, word, pdf, powerpoints websites dashboards3To make Rmd publish - hit knit button top doc","code":""},{"path":"markdown.html","id":"format","chapter":"7 Markdown","heading":"7.0.1 Format","text":"Go RStudio Cloud open workspace last time.Go RStudio Cloud open workspace last time.Follow instructions carefully - assemble Rmarkdown file bit bit - prompted 'knit' document . observed results might make changes.Follow instructions carefully - assemble Rmarkdown file bit bit - prompted 'knit' document . observed results might make changes.","code":""},{"path":"markdown.html","id":"background-to-rmarkdown","chapter":"7 Markdown","heading":"7.1 Background to Rmarkdown","text":"Markdown “language” allows write document using plain text, can converted html formats. specific R. Files written Markdown ‘.md’ extension.Markdown “language” allows write document using plain text, can converted html formats. specific R. Files written Markdown ‘.md’ extension.R Markdown: variation markdown specific R - allows write document using markdown produce text embed R code display outputs. R Markdown files ‘.Rmd’ extension.R Markdown: variation markdown specific R - allows write document using markdown produce text embed R code display outputs. R Markdown files ‘.Rmd’ extension.rmarkdown - package: used R render .Rmd file desired output. ’s focus converting markdown (text) syntax, also need…rmarkdown - package: used R render .Rmd file desired output. ’s focus converting markdown (text) syntax, also need…knitr: R package Xie (2021a) read code chunks, execute , ‘knit’ back document. tables graphs included alongside text.knitr: R package Xie (2021a) read code chunks, execute , ‘knit’ back document. tables graphs included alongside text.Pandoc: Finally, pandoc actually convert output word/pdf/powerpoint etc. software separate R installed automatically RStudio.Pandoc: Finally, pandoc actually convert output word/pdf/powerpoint etc. software separate R installed automatically RStudio.process happens background (need know steps!) involves feeding .Rmd file knitr, executes R code chunks creates new .md (Markdown) file includes R code rendered output..md file processed pandoc create finished product: Microsoft Word document, HTML file, Powerpoint document, pdf, etc.using RStudio Cloud - features pre-loaded - take R journey future install copy R RStudio computer might little setting get working (see Appendices).","code":""},{"path":"markdown.html","id":"starting-a-new-rmd-file","chapter":"7 Markdown","heading":"7.2 Starting a new Rmd file","text":"RStudio, open new R markdown file, start ‘File’, ‘New file’ ‘R markdown…’.R Studio give output options pick . example select “HTML” want create html document. title author names important. output document type want one , don’t worry - can just pick one change script later.","code":""},{"path":"markdown.html","id":"activity-1-make-an-rmarkdown-file","chapter":"7 Markdown","heading":"7.3 Activity 1: Make an Rmarkdown file","text":"\nTry first \"knit\" make document.\nCreate new Rmarkdown file. comes prepopulated example text code.Create new Rmarkdown file. comes prepopulated example text code.Save (without changes) location .Rproj file name contained_report_penguins.Rmd.Save (without changes) location .Rproj file name contained_report_penguins.Rmd.moved visualisation reproducible report making.moved visualisation reproducible report making.Try first knit just hit button watch work - see R code chunks processed.Try first knit just hit button watch work - see R code chunks processed.Read intro information learn Markdown works.Read intro information learn Markdown works.\nworking directory .rmd files little different working scripts.\n\n.Rmd file, working directory wherever Rmd file saved.\n\nexample .Rmd file subfolder ~/markdownfiles/markdown.Rmd code read_csv(\"data/data.csv\") within markdown look .csv file subfolder called data inside 'markdown' folder root project folder .RProj file lives.\n\ntwo options using .Rmd files\n\n\nput .Rmd file subfolder make sure lives directory .RProj file - way relative filepaths R scripts Rmarkdown files\n\n\nput .Rmd file subfolder make sure lives directory .RProj file - way relative filepaths R scripts Rmarkdown files\n\n\nUse package describe file locations - later\n\n\nUse package describe file locations - later\n","code":""},{"path":"markdown.html","id":"r-markdown-parts","chapter":"7 Markdown","heading":"7.4 R Markdown parts","text":"R Markdown document can edited RStudio just like standard R script. start new R Markdown script, RStudio tries helpful showing template explains different section R Markdown script.appears starting new Rmd script intended produce html output.can see, three basic components Rmd file:YAMLYAMLMarkdown textMarkdown textR code chunks.R code chunks.","code":""},{"path":"markdown.html","id":"yaml","chapter":"7 Markdown","heading":"7.4.1 YAML","text":"Referred ‘YAML metadata’ just ‘YAML’, recursive acronym stands \"YAML ain't Markdown Language\". found top R Markdown document. section script tell Rmd file type output produce, formatting preferences, metadata document title, author, date.example , clicked default output html file, can see YAML says output: html_document. However can also change say powerpoint_presentation word_document even pdf_document.\nCan edit YAML Rmarkdown file markdown folder name author, today's date title file called \"Penguins Palmer Archipelago, Antarctica\".\n","code":""},{"path":"markdown.html","id":"text","chapter":"7 Markdown","heading":"7.4.2 Text","text":"narrative document, including titles headings. written “markdown” language, used across many different software.core ways write text. See extensive documentation available R Markdown “cheatsheets” RStudio website4.","code":""},{"path":"markdown.html","id":"new-lines","chapter":"7 Markdown","heading":"7.4.2.1 New lines","text":"Uniquely R Markdown, initiate new line, enter *two spaces** end previous line Enter/Return.","code":""},{"path":"markdown.html","id":"text-emphasis","chapter":"7 Markdown","heading":"7.4.2.2 Text emphasis","text":"Surround normal text characters change appears output.Underscores (_text_) single asterisk (*text*) italiciseDouble asterisks (**text**) bold textBack-ticks (` text `) display text codeThe actual appearance font can set using specific templates (specified YAML metadata).","code":""},{"path":"markdown.html","id":"titles-and-headings","chapter":"7 Markdown","heading":"7.4.2.3 Titles and headings","text":"hash symbol text portion R Markdown script creates heading. different chunk R code script, hash symbol mechanism comment/annotate/de-activate, normal R script.Different heading levels established different numbers hash symbols start new line. One hash symbol title primary heading. Two hash symbols second-level heading. Third- fourth-level headings can made successively hash symbols.","code":"\n# First-level heading / Title\n\n## Second level heading  \n\n### Third-level heading\n"},{"path":"markdown.html","id":"bullets-and-numbering","chapter":"7 Markdown","heading":"7.4.2.4 Bullets and numbering","text":"Use asterisks (*) created bullets list. Finish previous sentence, enter two spaces, Enter/Return twice, start bullets. Include space asterisk bullet text. bullet enter two spaces Enter/Return. Sub-bullets work way indented. Numbers work way instead asterisk, write 1), 2), etc. R Markdown script text might look.bullets (two spaces colon):","code":"* Bullet 1 (followed by two spaces and Enter/Return)  \n* Bullet 2 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 1 (followed by two spaces and Enter/Return)  \n  * Sub-bullet 2 (followed by two spaces and Enter/Return)  "},{"path":"markdown.html","id":"code-chunks","chapter":"7 Markdown","heading":"7.4.3 Code Chunks","text":"Sections script dedicated running R code called “chunks”. may load packages, import data, perform actual data management visualisation. may many code chunks, can help organize R code parts, perhaps interspersed text. note: ‘chunks’ appear slightly different background colour narrative part document.chunk opened line starts three back-ticks, curly brackets contain parameters chunk { }. chunk ends three back-ticks.can create new chunk typing , using keyboard shortcut “Ctrl + Alt + ” (Cmd + Shift + r Mac), clicking green ‘insert new code chunk’ icon top script editor.\nnotes contents curly brackets { }:\n\nstart ‘r’ indicate language name within chunk R. possible include programming language chunks SQL, Python Bash.\n\nr can optionally write chunk “name” – necessary can help organise work. Note name chunks, ALWAYS use unique names else R complain try render.\n\nlanguage name optional chunk name put comma, can include options , written tag=value, :\n\n\neval = FALSE run R code\n\n\neval = FALSE run R code\n\n\necho = FALSE print chunk’s R source code output document\n\n\necho = FALSE print chunk’s R source code output document\n\n\nwarning = FALSE print warnings produced R code\n\n\nwarning = FALSE print warnings produced R code\n\n\nmessage = FALSE print messages produced R code\n\n\nmessage = FALSE print messages produced R code\n\n\ninclude = either TRUE/FALSE whether include chunk outputs (e.g. plots) document\n\n\ninclude = either TRUE/FALSE whether include chunk outputs (e.g. plots) document\n\n\n.width = .height = - size ouput e.g. .width = \"75%\"\n\n\n.width = .height = - size ouput e.g. .width = \"75%\"\n\n\nfig.align = \"center\" adjust figure aligned across page\n\n\nfig.align = \"center\" adjust figure aligned across page\n\n\nfig.show='hold' chunk prints multiple figures want printed next (pair .width = c(\"33%\", \"67%\").\n\n\nfig.show='hold' chunk prints multiple figures want printed next (pair .width = c(\"33%\", \"67%\").\nchunk header must written one lineTry avoid periods, underscores, spaces. Use hyphens ( - ) instead need separator.Read extensively knitr options here5.also two arrows top right chunk, useful run code within chunk, code prior chunks. Hover see .","code":"```{r}\ncode goes here\n```\n```{r optional-name , eval = TRUE, echo = FALSE}\n\n```"},{"path":"markdown.html","id":"activity-2-setting-code-chunks","chapter":"7 Markdown","heading":"7.5 Activity 2: Setting code chunks","text":"Question 1. global option document set show R code used render chunks FALSETRUEknitr::opts_chunk$set(echo = TRUE)Question 2. Options set individual code chunks override global options TRUEFALSEIn second chunk see echo = FALSE prevented code printed, see rendered outputQuestion 3. wanted see R code, output need select combo code chunk options? echo = TRUE, eval = TRUEecho = FALSE, eval = TRUEecho = TRUE, eval = FALSEecho = FALSE, eval = FALSE","code":""},{"path":"markdown.html","id":"global-options-1","chapter":"7 Markdown","heading":"7.5.1 Global options","text":"global options applied chunks script, can set within first R code chunk script.\nhandy know want majority code chunks behave way.\ninstance, outputs shown code chunk code , can include command R code chunk (set chunk include = false):\nGlobal options useful, code block can still individually set.\n","code":"\nknitr::opts_chunk$set(echo = FALSE) "},{"path":"markdown.html","id":"in-text-code","chapter":"7 Markdown","heading":"7.5.2 In-text code","text":"can also include minimal R code within back-ticks. Within back-ticks, begin code “r” space, RStudio knows evaluate code R code. See example .book printed `r Sys.Date()`typed -line within section otherwise Markdown text, knows produce r output instead:book printed 2023-03-14","code":""},{"path":"markdown.html","id":"activity-3-make-some-markdown-edits","chapter":"7 Markdown","heading":"7.6 Activity 3: Make some markdown edits","text":"\nadded -line code, try re-knitting .Rmd file.\n","code":""},{"path":"markdown.html","id":"activity-4-generating-a-self-contained-report-from-data","chapter":"7 Markdown","heading":"7.7 Activity 4: Generating a self-contained report from data","text":"relatively simple report, may elect organize R Markdown script “self-contained” involve external scripts.Set Rmd file 'read' penguins data file.Everything need run R markdown imported created within Rmd file, including code chunks package loading. “self-contained” approach appropriate need much data processing (e.g. brings clean semi-clean data file) rendering R Markdown take long.scenario, one logical organization R Markdown script might :Set global knitr optionsSet global knitr optionsLoad packagesLoad packagesImport dataImport dataProcess dataProcess dataProduce outputs (tables, plots, etc.)Produce outputs (tables, plots, etc.)Save outputs, applicable (.csv, .png, etc.)Save outputs, applicable (.csv, .png, etc.)","code":"```{r, include=FALSE}\n# GLOBAL KNITR OPTIONS ----\nknitr::opts_chunk$set(echo = TRUE)\n# ____________________----\n\n# PACKAGES ----\nlibrary(tidyverse)\n\n``````{r}\n# READ DATA ----\n\npenguins <- read_csv(\"data/penguins_raw.csv\")\n\nhead(penguins)\n\n```"},{"path":"markdown.html","id":"heuristic-file-paths-with-here","chapter":"7 Markdown","heading":"7.7.1 Heuristic file paths with here()","text":"package Müller (2020) function () (::()), make easy tell R find save files - essence, builds file paths. becomes especially useful dealing alternate filepaths generated .Rmd files, can used exporting/importing scripts, functions data.() works within R project:package first loaded within R project, places small file called “.” root folder R project “benchmark” “anchor”package first loaded within R project, places small file called “.” root folder R project “benchmark” “anchor”scripts, reference file R project’s sub-folders, use function () build file path relation anchorIn scripts, reference file R project’s sub-folders, use function () build file path relation anchorTo build file path, write names folders beyond root, within quotes, separated commas, finally ending file name file extension shown belowTo build file path, write names folders beyond root, within quotes, separated commas, finally ending file name file extension shown belowhere() file paths can used importing exportinghere() file paths can used importing exportingSo use () wrapped inside functions importing/exporting (like read_csv() ggsave()) include () can still use RProject location root directory 'knitting' Rmarkdown files, even markdown tidied away separate sub-folder.means previous relative filepaths replaced :\nTry replacing previous code examples re-knitting .Rmd file.\n\nmight want start using () now read export data scripts. Make sure consistent whether use () heuristic file paths relative file paths across .R .Rmd files project - otherwise might encounter errors.\n","code":"```{r, include=FALSE}\n# GLOBAL KNITR OPTIONS ----\nknitr::opts_chunk$set(echo = TRUE)\n# ____________________----\n\n# PACKAGES ----\nlibrary(tidyverse)\nlibrary(here)\n\n``````{r, include=FALSE}\n# READ DATA ----\n\npenguins <- read_csv(here(\"data\", \"penguins_raw.csv\"))\n\nhead(penguins)\n\n```"},{"path":"markdown.html","id":"activity-4-can-you-change-the-global-options-of-your-rmd-file-so-that-it-doesnt-display-any-code-warnings-or-messages","chapter":"7 Markdown","heading":"7.8 Activity 4: Can you change the global options of your Rmd file so that it doesn't display any code, warnings or messages?","text":"made edits chunk options try hitting 'knit' .","code":""},{"path":"markdown.html","id":"ggplot","chapter":"7 Markdown","heading":"7.9 ggplot","text":"","code":""},{"path":"markdown.html","id":"size-options-for-figures","chapter":"7 Markdown","heading":"7.9.1 Size options for figures","text":"Options fig.width fig.height enable set width height R produced figures. default value set 7 (inches). play options, prefer using one (fig.width) association another one, fig.asp, sets height--width ratio figure. ’s easier mind play ratio give width height separately. default value fig.asp NULL often set (0.8), often corresponds expected result.Size options figures produced R consequences relative sizes elements figures. ggplot2 figure, elements remain size defined used theme, whatever chosen size figure. Therefore huge size can lead small text vice versa.\nbase font size 11 pts default. can change base_size argument theme ’re using.\n\ncode likely produce error cause document fail knit. error message can work missing code causing ? Hint - difference column names asking ones actual spreadsheet just imported\nfind result like, ’ll need combine sizes set theme set chunk options. customised theme, default size (7) looks good .texts axis longer figures overloaded, can choose bigger size (8 9) relatively reduce figure elements. ’s worth noting text sizes, can also modify base size theme obtain similar figures.","code":"\n# snake_case names need to be made\n\npenguins <- janitor::clean_names(penguins)\npenguin_colours <- c(\"darkolivegreen4\", \"darkorchid3\", \"goldenrod1\")\n\nplot <- penguins %>% \n  ggplot(aes(x=flipper_length_mm, \n             y = body_mass_g))+\n  geom_point(aes(colour=species))+\n  scale_color_manual(values=penguin_colours)+\n  theme_minimal(base_size = 11)```{r fig.asp = 0.8, fig.width = 3}\nplot\n# figure elements are too big\n``````{r fig.asp = 0.8, fig.width = 10}\nplot\n# figure elements are too small\n``````{r fig.asp = 0.8, fig.width = 7}\nplot\n``````{r fig.asp = 0.8, fig.width = 7}\nplot + theme(base_size = 14)\n# figure width stays the same, but modify the text size in ggplot\n```"},{"path":"markdown.html","id":"size-of-final-figure-in-document","chapter":"7 Markdown","heading":"7.9.2 Size of final figure in document","text":"Figures made R R Markdown document exported (default png format) inserted final rendered document. Options .width .height enable us choose size figure final document.rare need re-scale height--width ratio figures produced R ratio kept modify one option therefore use .width. like use percentage define size output figures. example size set 50%","code":"```{r fig.asp = 0.8, fig.width = 7, out.width = \"50%\"}\nplot \n# The final rendered size of the image changes according to out.width\n```"},{"path":"markdown.html","id":"changing-default-values-of-chunk-options","chapter":"7 Markdown","heading":"7.9.3 Changing default values of chunk options","text":"can also change default values chunk options writing beginning R Markdown document.values applied chunks unless specify value chunk locally. can set values often used (differ default one) avoid repeating chunk.","code":"```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n fig.width = 6,\n fig.asp = 0.8,\n out.width = \"80%\"\n)\n```"},{"path":"markdown.html","id":"static-images","chapter":"7 Markdown","heading":"7.10 Static images","text":"can include images R Markdown several ways:knitr::include_graphics(\"path//image.png\")","code":"# choose ONE of these\nknitr::include_graphics(\"../images/darwin.png\")\n\nknitr::include_graphics(here(\"images\", \"darwin.png\")"},{"path":"markdown.html","id":"tables","chapter":"7 Markdown","heading":"7.11 Tables","text":"","code":""},{"path":"markdown.html","id":"markdown-tables","chapter":"7 Markdown","heading":"7.11.1 Markdown tables","text":"render ","code":"| Syntax      | Description |\n| ----------- | ----------- |\n| Header      | Title       |\n| Paragraph   | Text        |\n"},{"path":"markdown.html","id":"knitrkable","chapter":"7 Markdown","heading":"7.11.2 knitr::kable()","text":"create manage able objects, first pass data frame kable() function knitr package. package kableExtra Zhu (2020) gives us lots extra styling options.6\nCan get working? Add library call kableExtra first chunk Rmd file, make chunk bottom file hit knit test.\n\nTable 7.1: Mean Body mass (g) flipper length (mm) three species Penguin Palmer Archipelago\n","code":"\npenguins %>% \n  group_by(species) %>% \n  summarise(`Body Mass (g)`= mean(body_mass_g, na.rm = T),\n            `Flipper Length (mm)`= mean(flipper_length_mm, na.rm = T)) %>% \n  kbl(caption = \"Mean Body mass (g) and flipper length (mm) for three species of Penguin in the Palmer Archipelago\") %>% \n  kable_styling(bootstrap_options = \"striped\", full_width = F, position = \"left\")"},{"path":"markdown.html","id":"gt","chapter":"7 Markdown","heading":"7.11.3 gt()","text":"gt Iannone et al. (2021) package making simple produce nice-looking display tables HTML (work LaTex). lot customisation options.\nable see tables unless try re-knitting .Rmd file.\n","code":"\npenguins %>% \n    group_by(species) %>% \n    summarise(`Body Mass (g)`= mean(body_mass_g, na.rm = T),\n              `Flipper Length (mm)`= mean(flipper_length_mm, na.rm = T)) %>% gt::gt()"},{"path":"markdown.html","id":"source-files","chapter":"7 Markdown","heading":"7.12 Source files","text":"One variation “self-contained” approach R Markdown code chunks “source” (run) R scripts.can make R Markdown script less cluttered, simple, easier organize. can also help want display final figures beginning report.approach, final R Markdown script simply combines pre-processed outputs document. already used source() function feed R objects one script another, now can thing report.advantage data cleaning organising happens \"elsewhere\" need repeat code. make changes analysis scripts, reflected changes report next time compile (knit) .\ntry using () unless script dependencies ALSO use . knitting Rmd file treats absolute file path relative .Rmd file (even running scripts written outside document).\n\nusually simpler save .Rmd file place .RProj file\n","code":"source(\"scripts/your-script.R\")"},{"path":"markdown.html","id":"activity-5-connecting-scripts-and-reports","chapter":"7 Markdown","heading":"7.13 Activity 5: Connecting scripts and reports","text":"Create new Rmarkdown file.Create new Rmarkdown file.Save (without changes) folder .Rproj file call 03_linked_report_penguins.Rmd.Save (without changes) folder .Rproj file call 03_linked_report_penguins.Rmd.\nnow source pre-written scripts data loading wrangling R project, just use source command read script - can call objects made externally - case penguin plot - put code block hit knit.\n","code":"```{r setup, include=FALSE}\n# GLOBAL KNITR OPTIONS ----\nknitr::opts_chunk$set(echo = TRUE)\n# ____________________----\n\n# PACKAGES ----\nlibrary(tidyverse)\n\n\n``````{r read-data, include=FALSE}\n# READ DATA ----\n\nsource(\"scripts/02_visualisation_penguins.R\")\n\n```\n\n```{r figure, include=FALSE}\n\n (p1+p2)/p3+\n  plot_layout(guides = \"collect\") \n\n```"},{"path":"markdown.html","id":"activity-6-test-yourself","chapter":"7 Markdown","heading":"7.14 Activity 6: Test yourself","text":"make another reproducible report.Make new Rmarkdown RNotebook file YYYYMMDD_surname_5023Y_rmd_workshop.RmdMake new Rmarkdown RNotebook file YYYYMMDD_surname_5023Y_rmd_workshop.RmdMake summary figure want penguins data ggplotMake summary figure want penguins data ggplotMake summary table summarise make beautiful kableExtra gt()Make summary table summarise make beautiful kableExtra gt()Write sentences explaining presentingWrite sentences explaining presentingKnit report htmlKnit report htmlUse chunk options optimise figure layout text make raw code rendered outputs visible. example literate programmingUse chunk options optimise figure layout text make raw code rendered outputs visible. example literate programming","code":""},{"path":"markdown.html","id":"hygiene-tips","chapter":"7 Markdown","heading":"7.14.1 Hygiene tips","text":"recommend three chunks top documentGlobal chunk optionsGlobal chunk optionsAll packagesAll packagesReading dataReading data","code":"\n```{r setup , include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, \n                      fig.align = \"center\",\n                      fig.width = 6,\n                      fig.asp = 0.8,\n                      out.width = \"80%\n                      )\n                      \n```\n\n```{r library}\nlibrary(tidyverse)\n```\n\n```{r read-data}\nsource(\"scripts/02_visualisation_penguins.R\")\n```"},{"path":"markdown.html","id":"common-knit-issues","chapter":"7 Markdown","heading":"7.15 Common knit issues","text":"issues cause Rmd document fail knit entirety. failed knit usually easy fix, needs READ error message, little detective work.","code":""},{"path":"markdown.html","id":"duplication","chapter":"7 Markdown","heading":"7.15.1 Duplication","text":"","code":"\n```{r title-one}\n```\n\n```{r title-one}\n```"},{"path":"markdown.html","id":"not-the-right-order","chapter":"7 Markdown","heading":"7.15.2 Not the right order","text":"","code":"plot(my_table)\n\nmy_table <- table(mtcars$cyl)"},{"path":"markdown.html","id":"forgotten-trails","chapter":"7 Markdown","heading":"7.15.3 Forgotten trails","text":": Missing “,”, “(”, “}”, “’”","code":""},{"path":"markdown.html","id":"path-not-taken","chapter":"7 Markdown","heading":"7.15.4 Path not taken","text":"Rmd document different location .Rproj file causing issues relative filepaths","code":""},{"path":"markdown.html","id":"spolling","chapter":"7 Markdown","heading":"7.15.5 Spolling","text":"Incorrectly labelled chunk optionsIncorrectly labelled chunk optionsIncorrectly evaluated R codeIncorrectly evaluated R code","code":""},{"path":"markdown.html","id":"visual-editor","chapter":"7 Markdown","heading":"7.16 Visual editor","text":"RStudio comes pretty nifty Visual Markdown Editor includes:SpellcheckSpellcheckEasy table & equation insertionEasy table & equation insertionEasy citations reference list buildingEasy citations reference list buildingYou can switch modes button push, try !","code":""},{"path":"markdown.html","id":"activity-7-test-yourself-2","chapter":"7 Markdown","heading":"7.17 Activity 7: Test yourself","text":"\nSubmit final knitted report YYYYMMDD_surname_5023Y_rmd_workshop.html Blackboard\n\nmay need send zipped folder submission Blackboard portal\nFind doi palmerpenguins Horst et al. (2020) package, use visual editor easily include reference report.completed document reknit. Check output document original markdown file + project space.find new file project space .bib new conditions YAML?","code":""},{"path":"markdown.html","id":"summing-up-rmarkdown","chapter":"7 Markdown","heading":"7.18 Summing up Rmarkdown","text":"","code":""},{"path":"markdown.html","id":"what-we-learned-1","chapter":"7 Markdown","heading":"7.18.1 What we learned","text":"learnedHow use markdown knitrHow use markdown knitrHow embed R chunks, produce code, figures analysesHow embed R chunks, produce code, figures analysesHow organise projects hereHow organise projects hereHow knit pdf html outputsHow knit pdf html outputsHow make simple tablesHow make simple tablesHow size figure outputs documentsHow size figure outputs documents","code":""},{"path":"markdown.html","id":"further-reading-guides-and-tips","chapter":"7 Markdown","heading":"7.18.2 Further Reading, Guides and tips","text":"R Cheat SheetsR Cheat SheetsXie (2015) Dynamic documents RmarkdownXie (2015) Dynamic documents RmarkdownThe fully comprehensive guide(https://rmarkdown.rstudio.com/articles_intro.html)(https://rmarkdown.rstudio.com/authoring_quick_tour.html)","code":""},{"path":"github.html","id":"github","chapter":"8 Github","heading":"8 Github","text":"","code":""},{"path":"github.html","id":"lets-git-it-started","chapter":"8 Github","heading":"8.1 Let's Git it started","text":"Git version control system. Originally built help groups developers work collaboratively big software projects. helps us manage RStudio projects - tracked changes.Git GitHub big part data science community. can use GitHub number waysTo source code repurpose analyses built others usesTo source code repurpose analyses built others usesManage analysis projects parts :\n🔢 Data\n✍ ️Scripts\n📊 Figures\n📝 ReportsManage analysis projects parts :🔢 Data✍ ️Scripts📊 Figures📝 ReportsAre version controlled open accessVersion control lets recover mistakes & analysis backed externallyVersion control lets recover mistakes & analysis backed externallyWhen come publish reports - analysis accessible othersWhen come publish reports - analysis accessible othersBuild library projects show can Data ScienceBuild library projects show can Data Science","code":""},{"path":"github.html","id":"what-is-github","chapter":"8 Github","heading":"8.1.1 What is Github?","text":"Watch video today's session:","code":""},{"path":"github.html","id":"will-this-be-fun","chapter":"8 Github","heading":"8.1.2 Will this be fun?","text":".Using GitHub version control bit like cleaning teeth. exactly fun, good promotes excellent hygiene. also takes two minutes.talk projects GitHub refer Repositories / repos.Repos GitHub unit RStudio Project - place can easily store information/data/etc. related whatever project working .way set RStudio Projects now extra steps itMake new GitHub repository (fork existing one)Make new GitHub repository (fork existing one)Make New project RStudio Cloud - selecting GitHub Repository optionMake New project RStudio Cloud - selecting GitHub Repository optionClone GitHub repo RStudio ProjectClone GitHub repo RStudio ProjectMake sure RStudio Github can talk otherMake sure RStudio Github can talk otherGo normal business:Go normal business:comes saving files, also periodically make commit - takes multi-file snapshot entire projectWhen comes saving files, also periodically make commit - takes multi-file snapshot entire projectAt end session push changes GitHub.end session push changes GitHub.changes working RStudio feel little different first, quickly become routine - big step forward Data Science skills.","code":""},{"path":"github.html","id":"the-payoff","chapter":"8 Github","heading":"8.1.3 The Payoff","text":"portfolio: build library data science projects can show offA portfolio: build library data science projects can show offbe keen: track development R packages GitHUbbe keen: track development R packages GitHUbversion control: keep safe archive edits changesversion control: keep safe archive edits changesplay others: easy ways collaborate data science projectsplay others: easy ways collaborate data science projectsFor full rundown use Git R go wrong checking Happy Git","code":""},{"path":"github.html","id":"set-up-github","chapter":"8 Github","heading":"8.2 Set up GitHub","text":"First things first need set GitHub account.Head GitHub sign free account.\nMake careful note \n\n\nusername choose\n\n\nusername choose\n\n\nUse email signed RStudio Cloud \n\n\nUse email signed RStudio Cloud \n\n\nNote password carefully!\n\n\nNote password carefully!\n","code":""},{"path":"github.html","id":"activity-1-fork-clone-an-existing-repo-on-github-make-edits-push-back","chapter":"8 Github","heading":"8.3 Activity 1: Fork & clone an existing repo on GitHub, make edits, push back","text":". Go github.com log (need account - sign uea.ac.uk e-mail)b. Search bar, look repo Philip-Leftwich/5023Y-Happy-Gitc. Click repo name, look existing repo structured. FORK repo","code":""},{"path":"github.html","id":"what-the-hell-is-a-fork","chapter":"8 Github","heading":"8.3.1 What the hell is a fork?","text":"fork generate personal copy another user's repository.e. Press Clone/download copy URL, create new project RStudio Cloud selecting New project Git repository option - make sure 5023Y Workspacef. Open some_cool_animals.Rmd document, accompanying htmlg. Add name top documenth. WAIT. forgotten add great image facts important species - Baby Yoda, including image (file repo, info add ).FACTSAlso known \"Child\"Also known \"Child\"likes unfertilised frog eggs & control knobslikes unfertilised frog eggs & control knobsstrong forcestrong force\n \n\n \n. ’ve added Grogu, knit Rmd document update htmlj. Add Git credentials go section talking githubk. Stage, Commit & Push files (glossary)Staged - pick files intend bind commitCommit - write short descriptive message, binds changes single commitPush - \"Pushes\" changes local repo remote repo GitHub, (push)l. GitHub, refresh see files updated. Cool! Now ’ve used something someone else created, customized , saved updated version.","code":""},{"path":"github.html","id":"talking-to-github","chapter":"8 Github","heading":"8.4 Talking to GitHub","text":"Getting set talk GitHub can seem like pain. Eventually work computer - copy R & RStudio installed - . now use RStudio Cloud - looks like per project. takes seconds put commands directly console.Run first line console put GitHub username e-mail connected GitHub account.\nMake sure go RStudio Cloud profile > Authentication select Github Enabled & Private repo access also enabled\nneed give RStudio Cloud GitHub Personal Access Token, can retrieve going Github.com finding Settings > Developer Settings > Generate TokenSelect \"scopes\" name token.Make note need whenever set new project want talk GitHub. GitHub recently removed password authentication favour PATs, RStudio Cloud seem updated yet - ok though - just enter line code - copy+paste PAT prompted. - Option set/replace credentials.\nstart working computer, re-input PAT expires. RStudio Cloud works little differently.\n\ntheory need input PAT per project. Sometimes seems forget asks one session next. might want write somewhere.\n\nforget PAT - ok - retrieve - can just generate new one o Github.\n","code":"\nusethis::use_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\")\ngitcreds::gitcreds_set()"},{"path":"github.html","id":"see-changes","chapter":"8 Github","heading":"8.4.1 See changes","text":"first immediate benefit using GitHub RStudio Project seeing changes made since last commit.RStudio Git pane lists every file ’s added, modified deleted. icon describes change:changed file\nadded new file Git seen \ndeleted file\ncan get details changes made file right-clicking selecting diffThis opens new window highlighting differences current file previous commit.","code":""},{"path":"github.html","id":"how-to-use-version-control---when-to-commit-push-and-pull","chapter":"8 Github","heading":"8.5 How to use version control - when to commit, push and pull","text":"Repositories (repos) GitHub unit RStudio Project - place can easily store information/data/etc. related whatever project working .create Repository GitHub communicating Project RStudio, can changes moving two directionspull information GitHub RStudioorpush information RStudio GitHub safely stored /collaborators can access .Github also keeps complete history different versions file can accessed/reviewed collaborators time, anywhere, long internet.mentioned term commit times (8.11). fundamental unit work Git commit. commit takes snapshot code specified point time.create commit two stages:stage files, telling Git changes included next commit.stage files, telling Git changes included next commit.commit staged files, describing changes message.commit staged files, describing changes message.","code":""},{"path":"github.html","id":"stage","chapter":"8 Github","heading":"8.5.1 Stage","text":"\nstaging section allows finescale control files included commit. theory separate changes made different files different commitments.\nFirst save files, select files inclusion staging , tick checkbox select commit box.new window open 'Review Changes' - see diffs bottom pane, files selected latest commit.","code":""},{"path":"github.html","id":"commit","chapter":"8 Github","heading":"8.5.2 Commit","text":"new 'Review Changes' window see list files staged last window.click file name see changes made highlighted bottom panel. Added content highlighted green, removed content highlighted red.commit changes (take snapshot) must enter mandatory commit message \"commit message\" box.\nFigure 8.1: Green = added content, Red = deleted content\ncommit message short meaningful (collaborators)Describe , . Git stores associated differences commits, message doesn’t need say exactly changed - kept track Git. Instead provide summary focuses reasons change. Make understandable someone else!tradition enter first message new project \"First Commit\".click > commit, new window open summarises commit - can close \ncommit changes - simply saving new version file. committing exact line changes made, modifying files selected commit.\n","code":""},{"path":"github.html","id":"push","chapter":"8 Github","heading":"8.5.3 Push","text":"moment, commits local, order send GitHub select Push point github credentials need place - get prompted provide , close windows follow steps trying .git pane empty point - little message top detailing many commits ahead master repo GitHub. says branch one commits ahead master, commits still local pushed yet.confirm changes made project pushed Github, open GitHub page (get link Tools > Project Options > Git/SVN).see files listed, alongside file names see last commit message made commit.","code":""},{"path":"github.html","id":"a-couple-of-general-tips","chapter":"8 Github","heading":"8.5.4 A couple of general tips:","text":"\n\nPull start every session retrieves master repo GitHub - update end every session. helps prevent conflicts\n\n\nPull start every session retrieves master repo GitHub - update end every session. helps prevent conflicts\n\n\nCommit/push small, meaningful increments often. can make multiple commits session - always push end session\n\n\nCommit/push small, meaningful increments often. can make multiple commits session - always push end session\n\n\nway GitHub Repo becomes master copy project.\n\n\nway GitHub Repo becomes master copy project.\n","code":""},{"path":"github.html","id":"activity-2-github-classrooms-enabled-r-projects-with-subfolders","chapter":"8 Github","heading":"8.6 Activity 2: GitHub Classrooms enabled R Projects with subfolders","text":"GitHub Classrooms way set repos assigments - accept assignment GitHub Classroom automatically forks private repo .make regular commits pushes save work go - grading project repositories GitHub classrooms assignment work.\naccept assignment GitHub classrooms - repo appear main profile, belongs class rather . can always find searching Organisations - probably easiest just check URL Project Options RStudio\n. Follow invite linkb. invited sign-Github (already) & join UEABIO organisationc. Clone assignment work locally RStudio Cloud - 5023Y Workspaced. local project folder, create subfolders ‘data’ ‘figures’, 'scripts'.f. Open new .R script (.Rmd prefer practice )g. Attach tidyverse, janitor, optionally packagesh. Read infant_mortality.csv dataThis file look death rate every country world across six decades. See README informationi. Stage, commit & push point - notice empty folder ‘final_graphs’ doesn’t show (won’t commit empty folder) - set git credentials againj. Back script, write short script read clean data.script pre-written, puts data tidy format, cleans names, makes sure year treated date data filters four countries interest.Assign new objectk. Make ggplot plotting infant mortality rate countryHINT - use geom_line() remember separate countries colourl. Update graph direct labels (using annotate) vertical horizontal lines geom_vline geom_hline.m. Use ggsave() write graph .png ‘final_graphs’ subfoldern. Save, stage, commito one cool fun thing! make interactive version plot using plotly Sievert et al. (2021) just fun!p Now save, stage, commit & pushq. Check changes stored GitHub(NOTE organisations rather repos)Make sure finish exercises next week become GitHub pro!!!!!!!!!","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(plotly)\n\ninfant_mortality <- read_csv(\"data/infant_mortality.csv\") \n\nsubset_infant_mortality <- infant_mortality %>%\n  pivot_longer(cols=\"1960\":\"2020\", \n               names_to=\"year\",               \n               values_to=\"infant_mortality_rate\") %>%\n  mutate(year=lubridate::years(year)) %>% # set ymd format\n  mutate(year=lubridate::year(year)) %>% # extract year\n  janitor::clean_names() %>% # put names in snake case\n  filter(country_name %in% \n           c(\"United States\", \n             \"Japan\", \n             \"Afghanistan\", \n             \"United Kingdom\")) # extract four countries\n\n# View(subset_infant_mortality)\n\n# subset the date according to (US,UK, Japan = lowest infant death rates, Afghanistan = highest infant death rates)\nggplot(data = subset_infant_mortality) +\n  geom_line(aes(x = year,\n                 y = infant_mortality_rate,\n                 color = country_name))\nmortality_figure <- ggplot(data = subset_infant_mortality,\n                           aes(x = year,\n                 y = infant_mortality_rate,\n                 color = country_name)) +\n  geom_line() +\n  scale_color_manual(values = c(\"black\", \"blue\", \"magenta\", \"orange\")) +\n  annotate(geom = \"text\",\n           x = 2023,\n           y = 50,\n           label = \"Afghanistan\",\n           size = 4,\n           colour=\"black\") +\n    annotate(geom = \"text\",\n           x = 2023,\n           y = -2,\n           label = \"Japan\",\n           size = 4,\n           colour=\"blue\") +\n    annotate(geom = \"text\",\n           x = 2023,\n           y = 15,\n           label = \"United Kingdom\",\n           size = 4,\n           colour=\"orange\") +\n    annotate(geom = \"text\",\n           x = 2023,\n           y = 5,\n           label = \"United States\",\n           size = 4,\n           colour=\"magenta\") +\n  geom_vline(xintercept = 2000,\n             lty = 2) +\n  theme_minimal()+\n  theme(legend.position=\"none\")+\n  xlim(1970, 2025)+\n  labs(x=\"Year\",\n       y=\"Deaths per 100,000\")+\n  ggtitle(\"Mortality rate, infant (per 1,000 live births) \\nhas been steadily falling in Afghanistan from 1970 to present\")\nggsave(\"figures/infant mortality graph.png\", plot = mortality_figure, dpi=900, width = 7, height = 7)\nggplotly(mortality_figure, tooltip = c(\"infant_mortality_rate\"))\n## uses plotly package"},{"path":"github.html","id":"find-your-classroom-repos","chapter":"8 Github","heading":"8.7 Find your classroom repos","text":"work GitHub classrooms repos become part organisation UEABIO.want find repos GitHub can couple waysBookmark direct URL (noted ) first visit repoBookmark direct URL (noted ) first visit repoHead (https://github.com/UEABIO) - able see repos belong .Head (https://github.com/UEABIO) - able see repos belong .RStudio Cloud head Tools > Project Options > Git find URL.RStudio Cloud head Tools > Project Options > Git find URL.","code":""},{"path":"github.html","id":"git-history","chapter":"8 Github","heading":"8.8 Git History","text":"far used Git track, stage commit file changes GitHub. Now look briefly review changes want revert changes.","code":""},{"path":"github.html","id":"commit-history","chapter":"8 Github","heading":"8.8.1 Commit History","text":"view commit history RStudio, simply click 'History' button 🕒 Git Panel.window split two parts. top pane lists every commit made repository, associated messsages (top bottom, recent last).Click commit bottom pane shows changes made compared previous commit, also summary made commit, commit message date made.also SHA (Secure Hash Algorithm), unique identifier commit, Parent SHA identifies commit immediately preceded .can also review commit history Github clicking 'commits' link repository","code":""},{"path":"github.html","id":"reverting-changes","chapter":"8 Github","heading":"8.8.2 Reverting changes","text":"One powerful things Git ability revert previous versions files, made mistake, broke something, just changed mind!depends stage making changes. go scenarios turn.","code":""},{"path":"github.html","id":"changes-saved-but-not-staged-committed-or-pushed","chapter":"8 Github","heading":"8.8.2.1 Changes saved but not staged, committed or pushed","text":"saved changes file, yet staged , can click offending file Git pane select 'revert'. roll back file last 'commit' (warning reverting undone).Changes can made part file opening 'Diff' window. Select line wish discard double-clicking line select 'Discard line/chunk'","code":""},{"path":"github.html","id":"staged-but-not-committed","chapter":"8 Github","heading":"8.8.2.2 Staged but not committed","text":"Simply unclick staged check box, revert described .","code":""},{"path":"github.html","id":"staged-and-committed-but-not-pushed","chapter":"8 Github","heading":"8.8.2.3 Staged and committed but not pushed","text":"made mistake forgot include file last commit, can fix mistake, save changes tick box 'Amend previous commit' 'Review Changes' pane.want make change several commits ago two options:Option 1 - easier Git 🤷Look commit history RStudio - find commit want go back click 'View file @' button show file contents.Copy contents file clipboard paste current file. Save, stage, commit normal.Option 2 - Go Git history, find commit write SHA.Now go Terminal tab (next Console) typeThis might look something like thisThis command copy selected file past replace present. may asked want reload file now (say yes). stage, commit usual.","code":"git checkout <SHA> <filename>git checkout 2b4693d1 first_doc.Rmd"},{"path":"github.html","id":"staged-committed-and-pushed","chapter":"8 Github","heading":"8.8.2.4 Staged, committed and pushed","text":"use either strategies described , although using Terminal now better command git revert.First need identify SHA commit want revert . use git revert command Terminal. Adding ---commit option stops us deal intermediate commits. Adding ..HEAD tells GIT make old commit new/old \"HEAD\" lead project.","code":"git revert --no-commit d27e79f1..HEAD\n"},{"path":"github.html","id":"collaborate-with-git","chapter":"8 Github","heading":"8.9 Collaborate with Git","text":"GitHub great collaboration. can seem little scary complicated first, totally worth !Github works distributed system means person working project copy. Changes merged together remote repository GitHub.small projects can use exactly system . Everybody connects local repository remote one.Pull repository start session make sure working -date version.Pull repository start session make sure working -date version.Work aspect project, staging, committing pushing go.Work aspect project, staging, committing pushing go.small projects works well person files work , two people working file time can cause 'merge conflict'. bigger projects collaborator creates copy (fork) repository, pull request must sent owner main repository incorporate changes, includes review step changes integrated.","code":""},{"path":"github.html","id":"final-git-tips","chapter":"8 Github","heading":"8.10 Final Git tips","text":"Reminders:Commit often, push end sessionCommit often, push end sessionIf want track file repository (maybe working collaboration) can get Git ignore right-click selecting Ignore.want track file repository (maybe working collaboration) can get Git ignore right-click selecting Ignore.Check Github repo online make sure changes pushedCheck Github repo online make sure changes pushedIf goes wrong! trash project! ok, long GitHub repository online good final option delete RStudio project computer RStudio Cloud clone project GitHub !goes wrong! trash project! ok, long GitHub repository online good final option delete RStudio project computer RStudio Cloud clone project GitHub !","code":""},{"path":"github.html","id":"glossary-github","chapter":"8 Github","heading":"8.11 Glossary-GitHub","text":"","code":""},{"path":"github.html","id":"summing-up-github","chapter":"8 Github","heading":"8.12 Summing up GitHub","text":"","code":""},{"path":"github.html","id":"what-we-learned-2","chapter":"8 Github","heading":"8.12.1 What we learned","text":"learned:fork clone GitHub ProjectsHow fork clone GitHub ProjectsHow use GitHub classroomsHow use GitHub classroomsHow make RStudio GitHub talk otherHow make RStudio GitHub talk otherHow use version control, stage, commit pushHow use version control, stage, commit pushRemember bookmark Happy GitRemember bookmark Happy GitYou usedgitcreds Csárdi (2020)gitcreds Csárdi (2020)usethis Wickham et al. (2021)usethis Wickham et al. (2021)","code":""},{"path":"github.html","id":"sharing-a-github-repo---dealing-with-conflict-when-collaborating","chapter":"8 Github","heading":"8.13 Sharing a Github repo - Dealing with conflict when collaborating","text":"","code":""},{"path":"github.html","id":"how-to-avoid-a-conflict","chapter":"8 Github","heading":"8.13.1 How to avoid a conflict","text":"best simplest way avoid Github conflicts follow simple guidelines. two people sharing repo commit work usually go smoothly. However, try merge changes part file get merge conflict.see message like , first thing panic. Merge conflicts can easily fixed.can avoid merge conflicts altogether following simple organisation tips:Partition project, work independent R scripts, changes made one person affect files someone else working .Partition project, work independent R scripts, changes made one person affect files someone else working .Communicate - organise times one person might work shared file, two people work file timeCommunicate - organise times one person might work shared file, two people work file timeAlways Pull latest version repo start working, try pulling just push order collect latest changes & always push Github end session.Always Pull latest version repo start working, try pulling just push order collect latest changes & always push Github end session.","code":"git merge issue-5\n# Auto-merging index.html\n# CONFLICT (content): Merge conflict in index.html\n# Automatic merge failed; fix conflicts and then commit the result.\n"},{"path":"github.html","id":"dealing-with-a-conflict","chapter":"8 Github","heading":"8.13.2 Dealing with a conflict","text":"imagine made mistake two people tried push changes file time!second person trying push change Github get error\nFigure 8.2: Git conflict\nmessage says pull changes Github, generate different error mesage. case indicating merge conflict differences line file. Git pane, file now flagged orange 'U'. stands 'unresolved'\nFigure 8.3: git conflict\nresolve conflict, file now needs edited. Git flagged locations conflicts occurred <<<<<<<, ======= >>>>>>>. file needs edited merging appropriate changes file reads conflict markers removed.","code":""},{"path":"github.html","id":"commit-resolutions","chapter":"8 Github","heading":"8.13.3 Commit resolutions","text":"Proceed normal, commit file changes, change file orange U blue M push Github, collaborators need informed Pull updated repo get new changes.","code":""},{"path":"github.html","id":"try-and-create-and-solve-a-merge-error.","chapter":"8 Github","heading":"8.13.4 Try and create and solve a merge error.","text":"\nMerge Conflict Challenge part group try intentionally create merge conflict, go steps needed resolve issues continue developing merged files. See sections help steps:\n\nStep 0: Ensure starting project Step 1: Project co-ordinator makes change commits - small change README.md Step 2: Collaborator makes change commits line Step 3: Collaborator pushes file GitHub Step 4: Owner pushes changes gets error Step 5: Owner pulls GitHub get Collaborator changes Step 6: Owner edits file resolve conflict Step 7: Owner commits resolved changes Step 8: Owner pushes resolved changes GitHub Step 9: Collaborator pulls resolved changes GitHub Step 10: can view commit history\n","code":""},{"path":"github.html","id":"abort","chapter":"8 Github","heading":"8.13.5 Abort!","text":"Sometimes just made mistake. get merge conflict, repository placed ‘Merging’ state resolve . ’s commandline command abort merge altogether:terminal typeOf course, still haven’t synced collaborator’s changes, things still unresolved. least repository now usable local machine. Let know asap can fix issue","code":"git merge --abort"},{"path":"functions-1.html","id":"functions-1","chapter":"9 Functions","heading":"9 Functions","text":"\nToday's workshop can carried R project.\n\ntry set project Github open RStudio Cloud?\n\nFirst - go (https://github.com) log .\n\nNear repositories click big green \"New\" button.\n\nSet template, give name like \"Learning R functions\".\n\nInitialise project README create repository\n\nClick green \"Code\" button get link Clone repository RStudio Cloud.\ntime work R, use functions; often pre-written functions access baseR installed packages. can also write functions. Eventually even turn collection functions package (others).Functions make easy use sets code instructions repeatedly (without filling scripts code underlying function) help us carry multiple tasks single step without go details steps executed.","code":""},{"path":"functions-1.html","id":"structuring-a-function","chapter":"9 Functions","heading":"9.1 Structuring a function","text":"R makes easy create user defined functions using function(). works:Give function object name assign function , e.g. my_function_name <- function().Give function object name assign function , e.g. my_function_name <- function().Within parentheses specify inputs arguments just like pre-written functions work, e.g. function(my_args).Within parentheses specify inputs arguments just like pre-written functions work, e.g. function(my_args).Next, put code want function execute inside curly brackets like : function(my_args) {code run}Next, put code want function execute inside curly brackets like : function(my_args) {code run}Use return() specify want function output done running code.Use return() specify want function output done running code.","code":"\nmy_function_name <- function(my_args) {\n  # code to run\n  # return (some value)\n}"},{"path":"functions-1.html","id":"activity-1-understand-the-function","chapter":"9 Functions","heading":"9.2 Activity 1: Understand the function","text":"simple function. Can guess ?value get running function ? Now try applying function vector:see worked element inside vector. emphasises R vector based language (default apply functions elements object).","code":"\nadd_one <- function(input_data) {\n  return(input_data + 1)\n}\nadd_one(10)## [1] 11\nnumber_series <- c(1,5,10)"},{"path":"functions-1.html","id":"activity-2-write-your-own-function","chapter":"9 Functions","heading":"9.3 Activity 2: Write your own function:","text":"’ve started writing function square values, sum divide n-1. take square root, use sqrt() function.’ve started writing function square values, sum divide n-1. take square root, use sqrt() function.Complete function filling input_data sqrt(), filling remaining empty parentheses appropriate object names.Complete function filling input_data sqrt(), filling remaining empty parentheses appropriate object names.Now test function number_series vector (vector like).Now test function number_series vector (vector like).function retruning applied vector? standard deviationvariancesum squares\ngeneral rule thumb. end repeating line code three times script - write function work instead. write clear comments use!\n\n?\n\nreduces numbers lines code script, reduces amount repetition code, need make changes can change function without hunt code.\n\nreally good way organise functions organise separate script rest analysis. Write functions separate script use source(\"scripts/functions.R\")\n","code":"\n# Use the instructions above to complete the function below\nvariance <- function(input_data){\n  square <- sqrt(__)\n  ss <- sum(__)\n  variance <- (__/(length(__)-1))\n  return(__)\n}\n\n# Use vector (or make a new one) and try out your new function\n\n\nvariance(number_series)\n\nvariance <- function(input_data){\n     square <- sqrt(input_data)\n     ss <- sum(square)\n     variance <- (ss/length(input_data-1))\n     return(variance)\n}"},{"path":"functions-1.html","id":"argument-defaults","chapter":"9 Functions","heading":"9.4 Argument defaults","text":"example simple function just prints string \"Hello World\" whenever type function say_hello()","code":"\nsay_hello <- function(){\n  paste(\"Hello World\") \n}\n\nsay_hello()## [1] \"Hello World\""},{"path":"functions-1.html","id":"activity-3-understand-arguments","chapter":"9 Functions","heading":"9.4.1 Activity 3: Understand arguments","text":"happens try put something brackets using function?Now lets try similar function, include argument:example included argument function. now requires value provided order work.","code":"\nsay_morning <- function(x){\n  paste(\"Good morning\", x)\n}\n\n#  what about this one?\nsay_morning(\"Phil\")## [1] \"Good morning Phil\"Error in paste(\"Good morning\", x) : \n  argument \"x\" is missing, with no default"},{"path":"functions-1.html","id":"argument-defaults-1","chapter":"9 Functions","heading":"9.4.1.1 Argument defaults","text":"However, probably used idea many functions \"default\" values arguments, can easily set .\nnow default value supplied argument, still able changed running function. Try !\n","code":"\nsay_morning_default <- function(name = \"you\"){\n  paste(\"Good morning\", name)\n}\n\nsay_morning_default()## [1] \"Good morning you\""},{"path":"functions-1.html","id":"conditonal-functions","chapter":"9 Functions","heading":"9.5 Conditonal functions","text":"make function reports p-values APA format (\"p = [rounded value]\" p >= .001 \"p < .001\" p < .001).can add default value argument. argument skipped, function uses default argument.First make function rounds value three digits.like conditional response well: need else statement (if_else)","code":"\nreport_p <- function(p, digits = 3) {\n      roundp <- round(p, digits)\n    reported <-  paste(\"p =\", roundp)\n    \n    return(reported)\n}\n report_p <- function(p, digits = 3) {\n     reported <- if_else(p < 0.001,\n             \"p < 0.001\",\n             paste(\"p=\", round(p, digits)))\n     \n     return(reported)\n }\nreport_p <- function(p, digits = 3) {\n  if (p < .001) {\n    reported = \"p < .001\"\n  } else {\n    roundp <- round(p, digits)\n    reported = paste(\"p =\", roundp)\n  }\n  \n  return(reported)\n}"},{"path":"functions-1.html","id":"scope","chapter":"9 Functions","heading":"9.6 Scope","text":"Note objects created inside function, stay function. possible variables name (one inside function, one R environment). Changing values one effect .","code":""},{"path":"functions-1.html","id":"warnings-and-errors","chapter":"9 Functions","heading":"9.7 Warnings and errors","text":"\nhappens omit argument p, set value 1.5 character \"\"?\nSometimes function run, first example provide argument default.p = 1.5 probably run (p = 1.5 makes sense), !p = \"\" warning perhaps intuitive one.can make custom/specific warnings, try run arguments !","code":"\n report_p <- function(p, digits = 3) {\n   \n  if (!is.numeric(p)) stop(\"p must be a number\")\n  if (p <= 0) warning(\"p-values cannot less 0\")\n  if (p >= 1) warning(\"p-values cannot be greater than 1\")\n   \n     reported <- if_else(p < 0.001,\n             \"p < 0.001\",\n             paste(\"p=\", round(p, digits)))\n     return(reported)\n}"},{"path":"functions-1.html","id":"anonymous-functions","chapter":"9 Functions","heading":"9.8 Anonymous functions","text":"Anonymous functions ones function definiton bound R object. function may created used never assigned variable. normally encounter \"wild\", may quite common used Iteration (see next chapter).","code":"\nfunction(input_data) {\n  return(input_data + 1)\n}"},{"path":"functions-1.html","id":"activity-3-stretch-exercise","chapter":"9 Functions","heading":"9.9 Activity 3 : Stretch Exercise","text":"going try write custom function called find_largest_male(), used identify largest male Drosophila small dataset.","code":"\n# Make some fake data into a tibble\n\nvial <- (c((1:10),(1:10)))\nsex <- (c(rep(\"male\",10),rep(\"female\", 10)))\nweight_mg <- c(rnorm(10, mean=0.2, sd=0.02), rnorm(10, mean=0.21, sd=0.01))\n\ndros_weight <- tibble(vial, sex, weight_mg)"},{"path":"functions-1.html","id":"step-1.","chapter":"9 Functions","heading":"9.9.0.1 Step 1.","text":"functions use extract heaviest male dataset? Try think first.","code":"\n  dros_weight %>% \n    filter(sex == \"male\") %>% \n    arrange(., desc(weight_mg)) %>% \n    head(., n=1)"},{"path":"functions-1.html","id":"step-2.","chapter":"9 Functions","heading":"9.9.0.2 Step 2.","text":"Abstract lines code make function. remove data introduce placeholder instead?","code":"\nfind_largest_male <- function(df){ \n  df %>% \n    filter(sex == \"male\") %>% \n    arrange(., desc(weight_mg)) %>% \n    head(., n=1)\n}"},{"path":"functions-1.html","id":"step-3.","chapter":"9 Functions","heading":"9.9.0.3 Step 3.","text":"Now basic function can work refine extend .made function pick largest Drosophila overall, filter male female depending need?extend return one value requested?make argument except one value potential default use c(\"male\", \"female\")","code":"\nfind_largest_fly <- function(df,  n=1, s=c(\"male\", \"female\") ){ \n  df %>% \n    filter(sex == s) %>% \n    arrange(., desc(weight_mg)) %>% \n    head(., n=n)\n}"},{"path":"functions-1.html","id":"step-4.-stretch-exercise","chapter":"9 Functions","heading":"9.9.0.4 Step 4. Stretch exercise","text":"Can add useful warning messages? Perhaps fruitfly weight 0.4mg unusual value? warnings wrong types data supplied .numeric?","code":""},{"path":"functions-1.html","id":"activity-4-custom-ggplot-themes","chapter":"9 Functions","heading":"9.10 Activity 4: Custom ggplot themes","text":"often case start default particular 'style' figures, may making several similar figures within research paper. Creating custom functions can extend making custom ggplot themes. probably already used theme variants theme_bw(), theme_void(), theme_minimal() - incredibly useful, might find still wish make consistent changes.plot can make dros_weight tibble:addition title theme_classic() can improve style quicklyBut still want make changes, rather work one figure, potentially repeat several times subsequent figures, can decide make new function instead. See full breakdown arguments theme() function.\nNote using pre-set theme, modifying , important get order syntax correct e.g\n\ntheme_classic + theme() # correct\n\ntheme() + theme_classic() # work intended\nfunction set, can now use many figures wish. use future probably save unique script, clear title comments future use.easily use source(\"custom_theme_function.R\") make available scripts using.\nFunctions 'abstracting' command, can used . trouble writing function, start writing standard set commands solve specific problem. work backwards turn function.\n","code":"\nplot <- dros_weight %>% \n  ggplot(aes(x=sex,\n         y=weight_mg))+\n  geom_jitter(width = 0.1)\n\nplot\nplot+\n  ggtitle(\"Comparison of weights (mg) between \\nmale and female Drosophila\")+\n  theme_classic()\n# custom theme sets defaults for font and size, but these can be changed without changing the function\ntheme_custom <- function(base_size=12, base_family=\"serif\"){\n  theme_classic(base_size = base_size, \n                base_family = base_family,\n                ) +\n# update theme minimal \ntheme(\n  # specify default settings for plot titles - use rel to set titles relative to base size\n  plot.title=element_text(size=rel(1.5),\n      face=\"bold\",\n      family=base_family),\n  #specify defaults for axis titles\n  axis.title=element_text(\n    size=rel(1),\n    family=base_family),\n  # specify position for y axis title\n  axis.title.y=element_text(margin = margin(r = 10, l= 10)),\n  # specify position for x axis title\n  axis.title.x = element_text(margin = margin( t = 10, b = 10)),\n  # set major y grid lines\n  panel.grid.major.y = element_line(colour=\"gray\", size=0.5),\n  # add axis lines\n  axis.line=element_line(),\n   # Adding a 0.5cm margin around the plot\n  plot.margin = unit(c(0.2, 0.5, 0.5, 0.5), units = , \"cm\"),    \n   # Setting the font for the legend text\n  legend.text = element_text(face = \"italic\"),   \n    # Removing the legend title\n          legend.title = element_blank(),    \n   # Setting the position for the legend - 0 is left/bottom, 1 is top/right\n          legend.position = c(0.9, 0.8)             \n)\n  \n}\nplot+\ntheme_custom()"},{"path":"functions-1.html","id":"writing-packages","chapter":"9 Functions","heading":"9.11 Writing Packages","text":"familiar now idea R packages add data functions workspace. bundles code anyone can write, commonly downloading packages CRAN. However development stage packages can also downloaded directly GitHub.previous section walked basic writing new functions. can save R scripts move project project. choose write documented R package.\ntutorial shows just . Writing packages useful thing , even think person ever use , easily access functions across different workspaces projects.","code":""},{"path":"functions-1.html","id":"resources","chapter":"9 Functions","heading":"9.12 Resources","text":"R4DS: Functions","code":""},{"path":"data-insights-part-one.html","id":"data-insights-part-one","chapter":"10 Data Insights part one","heading":"10 Data Insights part one","text":"last chapters concentrating generating insights data using visualisations descriptive statistics. easiest way use questions tools guide investigation. ask question, question focuses attention specific part dataset helps decide graphs, models, transformations make.exercise propose task generate insights body mass penguins, order answer questionHow body mass associated bill length depth penguins?order answer question properly first understand different variables might relate .Distribution data typesCentral tendencyRelationship variablesConfounding variablesThis inevitably leads variety questions. new question ask expose new aspect data.","code":""},{"path":"data-insights-part-one.html","id":"data-wrangling","chapter":"10 Data Insights part one","heading":"10.0.1 Data wrangling","text":"Importantly already generated understanding variables contained within dataset data wrangling steps. Including:number variablesThe number variablesThe data format variableThe data format variableChecked missing dataChecked missing dataChecked typos, duplications data errorsChecked typos, duplications data errorsCleaned column factor namesCleaned column factor names\nimportant lose site questions asking\n\nalso play close attention data, remind frequently many variables names?\n\nmany rows/observations ?\n\nPay close attention outputs, errors warnings R console.\n","code":""},{"path":"data-insights-part-one.html","id":"variable-types","chapter":"10 Data Insights part one","heading":"10.1 Variable types","text":"quick refresher:","code":""},{"path":"data-insights-part-one.html","id":"numerical","chapter":"10 Data Insights part one","heading":"10.1.1 Numerical","text":"already familiar concepts numerical categorical data. Numeric variables values describe measure quantity. also known quantitative data. can subdivide numerical data :Continuous numeric variables. observations can take value within range numbers. Examples might include body mass (g), age, temperature flipper length (mm).\ntheory values can numbers, within dataset likely bounded (set within minimum/maximum observed measurable values), accuracy may precise measurement protocol allows.tibble represented header <dbl>.Discrete numeric variables Observations numeric restricted whole values e.g. 1,2,3,4,5 etc. also known integers. Discrete variables include number individuals population, number eggs laid etc. Anything make sense describe fractions e.g. penguin lay 2 half eggs. Counting!tibble represented header <int>.","code":""},{"path":"data-insights-part-one.html","id":"categorical","chapter":"10 Data Insights part one","heading":"10.1.2 Categorical","text":"Values describe characteristic data 'type' 'category'. Categorical variables mutually exclusive - one observation able fall two categories - exhaustive - data fit category (NA - recorded). Categorical variables qualitative, often represented non-numeric values words. bad idea represent categorical variables numbers (R treat correctly). Categorical variables can defined :Nominal variables Observations can take values logically ordered. Examples include Species Sex Penguins data.\ntibble represented header <chr>.Nominal variables Observations can take values logically ordered. Examples include Species Sex Penguins data.\ntibble represented header <chr>.Ordinal variables Observations can take values can logically ordered ranked. Examples include - activity levels (sedentary, moderately active, active); size classes (small, medium, large).Ordinal variables Observations can take values can logically ordered ranked. Examples include - activity levels (sedentary, moderately active, active); size classes (small, medium, large).coded manually see Factors, represented tibble header <fct>important order Ordinal variables logical order value plotting data visuals tables. Nominal variables flexible ordered whatever pattern works best data ( default plot alphabetically, perhaps order according values another numeric variable).","code":""},{"path":"data-insights-part-one.html","id":"quick-view-of-variables","chapter":"10 Data Insights part one","heading":"10.2 Quick view of variables","text":"take look variables, functions give quick snapshot overview.can see bill length contains numbers, many fractions, 0.1mm. comparison body mass appear discrete number variables. make body mass integer? underlying quantity (bodyweight) clearly continuous, clearly possible penguin weigh 3330.7g might look like integer way measured. illustrates importance understanding type variable working - just looking values enough.hand, choose measure record data can change way presented dataset. researchers decided simply record small, medium large classes bodyweight, dealing ordinal categorical variables (factors). distinctions can become less clear start deal multiple classes ordinal categories - example researchers measuring body mass nearest 10g. might reasonable treat integers...","code":"\nglimpse(penguins)\nsummary(penguins)"},{"path":"data-insights-part-one.html","id":"categorical-variables","chapter":"10 Data Insights part one","heading":"10.3 Categorical variables","text":"","code":""},{"path":"data-insights-part-one.html","id":"frequency","chapter":"10 Data Insights part one","heading":"10.3.1 Frequency","text":"might useful us make quick data summaries , like relative frequencySo 44% sample made observations Adelie penguins. comes making summaries categorical data, best can , can make observations common categorical observations, relative proportions.chart ok - can make anything better?go stacked bar approachThis graph OK great, height section bar represents relative proportions species dataset, type chart becomes increasingly difficult read categories included. Colours become increasingly samey,difficult read y-axis category starts stops, subtraction work values.best graph probably first one made - minor tweak can rapidly improve .example figure might use report paper. cleaned theme, added simple colour, made sure labels clear descriptive, ordered categories ascending frequency order, included simple text percentages aid readability.","code":"\npenguins %>% \n  group_by(species) %>% \n  summarise(n = n())\nprob_obs_species <- penguins %>% \n  group_by(species) %>% \n  summarise(n = n()) %>% \n  mutate(prob_obs = n/sum(n))\n\nprob_obs_species\npenguins %>% \n  ggplot()+\n  geom_bar(aes(x=species))\npenguins %>% \n  ggplot(aes(x=\"\",\n             fill=species))+ \n  # specify fill = species to ensure colours are defined by species\n  geom_bar(position=\"fill\")+ \n  # specify fill forces geom_bar to calculate percentages\n  scale_y_continuous(labels=scales::percent)+ \n  #use scales package to turn y axis into percentages easily\n  labs(x=\"\",\n       y=\"\")+\n  theme_minimal()\npenguins %>% \n  mutate(species=factor(species, levels=c(\"Adelie\",\n                                          \"Gentoo\",\n                                          \"Chinstrap\"))) %>% \n  # set as factor and provide levels\n  ggplot()+\n  geom_bar(aes(x=species),\n           fill=\"steelblue\",\n           width=0.8)+\n  labs(x=\"Species\",\n       y = \"Number of observations\")+\n  geom_text(data=prob_obs_species,\n            aes(y=(n+10),\n                x=species,\n                label=scales::percent(prob_obs)))+\n  coord_flip()+\n  theme_minimal()"},{"path":"data-insights-part-one.html","id":"two-categorical-variables","chapter":"10 Data Insights part one","heading":"10.3.2 Two categorical variables","text":"Understanding frequency broken species sex might useful information .","code":"\npenguins %>% \n  group_by(species, sex) %>% \n  summarise(n = n()) %>% \n  mutate(prob_obs = n/sum(n))"},{"path":"data-insights-part-one.html","id":"continuous-variables","chapter":"10 Data Insights part one","heading":"10.4 Continuous variables","text":"","code":""},{"path":"data-insights-part-one.html","id":"visualising-distributions","chapter":"10 Data Insights part one","heading":"10.4.1 Visualising distributions","text":"Variation tendency values variable change measurement measurement. can see variation easily real life; measure continuous variable twice, get two different results. true even measure quantities constant, like speed light. measurements include small amount error varies measurement measurement. Every variable pattern variation, can reveal interesting information. best way understand pattern visualise distribution variable’s values.script plot frequency distribution, specify x variable, intend plot histogram, y variable always count observations. ask data presented 10 equally sized bins data. case chopping x axis range 10 equal parts counting number observations fall within one.\nChange value specified bins argument observe figure changes. usually good idea try one set bins order better insights data\nget data, combine data collected summary() function histogram hereWhich values common? < 3500g3500-4000g4000-4500g4500-5000g5000-5500g5500-6000g>6500gWhich values common? < 3500g3500-4000g4000-4500g4500-5000g5000-5500g5500-6000g>6500gWhich values rare? ? match expectations?\n< 3500g3500-4000g4000-4500g4500-5000g5000-5500g5500-6000g>6500gWhich values rare? ? match expectations?\n< 3500g3500-4000g4000-4500g4500-5000g5000-5500g5500-6000g>6500gCan see unusual patterns? YesNoCan see unusual patterns? YesNoHow many observations missing body mass information? many observations missing body mass information? Penguins weighing less 3kg 6kg rare.\ncommon weight appears just 4kg.","code":"\npenguins %>% \n  ggplot()+\n  geom_histogram(aes(x=body_mass_g),\n                 bins=10)"},{"path":"data-insights-part-one.html","id":"atypical-values","chapter":"10 Data Insights part one","heading":"10.4.1.1 Atypical values","text":"found atypical values point, decide exclude dataset (using filter()). stage strong reason believing mistake data entry, rather true outlier.","code":""},{"path":"data-insights-part-one.html","id":"central-tendency","chapter":"10 Data Insights part one","heading":"10.4.2 Central tendency","text":"Central tendency descriptive summary dataset single value reflects center data distribution. three widely used measures central tendency mean, median mode.mean defined sum values variable divided total number values. median middle value. N odd N even, average two middle values. mode frequently occurring observation data set, arguable least useful understanding biological datasets.can find mean median easily summarise function. mean usually best measure central tendency distribution symmetrical, mode best measure distribution asymmetrical/skewed.\nFigure 10.1: Red dashed line represents mean, Black dashed line median value\n","code":"\npenguin_body_mass_summary <- penguins %>% \n    summarise(mean_body_mass=mean(body_mass_g, na.rm=T), \n              sd = sd(body_mass_g, na.rm = T),\n              median_body_mass=median(body_mass_g, na.rm=T), \n              iqr = IQR(body_mass_g, na.rm = T))\n\npenguin_body_mass_summary\npenguins %>% \nggplot()+\n  geom_histogram(aes(x=body_mass_g),\n               alpha=0.8,\n               bins = 10,\n               fill=\"steelblue\",\n               colour=\"darkgrey\")+\n   geom_vline(data=penguin_body_mass_summary,\n             aes(xintercept=mean_body_mass),\n             colour=\"red\",\n             linetype=\"dashed\")+\n     geom_vline(data=penguin_body_mass_summary,\n             aes(xintercept=median_body_mass),\n             colour=\"black\",\n             linetype=\"dashed\")+\n  labs(x = \"Body mass (g)\",\n       y = \"Count\")+\n  theme_classic()"},{"path":"data-insights-part-one.html","id":"normal-distribution","chapter":"10 Data Insights part one","heading":"10.4.3 Normal distribution","text":"histogram can likely already tell whether normally distributed data.\nNormal distribution, also known \"Gaussian distribution\", probability distribution symmetric mean, showing data near mean frequent occurrence data far mean. graphical form, normal distribution appears \"bell curve\".\ndata follows normal distribution, can predict spread data, likelihood observing datapoint given value mean standard deviation.can simulate normally distributed dataset look like sample size, mean standard deviation.","code":"\nnorm_mass <- rnorm(n = 344,\n      mean = 4201.754,\n      sd = 801.9545) %>% \n  as_tibble()\n\nnorm_mass %>% \n  as_tibble() %>% \n  ggplot()+\n  geom_histogram(aes(x = value),\n                 bins = 10)"},{"path":"data-insights-part-one.html","id":"qq-plot","chapter":"10 Data Insights part one","heading":"10.4.3.1 QQ-plot","text":"QQ plot classic way checking whether sample distribution another (theoretical distribution). look bit odd first, actually fairly easy understand, useful! qqplot distributes data y-axis, theoretical normal distribution x-axis. residuals follow normal distribution, meet produce perfect diagonal line across plot.Watch video see QQ plots explained\nFigure 10.2: Examples qqplots different deviations normal distribution\nexample can see residuals can explained normal distribution, except low end data.fit perfect, also terrible!know much deviation idealised distribution ok?qqPlot() function R package car provides 95% confidence interval margins help determine severely quantiles deviate idealised distribution.information qqPlot section distribution deviates clearly normal distribution <3500g3500-4000g4000-4500g5000-5500g>5500g","code":"\nggplot(penguins, aes(sample = body_mass_g))+\n  stat_qq() + \n  stat_qq_line()\npenguins %>% \n  pull(body_mass_g) %>% \n  car::qqPlot()## [1] 170 186"},{"path":"data-insights-part-one.html","id":"variation","chapter":"10 Data Insights part one","heading":"10.4.4 Variation","text":"Dispersion (spread data ) important component towards understanding numeric variable. measures central tendency used estimate central value dataset, measures dispersion important describing spread data.Two data sets can equal mean (, measure central tendency) vastly different variability.Important measures dispersion range, interquartile range, variance standard deviation.range defined difference highest lowest values dataset. disadvantage defining range measure dispersion take account values calculation.range defined difference highest lowest values dataset. disadvantage defining range measure dispersion take account values calculation.interquartile range defined difference third quartile denoted 𝑸_𝟑 lower quartile denoted 𝑸_𝟏 . 75% observations lie third quartile 25% observations lie first quartile.interquartile range defined difference third quartile denoted 𝑸_𝟑 lower quartile denoted 𝑸_𝟏 . 75% observations lie third quartile 25% observations lie first quartile.Variance defined sum squares deviations mean, divided total number observations. standard deviation positive square root variance. standard deviation preferred instead variance units original values.Variance defined sum squares deviations mean, divided total number observations. standard deviation positive square root variance. standard deviation preferred instead variance units original values.","code":""},{"path":"data-insights-part-one.html","id":"interquartile-range","chapter":"10 Data Insights part one","heading":"10.4.4.1 Interquartile range","text":"used IQR function summarise() find interquartile range body mass variable.IQR also useful applied summary plots 'box whisker plots'. can also calculate values IQR margins, add labels scales Wickham & Seidel (2020).can see IQR obtained subtracting body mass tht 75% quantile 25% quantile (4750-3550 = 1200).","code":"\npenguins %>%\n  summarise(q_body_mass = quantile(body_mass_g, c(0.25, 0.5, 0.75), na.rm=TRUE),\n            quantile = scales::percent(c(0.25, 0.5, 0.75))) # scales package allows easy converting from data values to perceptual properties"},{"path":"data-insights-part-one.html","id":"standard-deviation","chapter":"10 Data Insights part one","heading":"10.4.4.2 Standard deviation","text":"standard deviation (\\(s\\)) measure dispersed data relation mean. Low standard deviation means data clustered around mean, high standard deviation indicates data spread . makes sense use mean good measure central tendency.\n\\(\\sigma\\) = known population standard deviation\n\n\\(s\\) = sample standard deviation\n","code":"penguins %>% \n  summarise(mean = mean(body_mass_g),\n            sd = sd(body_mass_g),\n            n = n())"},{"path":"data-insights-part-one.html","id":"visualising-dispersion","chapter":"10 Data Insights part one","heading":"10.4.5 Visualising dispersion","text":"\nFigure 10.3: Visualising dispersion different figures\nnow several compact representations body_mass_g including histogram, boxplot summary calculations. can generate summaries numeric variables. tables graphs provide detail need understand central tendency dispersion numeric variables.","code":"\ncolour_fill <- \"darkorange\"\ncolour_line <- \"steelblue\"\nlims <- c(0,7000)\n\nbody_weight_plot <- function(){\n  \n  penguins %>% \n  ggplot(aes(x=\"\",\n             y= body_mass_g))+\n  labs(x= \" \",\n       y = \"Mass (g)\")+\n  scale_y_continuous(limits = lims)+\n    theme_minimal()\n}\n\nplot_1 <- body_weight_plot()+\n  geom_jitter(fill = colour_fill,\n               colour = colour_line,\n               width = 0.2,\n              shape = 21)\n\nplot_2 <- body_weight_plot()+\n  geom_boxplot(fill = colour_fill,\n               colour = colour_line,\n               width = 0.4)\n\nplot_3 <- penguin_body_mass_summary %>% \n  ggplot(aes(x = \" \",\n             y = mean_body_mass))+\n  geom_bar(stat = \"identity\",\n           fill = colour_fill,\n           colour = colour_line,\n               width = 0.2)+\n  geom_errorbar(data = penguin_body_mass_summary,\n                aes(ymin = mean_body_mass - sd,\n                    ymax = mean_body_mass + sd),\n                colour = colour_line,\n                width = 0.1)+\n  labs(x = \" \",\n       y = \"Body mass (g)\")+\n  scale_y_continuous(limits = lims)+\n  theme_minimal()\n\n\nplot_1 + plot_2 + plot_3 "},{"path":"data-insights-part-one.html","id":"drop_na","chapter":"10 Data Insights part one","heading":"10.4.6 drop_na","text":"first met NA back Chapter 4 hopefully noticed, either previous chapters, missing values NA can really mess calculations. different ways can deal missing data:drop_na() everything start. runs risk lose lot data every row, NA column removeddrop_na() everything start. runs risk lose lot data every row, NA column removeddrop_na() particular variable. fine, approach cautiously - way write data new object e.g. penguins <- penguins %>% drop_na(body_mass_g) removed data forever - perhaps want drop rows specific calculation - might contain useful information variables.drop_na() particular variable. fine, approach cautiously - way write data new object e.g. penguins <- penguins %>% drop_na(body_mass_g) removed data forever - perhaps want drop rows specific calculation - might contain useful information variables.drop_na() specific task - cautious approach need aware another phenomena. data missing random? might need investigate missing values dataset. Data truly missing random can removed dataset without introducing bias. However, bad weather conditions meant researchers get particular island measure one set penguins data missing random treated caution. island contained one particular species penguin, might mean complete data two three penguin species. nothing can incomplete data aware data missing random influence distributions.drop_na() specific task - cautious approach need aware another phenomena. data missing random? might need investigate missing values dataset. Data truly missing random can removed dataset without introducing bias. However, bad weather conditions meant researchers get particular island measure one set penguins data missing random treated caution. island contained one particular species penguin, might mean complete data two three penguin species. nothing can incomplete data aware data missing random influence distributions.","code":""},{"path":"data-insights-part-one.html","id":"categorical-and-continuous-variables","chapter":"10 Data Insights part one","heading":"10.5 Categorical and continuous variables","text":"’s common want explore distribution continuous variable broken categorical variable.\nFigure 10.4: Species sex likely affect body mass\nreasonable think perhaps either species sex might affect morphology beaks directly - might affect body mass (direct relationship mass beak length, also indirect relationship sex species).best simplest place start exploring possible relationships producing simple figures.start looking distribution body mass species.","code":""},{"path":"data-insights-part-one.html","id":"activity-1-produce-a-plot-which-allows-you-to-look-at-the-distribution-of-penguin-body-mass-observations-by-species","chapter":"10 Data Insights part one","heading":"10.6 Activity 1: Produce a plot which allows you to look at the distribution of penguin body mass observations by species","text":"reasonable think perhaps either species sex might affect body mass, can visualise number different ways. last method, density histogram, looks little crowded now, use excellent ggridges package help ","code":"\njitter_plot <- penguins %>% \n    ggplot(aes(x = species,\n               y = body_mass_g))+\n    geom_jitter(shape = 21,\n                fill = colour_fill,\n                colour = colour_line,\n                width = 0.2)+\n  coord_flip()\n\nbox_plot <- penguins %>% \n    ggplot(aes(x = species,\n               y = body_mass_g))+\n    geom_boxplot(fill = colour_fill,\n                colour = colour_line,\n                width = 0.2)+\n  coord_flip()\n\nhistogram_plot <- penguins %>% \n    ggplot(aes(fill = species))+\n    geom_histogram(aes(x = body_mass_g,\n                       y = ..density..),\n                   position = \"identity\",\n                   alpha = 0.6,\n                colour = colour_line)\n\njitter_plot/box_plot/histogram_plot"},{"path":"data-insights-part-one.html","id":"ggridges","chapter":"10 Data Insights part one","heading":"10.7 GGridges","text":"package ggridges (Wilke (2021)) provides excellent extra geoms supplement ggplot. One useful features allow different groups mapped y axis, histograms easily viewed.Q. species data distribution appears normally distributed?Gentoo YesNoGentoo YesNoChinstrap YesNoChinstrap YesNoAdelie YesNoAdelie YesNoWhile Gentoo density plot appears show two peaks, qqplot indicates deviate might expect normal distribution. still investigate whether \"two populations\" .","code":"\nlibrary(ggridges)\nggplot(penguins, aes(x = body_mass_g, y = species)) + \n  ggridges::geom_density_ridges(fill = colour_fill,\n                colour = colour_line,\n                alpha = 0.8)\npenguins %>% \n  group_split(species) %>% \n  map(~ pull(.x, body_mass_g) \n      %>% car::qqPlot())## [[1]]\n## [1] 110 102\n## \n## [[2]]\n## [1] 38 39\n## \n## [[3]]\n## [1] 18 41\npenguins %>% drop_na %>% ggplot(aes(x = body_mass_g, y = species)) + \n    geom_density_ridges(aes(fill = sex),\n                        colour = colour_line,\n                        alpha = 0.8,\n                        bandwidth = 175)\n# try playing with the bandwidth argument - this behaves similar to binning which you should be familiar with from using geom_histogram"},{"path":"data-insights-part-one.html","id":"activity-2-test-yourself","chapter":"10 Data Insights part one","heading":"10.8 Activity 2: Test yourself","text":"Question 1. Write insights made data relationships observed. Compare ones . agree ? miss ? observations make list .revealing really interesting insights shape distribution body sizes penguin populations now.example:Gentoo penguins appear show strong sexual dimorphism almost males larger females (little overlap density curves).Gentoo penguins appear show strong sexual dimorphism almost males larger females (little overlap density curves).Gentoo males females average larger two penguin speciesGentoo males females average larger two penguin speciesGentoo females two distinct peaks body mass.Gentoo females two distinct peaks body mass.Chinstrap penguins also show evidence sexual dimorphism, though greater overlap.Chinstrap penguins also show evidence sexual dimorphism, though greater overlap.Adelie penguins larger males females average, wide spread male body mass, (possibly two groups?)Adelie penguins larger males females average, wide spread male body mass, (possibly two groups?)Note able understand data better, spending time making data visuals. descriptive data statistics (mean, median) measures variance (range, IQR, sd) important. substitutes spending time thinking data making exploratory analyses.Question 2. Using summarise can quickly calculate \\(s\\) can replicate hand dplyr functions? - total \\(s\\) (category).ResidualsResidualsSquared residualsSquared residualsSum squaresSum squaresVariance = SS/dfVariance = SS/df\\(s=\\sqrt{Variance}\\)\\(s=\\sqrt{Variance}\\)","code":"\nmean <- penguins %>% \n    summarise(mean = mean(body_mass_g, na.rm = T))\n\npenguins %>% \n    mutate(residuals = (body_mass_g - pull(mean)),\n           sqrd_resid = residuals^2) %>% \n    drop_na(sqrd_resid) %>% \n    summarise(sum_squares = sum(sqrd_resid),\n              variance = sum_squares/(n=n())-1,\n              sd = sqrt(variance))"},{"path":"data-insights-part-two.html","id":"data-insights-part-two","chapter":"11 Data insights part two","heading":"11 Data insights part two","text":"previous chapter looked individual variables, understanding different types data. made numeric graphical summaries distributions features within variable. week continue work space, extend understanding include relationships variables.Understanding relationship two variables often basis scientific questions. might include comparing variables type (numeric numeric) different types (numeric categorical). chapter see can use descriptive statistics visuals explore associations","code":""},{"path":"data-insights-part-two.html","id":"associations-between-numerical-variables","chapter":"11 Data insights part two","heading":"11.1 Associations between numerical variables","text":"","code":""},{"path":"data-insights-part-two.html","id":"correlations","chapter":"11 Data insights part two","heading":"11.1.1 Correlations","text":"common measure association two numerical variables correlation coefficient. correlation metric numerical measure strength associationThere several measures correlation including:Pearson's correlation coefficient : good describing linear associationsPearson's correlation coefficient : good describing linear associationsSpearman's rank correlation coefficient: rank ordered correlation - good assumptions Pearson's correlation met.Spearman's rank correlation coefficient: rank ordered correlation - good assumptions Pearson's correlation met.Pearson's correlation coefficient r designed measure strength linear (straight line) association. Pearson's takes value -1 1.value 0 means linear association variablesA value 0 means linear association variablesA value 1 means perfect positive association variablesA value 1 means perfect positive association variablesA value -1 means perfect negative association variablesA value -1 means perfect negative association variablesA perfect association one can predict value one variable complete accuracy, just knowing value variable.can use cor function R calculate Pearson's correlation coefficient.tells us two features association. sign magnitude. coefficient negative, bill length increases, bill depth decreases. value -0.22 indicates 22% variation bill length can explained changes bill depth (vice-versa), suggesting variables closely related.\nFigure 1.4: Different relationships two numeric variables. number represents Pearson's correlation coefficient association\nPearson's coefficient designed summarise strength linear relationship, can misleading relationship linear e.g. curved humped. always good idea plot relationship first (see ).Pearson's coefficient designed summarise strength linear relationship, can misleading relationship linear e.g. curved humped. always good idea plot relationship first (see ).Even relationship linear, tell us anything steepness association (see ). tells us often change one variable can predict change value change.Even relationship linear, tell us anything steepness association (see ). tells us often change one variable can predict change value change.can difficult understand first, carefully consider figure .first row shows differing levels strength association. drew perfect straight line two variables, closely data points fit around line.first row shows differing levels strength association. drew perfect straight line two variables, closely data points fit around line.second row shows series perfect linear relationships. can accurately predict value one variable just knowing value variable, steepness relationship example different. important means perfect association can still small effect.second row shows series perfect linear relationships. can accurately predict value one variable just knowing value variable, steepness relationship example different. important means perfect association can still small effect.third row shows series associations clearly relationship two variables, also linear inappropriate Pearson's correlation.third row shows series associations clearly relationship two variables, also linear inappropriate Pearson's correlation.","code":"\nlibrary(rstatix)\n\npenguins %>% \n  cor_test(culmen_length_mm, culmen_depth_mm)"},{"path":"data-insights-part-two.html","id":"non-linear-correlations","chapter":"11 Data insights part two","heading":"11.1.2 Non-linear correlations","text":"relationship variables non-linear? Instead using Pearson's correlation coefficient can calculate something called rank correlation.Instead working raw values two variables can use rank ordering instead. idea pretty simple start lowest vaule variable order '1', assign labels '2', '3' etc. ascend rank order. can see way applied manually function dense_rank dplyr :Measures rank correlation just comparison rank orders two variables, value -1 1 just like Pearsons's. already know Pearson's correlation coefficient, expect relationship negative. come surprise highest rank order values bill_length_mm appear associated lower rank order values bill_depth_mm.calculate Spearman's \\(\\rho\\) 'rho' pretty easy, can use cor functions , time specify hidden argument method=\"spearman\".can see example Pearson's r Spearman's \\(\\rho\\) basically identical.","code":"\npenguins %>% select(culmen_length_mm, \n                    culmen_depth_mm) %>% \n  drop_na() %>% \n  mutate(rank_length=dense_rank((culmen_length_mm)), \n         rank_depth=dense_rank((culmen_depth_mm))) %>% \n  head()\npenguins %>% \n  cor_test(culmen_length_mm, culmen_depth_mm, method=\"spearman\")"},{"path":"data-insights-part-two.html","id":"graphical-summaries-between-numeric-variables","chapter":"11 Data insights part two","heading":"11.1.3 Graphical summaries between numeric variables","text":"Correlation coefficients quick simple way attach metric level association two variables. limited however single number can never capture every aspect relationship. visualise data.already covered scatter plots ggplot2() extensively previous chapters, just cover different ways present nature relationship\nFigure 11.1: scatter plot bill depth bill length mm\n**Note - Remember number different options available constructing plot including changing alpha produce transparency plots lying top , colours (shapes) separate subgroups ways present third numerical variables setting aes(size=body_mass_g).\nFigure 11.2: Using patchwork can easily arrange extra plots fit marginals - boxplots, histograms density plots\nefforts allow us capture details spread distribution variables relate . figure provides us insights intoThe central tendency variableThe central tendency variableThe spread data variableThe spread data variableThe correlation two variablesThe correlation two variables","code":"\nlength_depth_scatterplot <- ggplot(penguins, aes(x= culmen_length_mm, \n                     y= culmen_depth_mm)) +\n    geom_point()\n\nlength_depth_scatterplot\nlibrary(patchwork) # package calls should be placed at the TOP of your script\n\nbill_depth_marginal <- penguins %>% \n  ggplot()+\n  geom_density(aes(x=culmen_depth_mm), fill=\"darkgrey\")+\n  theme_void()+\n  coord_flip() # this graph needs to be rotated\n\nbill_length_marginal <- penguins %>% \n  ggplot()+\n  geom_density(aes(x=culmen_length_mm), fill=\"darkgrey\")+\n  theme_void()\n\nlayout <- \"\nAA#\nBBC\nBBC\"\n# layout is easiest to organise using a text distribution, where ABC equal the three plots in order, and the grid is how much space they take up. We could easily make the main plot bigger and marginals smaller with\n\n# layout <- \"\n# AAA#\n# BBBC\n# BBBC\"\n# BBBC\n\nbill_length_marginal+length_depth_scatterplot+bill_depth_marginal+ # order of plots is important\n  plot_layout(design=layout) # uses the layout argument defined above to arrange the size and position of plots"},{"path":"data-insights-part-two.html","id":"associations-between-categorical-variables","chapter":"11 Data insights part two","heading":"11.2 Associations between categorical variables","text":"Exploring associations different categorical variables quite simple previous numeric-numeric examples. Generally speaking interested whether different combinations categories uniformally distributed show evidence clustering leading - -represented combinations.\nsimplest way investigate use group_by summarise used previously.**Note - remember group_by() applies functions comes group-specific pattern.tell us, 168 observations made Island Biscoe, three times many Gentoo penguin observations made Adelie penguins (remeber observations made, individual penguins). account penguin ID see around twice many Gentoo penguins recorded. can see Chinstrap penguins recorded Biscoe. Conversely can see Gentoo penguins observed Biscoe.\nisland Dream two populations Adelie Chinstrap penguins roughly equal size, island Torgensen appears population comprised Adelie penguins.also use bar chart ggplot represent count data.fine, looks bit odd, bars expand fill available space category axis. Luckily advanced version postion_dodge argument.alternative approach look 'relative proportions' population overall dataset. Using methods used previously looking single variables. add aesthetic tweaks improve look.\nFigure 5.2: dodged barplot showing numbers relative proportions data observations recorded penguin species location\n","code":"\nisland_species_summary <- penguins %>% \n  group_by(island, species) %>% \n  summarise(n=n(),\n            n_distinct=n_distinct(individual_id)) %>% \n  ungroup() %>% # needed to remove group calculations\n  mutate(freq=n/sum(n)) # then calculates percentage of each group across WHOLE dataset\n\nisland_species_summary\npenguins%>% \n  ggplot(aes(x=island, fill=species))+\n  geom_bar(position=position_dodge())+\n  coord_flip()\npenguins%>% \n  ggplot(aes(x=island, fill=species))+\n  geom_bar(position=position_dodge2(preserve=\"single\"))+ \n  #keeps bars to appropriate widths\n  coord_flip()\npenguins %>% \n  ggplot(aes(x=island, fill=species))+\n  geom_bar(position=position_dodge2(preserve=\"single\"))+ \n  #keeps bars to appropriate widths\n    labs(x=\"Island\",\n       y = \"Number of observations\")+\n  geom_text(data=island_species_summary, # use the data from the summarise object\n            aes(x=island,\n                y= n+10, # offset text to be slightly to the right of bar\n                group=species, # need species group to separate text\n                label=scales::percent(freq) # automatically add %\n                ),\n            position=position_dodge2(width=0.8))+ # set width of dodge\n  scale_fill_manual(values=c(\"cyan\",\n                            \"darkorange\",\n                            \"purple\"\n                            ))+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position=\"bottom\") # put legend at the bottom of the graph"},{"path":"data-insights-part-two.html","id":"associations-between-categorical-numerical-variables","chapter":"11 Data insights part two","heading":"11.3 Associations between Categorical-numerical variables","text":"","code":"\npenguins %>% \n  ggplot(aes(x=species,\n             y=body_mass_g))+\n  geom_boxplot()+\n  labs(y=\"Body mass (g)\",\n         x= \"Species\")\npenguins %>% \n  ggplot(aes(x=body_mass_g,\n             fill=species))+\n  geom_histogram(alpha=0.6,\n         bins=30,\n         position=\"identity\")+\n  facet_wrap(~species,\n             ncol=1)"},{"path":"data-insights-part-two.html","id":"complexity","chapter":"11 Data insights part two","heading":"11.4 Complexity","text":"reasonable think perhaps either species sex might affect morphology beaks directly - might affect body mass (direct relationship mass beak length, also indirect relationship sex species).Failure account complex interactions can lead misleading insights data.","code":""},{"path":"data-insights-part-two.html","id":"simpsons-paradox","chapter":"11 Data insights part two","heading":"11.4.1 Simpson's Paradox","text":"Remember first correlated bill length bill depth found overall negative correlation -0.22. However, confounding variable accounted - species.another example carefully studying data - carefully considering variables likely affect studied controlled . entirely reasonable hypothesis different penguin species might different bill shapes might make overall trend misleading. can easily check effect categoricial variable two numeric variables assigning aesthetic colour.now clearly see striking reversal previous trend, fact within species penguin overall positive association bill length depth.prompt us re-evaluate correlation metrics:now see correlation values three species >0.22 - indicating associations much closer previously estimated.","code":"\ncolours <- c(\"cyan\",\n             \"darkorange\",\n             \"purple\")\n\nlength_depth_scatterplot_2 <- ggplot(penguins, aes(x= culmen_length_mm, \n                     y= culmen_depth_mm,\n                     colour=species)) +\n    geom_point()+\n  geom_smooth(method=\"lm\",\n              se=FALSE)+\n  scale_colour_manual(values=colours)+\n  theme_classic()+\n  theme(legend.position=\"none\")+\n    labs(x=\"Bill length (mm)\",\n         y=\"Bill depth (mm)\")\n\nlength_depth_scatterplot\nbill_depth_marginal_2 <- penguins %>% \n  ggplot()+\n  geom_density(aes(x=culmen_depth_mm,\n                   fill=species),\n               alpha=0.5)+\n  scale_fill_manual(values=colours)+\n  theme_void()+\n  coord_flip() # this graph needs to be rotated\n\nbill_length_marginal_2 <- penguins %>% \n  ggplot()+\n  geom_density(aes(x=culmen_length_mm,\n                   fill=species),\n               alpha=0.5)+\n  scale_fill_manual(values=colours)+\n  theme_void()+\n  theme(legend.position=\"none\")\n\nlayout2 <- \"\nAAA#\nBBBC\nBBBC\nBBBC\"\n\nbill_length_marginal_2+length_depth_scatterplot_2+bill_depth_marginal_2+ # order of plots is important\n  plot_layout(design=layout2) # uses the layout argument defined above to arrange the size and position of plots\npenguins %>% \n  group_by(species) %>% \n  cor_test(culmen_length_mm, culmen_depth_mm)"},{"path":"data-insights-part-two.html","id":"three-or-more-variables","chapter":"11 Data insights part two","heading":"11.4.2 Three or more variables","text":"example therefore, saw importance exploring relationships among two variables . Broadly speaking two ways top thisLayer extra aesthetic mapping onto ggplot - size, colour, shapeUse facets construct multipanel plots according values categorical variableIf want can also adopt approaches time:can see trends across different penguin sexes. Although comparing slopes lines, lengths lines amounts overlap can make insights \"sexually dimorphic\" different species e.g. terms beak morphology species show greater differences males females others?","code":"\npenguins %>% \n  drop_na(sex) %>% \nggplot(aes(x= culmen_length_mm, \n                     y= culmen_depth_mm,\n                     colour=sex)) + # colour aesthetic set to sex\n    geom_point(aes(shape = species))+\n  geom_smooth(aes(group = species),\n              method=\"lm\",\n              se=FALSE)+\n  scale_colour_manual(values=c(\"#1B9E77\", \"#D95F02\"))+ # pick two colour scheme\n  theme_classic()+\n  theme(legend.position=\"none\")+\n    labs(x=\"Bill length (mm)\",\n         y=\"Bill depth (mm)\")\npenguins %>% \n  drop_na(sex) %>% \nggplot(aes(x= culmen_length_mm, \n                     y= culmen_depth_mm,\n                     colour=sex)) + # colour aesthetic set to sex\n    geom_point()+\n  geom_smooth(method=\"lm\",\n              se=FALSE)+\n  scale_colour_manual(values=c(\"#1B9E77\", \"#D95F02\"))+ # pick two colour scheme\n  theme_classic()+\n  theme(legend.position=\"none\")+\n    labs(x=\"Bill length (mm)\",\n         y=\"Bill depth (mm)\")+\n  facet_wrap(~species, ncol=1) # specify plots are stacked split by species"},{"path":"data-insights-part-two.html","id":"summing-up","chapter":"11 Data insights part two","heading":"11.5 Summing up","text":"last data handling workshop. built towards able discover examine relationships differences among variables data. now skills handle many different types data, tidy , produce visuals generate insight communicate others.note caution required - easy spot identify patterns.spot trend, difference relationship, important recognise may enough evidence assign reason behind observation. scientists important develope hypotheses based knowledge understanding, can help (sometimes) avoiding spurious associations.Sometimes may see pattern data, likely occurred due random chance, rather result underlying process. formal statistical analysis, quantitatively assess evidence, assess probability study effect sizes can incredibly powerful. delve exciting topics next term.! Thank taking time get far. kind found difficult. done incredibly well.praise!!!!","code":"\npraise::praise()## [1] \"You are wonderful!\"[1] \"You are spectaculaR!\""},{"path":"introduction-to-statistics.html","id":"introduction-to-statistics","chapter":"12 Introduction to statistics","heading":"12 Introduction to statistics","text":"term focusing statistics. actually quite lot descriptive statistics work last term. Every time summarised described data, calculating mean, median, standard deviation, frequency/count, distribution carrying descriptive statistics helped us understand data better.building develop skills inferential statistics. Inferential statistics allow us make generalisations - taking descriptive statistics data sample mean, using say something population parameter (.e. population mean).example might measure measure heights plants outcrossed inbred make summaries figures construct average difference height (descriptive). use produce estimates general effect outcrossing vs inbreeding plant heights (inferential).","code":""},{"path":"introduction-to-statistics.html","id":"darwins-maize-data","chapter":"12 Introduction to statistics","heading":"12.1 Darwin's maize data","text":"Loss genetic diversity important issue conservation species. Declines population size due exploitation, habitat fragmentation lead loss genetic diversity. Even populations restored viable numbers conservation efforts may suffer continued loss population fitness inbreeding depression.Charles Darwin even wrote book subject \"Effects Cross Self-Fertilisation Vegetable Kingdom\". describes produced seeds maize (Zea mays) fertilised pollen individual different plant. height seedlings produced measured proxy evolutionary fitness.Darwin wanted know whether inbreeding reduced fitness selfed plants - hypothesis. data going use today Darwin's original dataset.\ngo - make sure basic R project set scratch. know data file saved? got separate subfolders set within project?\n\nset script put work - use write instructions store comments. Use File > New Script menu item select R Script.\n","code":"\nlibrary(tidyverse)\nlibrary(here)\n\ndarwin <- read_csv(here(\"data\", \"darwin.csv\"))"},{"path":"introduction-to-statistics.html","id":"activity-1-carry-out-some-basic-exploratory-data-analysis","chapter":"12 Introduction to statistics","heading":"12.2 Activity 1: Carry out some basic exploratory data analysis","text":"first thing know now always start exploring data. want stretch , see can perform basic data check without prompts.","code":"\n# check the structure of the data\nglimpse(darwin)\n\n# check data is in a tidy format\nhead(darwin)\n\n# check variable names\ncolnames(darwin)\n\n\n# clean up column names\n\ndarwin <- janitor::clean_names(darwin)\n\n# check for duplication\ndarwin %>% \n  duplicated() %>% \n  sum()\n\n# check for typos - by looking at impossible values\ndarwin %>% \n  summarise(min=min(height, na.rm=TRUE), \n            max=max(height, na.rm=TRUE))\n\n# check for typos by looking at distinct characters/values\n\ndarwin %>% \n  distinct(pair)\n\ndarwin %>% \n  distinct(type)\n\n# missing values\ndarwin %>% \n  is.na() %>% \n  sum()\n\n# quick summary\n\nsummary(darwin)"},{"path":"introduction-to-statistics.html","id":"visualisation","chapter":"12 Introduction to statistics","heading":"12.2.1 Visualisation","text":"Now seems like good time first data visualisation.graph clearly shows average height 'crossed' plants greater 'selfed' plants. need investigate order determine whether signal (apparent differences mean values) greater level noise (variance within different groups).variance appears roughly similar two groups - though making graph can now clearly see crossed group, potential outlier value 12.","code":"\ndarwin %>% \n  ggplot(aes(x=type,\n         y=height))+\n  geom_point()\n# you could also substitute (or combine) other geoms including\n# geom_boxplot()\n# geom_violin()\n# geom_histogram()\n# Why not have a go and see what you can make?"},{"path":"introduction-to-statistics.html","id":"comparing-groups","chapter":"12 Introduction to statistics","heading":"12.2.2 Comparing groups","text":"seen previously can use various tidy functions determine mean standard deviations groups.\n(re)familiarise () calculate standard deviation.\nSummary statistics like presented figures tables. normally reserve tables simple sets numbers, instance present .\nTable 12.1: Summary statistics crossed selfed maize plants\nDescriptive statistics careful data checking often skipped steps rush answer big questions. However, description essential part early phase analysis.","code":"\ndarwin %>% \n  group_by(type) %>% \n  summarise(mean=mean(height),\n            sd=sd(height))\n# make a new object\ndarwin_summary <-darwin %>% \n  group_by(type) %>% \n  summarise(mean=mean(height),\n            sd=sd(height))\n\n# make a summary plot\ndarwin_summary %>% \n  ggplot(aes(x=type,\n             y=mean))+\n  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd))+\n  theme_bw()\n# put this at top of script\nlibrary(kableExtra)\n\n# use kable extra functions to make a nice table (could be replaced with kable() if needed)\ndarwin_summary %>% \n    kbl(caption=\"Summary statistics of crossed and selfed maize plants\") %>% \n  kable_styling(bootstrap_options = \"striped\", full_width = T, position = \"left\")"},{"path":"introduction-to-statistics.html","id":"estimation","chapter":"12 Introduction to statistics","heading":"12.3 Estimation","text":"section concentrated description. hypothesis Darwin aimed test whether 'inbreeding reduced fitness selfed plants'. use height plants proxy fitness explicitly address whether difference mean heights plants two groups.goal :Estimate mean heights plants two groupsEstimate mean heights plants two groupsEstimate mean difference heights two groupsEstimate mean difference heights two groupsQuantify confidence differencesQuantify confidence differences","code":""},{"path":"introduction-to-statistics.html","id":"differences-between-groups","chapter":"12 Introduction to statistics","heading":"12.3.1 Differences between groups","text":"Darwin's data used match pairs - pair shared one parent. pair 1 parent plant either 'selfed' 'crossed' produce offspring. powerful approach experimental design, means can look differences heights across 15 pairs plants - rather infer differences two randomly derived groups.order calculate differences height pair need data wrangling tidyr::pivot_wider() Chapter 2 calculations mutate.","code":""},{"path":"introduction-to-statistics.html","id":"activity-2-differences","chapter":"12 Introduction to statistics","heading":"12.4 Activity 2: Differences","text":"Create new column called difference height selfed plant pair subtracted crossed plant.now difference height pair, can use calculate mean difference heights paired plants, amount variance (standard deviation)\njust calculated average difference height groups plants standard deviation difference Moving forward working lot estimating confidence differences groups\n","code":"\n# pivot data to wide format then subtract Selfed plant heights from Crossed plant heights\n\ndarwin_wide <- darwin %>% \n  pivot_wider(names_from = type, values_from = height) %>% \n  mutate(difference = Cross - Self)\ndifference_summary <- darwin_wide %>% \n  summarise(mean=mean(difference),\n            sd=sd(difference),\n            n=n())\n\ndifference_summary"},{"path":"introduction-to-statistics.html","id":"standard-error-of-the-difference","chapter":"12 Introduction to statistics","heading":"12.4.1 Standard error of the difference","text":"Remember standard deviation descriptive statistic - measures variance within dataset - e.g. closely datapoints fit mean. However inferential statistics interested confidence estimation mean. standard error comes .can think error standard deviation mean. mean calculated estimate based one sample data. expect sampled another 30 plants different sample mean. Standard error describes variability expect among sample means repeated experiment many times. can think measure confidence estimate true population mean.\\[\nSE = \\frac{s}{\\sqrt(n)}\n\\]sample size increases standard error reduce - reflecting increasing confidence estimate.can calculate standard error sample applying equation difference_summary object, can complete ?estimate mean really useful without accompanying measuring uncertainty like standard error, fact estimates averages differences always accompanied measure uncertainty.","code":"\ndifference_summary %>% \n  mutate(se= sd/sqrt(n))"},{"path":"introduction-to-statistics.html","id":"activity-3-communicate","chapter":"12 Introduction to statistics","heading":"12.4.2 Activity 3: Communicate","text":"information , present short sentence describing average different height?","code":""},{"path":"introduction-to-statistics.html","id":"uncertainty","chapter":"12 Introduction to statistics","heading":"12.5 Uncertainty","text":"mean standard error difference heights inbred crossed plants - work much confidence difference population means?Standard error measure uncertainty, larger standard error noise around data uncertainty . smaller standard error confidence can difference means real.Null hypothesis - difference mean height self vs crossed plantsNull hypothesis - difference mean height self vs crossed plantsAlternate hypothesis - inbreeding reduces fitness selfed plants, observed selfed plants average smaller crossed plantsAlternate hypothesis - inbreeding reduces fitness selfed plants, observed selfed plants average smaller crossed plants\nstatistical way thinking inferences terms confidence around keeping rejecting null hypothesis. (alternate) hypothesis simply one contradicts null.\n\ndecide whether enough confidence difference real (e.g. reject null hypothesis), ever 100% certain false positive (also known Type error). later\n","code":""},{"path":"introduction-to-statistics.html","id":"normal-distribution-1","chapter":"12 Introduction to statistics","heading":"12.5.1 Normal distribution","text":"remember, normal distribution bell-shaped curve. defined two parameters:meanthe meanthe standard deviationthe standard deviationThe mean determines centre/peak bell curve , standard deviation determines width bell (long tails ).Large standard deviations produce wide bell curves, short peaks. Small standard deviations produce narrow bell curves tall peaks.bell curve occurs frequently nature, circumstances can think continuous measure coming population e.g. human mass, penguin flipper lengths plant heights.probability distribution, area within curve sums whole population (e.g. probability curve contains every possible measurement 1). Known proportions curve lie within certain distances centre e.g. 67.8% observations values within one standard deviation mean. 95% observations values within two standard deviations mean. idealized normal distribution presented :convert information likely observe difference 2.62 inches plant heights 'true' difference crosses selfed plants zero?central limit theorem states population mean standard deviation, take sufficiently large random samples population, distribution sample means approximately normally distributed. Standard error measure variability around sample mean, assume can apply normal distribution ability estimate mean (revisit assumption later).now center bell curve estimate mean (2.62), just two thirds area curve ± 1.22 inches. 95% within ± 2 standard errors, 99.8% within ± 3 standard errors.Taking look figure can ask zero normal distribution? One way think , true difference plant groups zero, surprising estimated difference groups 2.62 inches?zero close center bell curve, observed mean surprising (null hypothesis true). However case middle bell. falls left-hand tail, > two standard deviations estimated mean.can describe two ways:estimate ran experiment 100 times >95 experiments estimate mean difference plant groups > 0.estimate ran experiment 100 times >95 experiments estimate mean difference plant groups > 0.also usually taken minimum threshold needed reject null hypothesis. can think probability estimating mean difference, true mean difference zero, p < 0.05.also usually taken minimum threshold needed reject null hypothesis. can think probability estimating mean difference, true mean difference zero, p < 0.05.probably used threshold null hypothesis rejection \\(\\alpha\\) = 0.05, lowest level confidence can pass statistical test. increase severity test minimum require \\(\\alpha\\) = 0.001 99% confidence, can see longer believe enough confidence reject null hypothesis (0 within 3 s.d. estimated mean).","code":"\n#Create a sequence of 100 equally spaced numbers between -4 and 4\nx <- seq(-4, 4, length=100)\n\n#create a vector of values that shows the height of the probability distribution\n#for each value in x\ny <- dnorm(x)\n\n#plot x and y as a scatterplot with connected lines (type = \"l\") and add\n#an x-axis with custom labels\nplot(x,y, type = \"l\", lwd = 2, axes = FALSE, xlab = \"\", ylab = \"\")\naxis(1, at = -3:3, labels = c(\"-3s\", \"-2s\", \"-1s\", \"mean\", \"1s\", \"2s\", \"3s\"))"},{"path":"introduction-to-statistics.html","id":"confidence-intervals","chapter":"12 Introduction to statistics","heading":"12.5.2 Confidence Intervals","text":"± 2 standard errors covers central 95% area normal curve, refer 95% confidence interval. can calculate confidence intervals level, commonly refer standard error (68% CI), 95% 99%.can work 95% confidence interval range estimated mean follows:common mistake state 95% confident 'true' mean lies within interval. technically refers fact kept running experiment intervals calculate capture true mean 95% experiments. really saying confident capture true mean 95% experiments.might write ?\nmaize plants cross pollinated taller average self-pollinated plants, mean difference height 2.62 [0.18, 5.06] inches (mean [95% CI]).\nNote possible generate multiple types average confidence interval, clearly state write . true presenting standard error (± S.E.) standard deviation (± S.D.) median interquartile range (median [± IQR]).good example simple clear write-clearly describes direction difference, amount error estimate.","code":"\nlowerCI <- 2.62-(2*1.22)\n\nupperCI <- 2.62+(2*1.22)\n\nlowerCI\nupperCI## [1] 0.18\n## [1] 5.06"},{"path":"introduction-to-statistics.html","id":"summary-1","chapter":"12 Introduction to statistics","heading":"12.6 Summary","text":"Statistics trying interpret whether signal (difference trend) stronger amount noise (variability). sample standard deviation strong choice estimating within dataset. standard deviation sampling distribution mean known standard error. standard error (mean) measure precision estimate mean. Thanks central limit theorem normal distribution can use variability estimate calculate confidence intervals, decide whether signal effect strong enough reject null hypothesis (effect difference).Next time start working linear models - approach allows us estimate means intervals sophisticated (automated) way.","code":""},{"path":"introduction-to-linear-models.html","id":"introduction-to-linear-models","chapter":"13 Introduction to Linear Models","heading":"13 Introduction to Linear Models","text":"last chapter conducted simple analysis Darwin's maize data using R. worked confidence intervals 'hand'. simple method allowed us learn analysis, estimates, standard error confidence. also slow, relied assumptions z-distribution assess true differences groups.now work much efficient way carry comparisons, use functions R let us perform linear model analysis.","code":""},{"path":"introduction-to-linear-models.html","id":"packages-1","chapter":"13 Introduction to Linear Models","heading":"13.0.1 Packages","text":"","code":"\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(emmeans)\nlibrary(performance)"},{"path":"introduction-to-linear-models.html","id":"a-linear-model-analysis-for-comparing-groups","chapter":"13 Introduction to Linear Models","heading":"13.1 A linear model analysis for comparing groups","text":"R general function lm() fitting linear models, part base R (require tidyverse packages). run different iterations linear model increasing complexity. often want fit several models data, common way work fit model assign named R object, can extract data need .example called model lsmodel0, short \"least-squares model 0\", linear-model uses technique called least-squares explore means later.\ncan pipe lm() function, use functions \"outside\" tidyverse family need put . data go (usually first argument).\n\nlsmodel0 <- darwin %>% lm(height ~ 1, data= .)\nfirst argument lm() function formula (write full future) - specifies want analyse response variable (height) function explanatory variable using tilde symbol (~).simplest possible model ignores explanatory variables, instead 1 indicates just want estimate intercept. Without explanatory variables means formula just estimate overall mean height plants dataset.","code":"\nlsmodel0 <- lm(formula = height ~ 1, data = darwin)"},{"path":"introduction-to-linear-models.html","id":"summaries-for-models","chapter":"13 Introduction to Linear Models","heading":"13.2 Summaries for models","text":"made linear model, can investigate summary model using base R function summary(). also tidyverse option provided package broom(Robinson et al. (2022)).","code":""},{"path":"introduction-to-linear-models.html","id":"broom","chapter":"13 Introduction to Linear Models","heading":"13.2.1 Broom","text":"broom summarizes key information models tidy tibble()s. broom provides three verbs make convenient interact model objects:broom::tidy() summarizes information model componentsbroom::tidy() summarizes information model componentsbroom::glance() reports information entire modelbroom::glance() reports information entire modelbroom::augment() adds informations individual observations dataset can used model predictions onto new dataset.broom::augment() adds informations individual observations dataset can used model predictions onto new dataset.","code":""},{"path":"introduction-to-linear-models.html","id":"model-summary","chapter":"13 Introduction to Linear Models","heading":"13.2.2 Model summary","text":"output called table coefficients. 18.9 estimate model coefficient (case overall mean), together standard error. first row R model output always labelled 'Intercept' challenge usually workout represents. case can prove overall mean follows:simple model allows us understand lm() function .","code":"\nsummary(lsmodel0)## \n## Call:\n## lm(formula = height ~ 1, data = darwin)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.8833 -1.3521 -0.0083  2.4917  4.6167 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  18.8833     0.5808   32.52   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.181 on 29 degrees of freedom\nbroom::tidy(lsmodel0)\nmean(darwin$height)## [1] 18.88333"},{"path":"introduction-to-linear-models.html","id":"compare-means","chapter":"13 Introduction to Linear Models","heading":"13.2.3 Compare means","text":"really want linear model analyses difference average plant height function pollination type. can use lm() function fit linear model follows:Now model formula contains pollination type addition intercept.things notice :intercept value changed! represent now?intercept value changed! represent now?label second row 'typeSelf'label second row 'typeSelf'mean? Think see can figure clicking revealThe label second row 'typeSelf' produced combining variable type, one factors (Self). two levels type, stands reason intercept must represent typeCross. coefficient label intercept average height 15 maize plants crossed treatment.second row? common mistake think must refer height Self plants. However, true value negative. Instead actually refers difference mean height two groups. focuses question asking: difference height plants result cross pollination compared plants self pollinated?linear model indicates average height Crossed plants 20.2 inches, Selfed plants average 2.6 inches shorter.can confirm :take look fuller summary model, see else can determine\nFigure 3.3: Annotation summary function output\nuse information model superimpose calculated means onto plot.","code":"\nlsmodel1 <- lm(height ~ type, data=darwin)\n\n# note that the following is identical\n\n# lsmodel1 <- lm(height ~ 1 + type, data=darwin)\nbroom::tidy(lsmodel1)\ndarwin %>% \n  group_by(type) %>% \n  summarise(mean=mean(height))\nsummary(lsmodel1)## \n## Call:\n## lm(formula = height ~ type, data = darwin)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.1917 -1.0729  0.8042  1.9021  3.3083 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  20.1917     0.7592  26.596   <2e-16 ***\n## typeSelf     -2.6167     1.0737  -2.437   0.0214 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.94 on 28 degrees of freedom\n## Multiple R-squared:  0.175,  Adjusted R-squared:  0.1455 \n## F-statistic:  5.94 on 1 and 28 DF,  p-value: 0.02141\ndarwin %>% \n  ggplot(aes(x=type, \n             y=height,\n             colour=type))+\n  geom_jitter(alpha=0.5,\n              width=0.1)+\n  stat_summary(fun=mean,\n               size=1.2)+\n  theme_bw()"},{"path":"introduction-to-linear-models.html","id":"standard-error-of-the-difference-1","chapter":"13 Introduction to Linear Models","heading":"13.2.4 Standard error of the difference","text":"output model also gives standard errors values (estimates). first row intercept calculates mean standard error mean (SEM). second row gives mean difference column gives standard error difference two means (SED). already seen calculate SEM, SED?\\[\nSED = {\\sqrt \\frac{s_1^2}{n_1}}+\\frac{s_2^2}{n_2}\n\\]** Note - subscripts 1 2 indicate two groups (self cross).\nlinear model analysis actually calculate individual variances two groups. Instead uses 'pooled' variance approach. assumes variance roughly equal across groups, allows us take advantage larger sample size 'pooling', generate accurate SED. However, assume variance roughly equal two groups. fact last week calculated standard deviation, saw case. must check assumption model (later).\n","code":""},{"path":"introduction-to-linear-models.html","id":"confidence-intervals-1","chapter":"13 Introduction to Linear Models","heading":"13.3 Confidence intervals","text":"follows layout table coefficients, output intercept row gives 95% CI height crossed plants second row gives 95% interval difference height crossed selfed plants. lower upper bounds 2.5% 97.5% t-distribution (later).difference height specifically interested. summary models generated p-values conspicuously ignored now. Instead going continue focus using confidence intervals answer question.","code":"\nconfint(lsmodel1)##                2.5 %     97.5 %\n## (Intercept) 18.63651 21.7468231\n## typeSelf    -4.81599 -0.4173433\nbroom::tidy(lsmodel1, conf.int=T)"},{"path":"introduction-to-linear-models.html","id":"answering-the-question","chapter":"13 Introduction to Linear Models","heading":"13.4 Answering the question","text":"Darwin's original hypothesis self-pollination reduce fitness (using height proxy ). null hypothesis effect pollination type, therefore difference average heights.\nmust ask experiment consistent null hypothesis can reject ? choose reject null hypothesis, level confidence can ?, can simply whether predicted value null hypothesis (difference zero) lies inside 95% CI difference mean.confidence intervals contain zero (difference), establish difference sample difference height (-2.62 inches) null prediction zero difference, given level variability (noise) data.case can see upper lower bounds confidence intervals cross zero. difference height consistent Darwin's alternate hypothesis inbreeding depression.GGally package handy ggcoef_model() function, produces graph estimated mean difference approx 95% CI. can see able reject null hypothesis 95% confidence level.\nSet confidence levels 99%, think difference treatments still statistically significant 0.01?\nincrease level confidence (95% 99%, roughly 2 SE 3 SE), may find reject null hypothesis higher threshold confidence. Try altering conf.level argument see action.can also include argument tidy() function wish :","code":"\nGGally::ggcoef_model(lsmodel1,\n                     show_p_values=FALSE, \n                     conf.level=0.95)\nbroom::tidy(lsmodel1, conf.int=T, conf.level=0.99)"},{"path":"introduction-to-linear-models.html","id":"getting-the-other-treatment-mean-and-standard-error","chapter":"13 Introduction to Linear Models","heading":"13.4.1 Getting the other treatment mean and standard error","text":"One limitation table coefficients output provide mean standard error treatment level (difference ). wish calculate \"\" mean SE can get R .relevelling, self treatment now taken intercept, get estimate mean standard error","code":"\ndarwin %>% \n  mutate(type=factor(type)) %>% \n  mutate(type=fct_relevel(type, c(\"Self\", \"Cross\"))) %>% \n  lm(height~type, data=.) %>% \n  broom::tidy()"},{"path":"introduction-to-linear-models.html","id":"emmeans","chapter":"13 Introduction to Linear Models","heading":"13.4.2 Emmeans","text":"also use package emmeans function emmeans() similar thingThe advantage emmeans provides mean, standard error 95% confidence interval estimates levels model (e.g. relevels model multiple times behind scenes).emmeans also gives us handy summary include data visuals combine raw data statistical inferences. standard ggplot() outputs can customised much want.Notice matter calculate estimated SE (therefore 95% CI) treatments . mentioned earlier variance pooled estimate, e.g. variance calculate separately group. difference see SE across treatments difference sample size groups.\nNotice Confidence intervals estimated means strongly overlap, difference two SEMs SED calculated. overlapping error bars used infer significance.\npooled variance, assumption variance equal across groups, assumptions linear model checked. trust results assumptions model adequately met.","code":"\nmeans <- emmeans::emmeans(lsmodel1, specs = ~ type)\n\nmeans##  type  emmean    SE df lower.CL upper.CL\n##  Cross   20.2 0.759 28     18.6     21.7\n##  Self    17.6 0.759 28     16.0     19.1\n## \n## Confidence level used: 0.95\nmeans %>% \n  as_tibble() %>% \n  ggplot(aes(x=type, \n             y=emmean))+\n  geom_pointrange(aes(\n    ymin=lower.CL, \n    ymax=upper.CL))"},{"path":"introduction-to-linear-models.html","id":"assumption-checking","chapter":"13 Introduction to Linear Models","heading":"13.5 Assumption checking","text":"now main parts linear model analysis, results inferences. need check whether assumptions model adequately met know whether analysis can trusted.first part going check two assumptions:residual/unexplained variance data approximately normally distributed.residual/unexplained variance data approximately normally distributed.residual/unexplained variance approximately equal groupsthat residual/unexplained variance approximately equal groupsResiduals differences observed values fitted values produced model - case heights plants treatment means. assumption normal distribution applies linear model uses calculate standard errors (therefore confidence intervals). assumption equal variance applies pooled variance approach (e.g. two treatments 15 replicates - pooling variance across treatments sample size 30).Several functions exist check assumptions linear models, easiest way make graphs. can several ways, base R plot() function, using performance::check_model() function.","code":"\nperformance::check_model(lsmodel1)\nplot(lsmodel1)"},{"path":"introduction-to-linear-models.html","id":"normal-distribution-2","chapter":"13 Introduction to Linear Models","heading":"13.5.1 Normal distribution","text":"","code":"\nperformance::check_model(lsmodel1, check=c(\"normality\",\"qq\"))\nplot(lsmodel1, which=c(2,2))"},{"path":"introduction-to-linear-models.html","id":"what-is-a-quantile-quantile-qq-plot","chapter":"13 Introduction to Linear Models","heading":"13.5.1.1 What is a Quantile-Quantile (QQ) plot?","text":"QQ plot classic way checking whether sample distribution another (theoretical distribution). look bit odd first, actually fairly easy understand, useful! qqplot distributes data y-axis, theoretical normal distribution x-axis. residuals follow normal distribution, meet produce perfect diagonal line across plot.Watch video see QQ plots explained\nFigure 13.1: Examples qqplots different deviations normal distribution\nexample can see residuals can explained normal distribution, except extreme low end data. surprising, already identified potential outliers.fit perfect, also terrible!","code":""},{"path":"introduction-to-linear-models.html","id":"equal-variance","chapter":"13 Introduction to Linear Models","heading":"13.5.2 Equal variance","text":"order assess variances equal can plot residuals (variance) data fitted (predicted) values. residuals zero, mean error, data exactly matches estimates. reality, always residual error, long evenly distributed treatments ok.check_models plot provides call 'standardized residuals' divide residual error standard deviation.instance can see higher fitted values (Cross treatment) appears variable lower fitted values. , bad, perfect. probably influence least partially potential outliers.","code":"\nperformance::check_model(lsmodel1, check=\"homogeneity\")\nplot(lsmodel1, which=c(1,3))"},{"path":"introduction-to-linear-models.html","id":"outliers","chapter":"13 Introduction to Linear Models","heading":"13.5.3 Outliers","text":"talked lot potential effect outliers, can see potentially affecting estimates error/variance. However, also check much effect might model estimates (means). formal outlier tests useful.value data points measured called Cook's distance. measure much 'leverage' single data point exerting model, high, may outsized effect estimates. check_model() function gives contours indicate whether data points fall inside outside margins affecting fit, rough estimate acceptable Cook's Distance either \\(\\frac{4}{N}\\) \\(\\frac{4}{df}\\), unlikely calculate hand.","code":"\nperformance::check_model(lsmodel1, check=\"outliers\")\nplot(lsmodel1, which=c(4,4))"},{"path":"introduction-to-linear-models.html","id":"summary-2","chapter":"13 Introduction to Linear Models","heading":"13.6 Summary","text":"can determine analysis? model perfect, however reasonably good. However, addressed important part experimental design yet. fact plants paired, example basically carried Student's t-test, paired t-test. Later add pair another explanatory variable see affects model.remember linear model sets one factor level 'intercept' estimates mean, draws line first treatment second treatment, slope line difference means two treatments.difference means always accompanied standard error difference (SED), can used calculate 95% confidence interval. confidence interval contain intercept value, can reject null hypothesis 'effect'.Linear models make variety assumptions, including noise (residual differences) approximately normally distributed, roughly equal (homogenous) variance.","code":"\ndarwin %>% \n  ggplot(aes(x=type, \n             y=height))+\n   geom_jitter(width=0.1, \n              pch=21, \n              aes(fill=type))+\n  theme_classic()+\n  geom_segment(aes(x=1, xend=2, y=20.192, yend=20.192-2.617), linetype=\"dashed\")+\nstat_summary(fun.y=mean, geom=\"crossbar\", width=0.2)"},{"path":"testing.html","id":"testing","chapter":"14 Testing","heading":"14 Testing","text":"","code":""},{"path":"testing.html","id":"its-t-time","chapter":"14 Testing","heading":"14.1 It's t-time","text":"last chapter used linear models calculate estimates, estimates mean difference confidence intervals. can set confidence intervals whatever threshold choose - reporting without P sufficient estimation choose. interesting bit, reporting direction effect size relationship difference whatever confidence threshold want.P-values comparison, boring, -one actually cares P-values, forgiven thinking important thing statistics way often see presented. , inevitably, asked supply P-value many lab reports, dissertations (maybe future scientific papers). Luckily significance tests come parcelled coefficients linear models.","code":""},{"path":"testing.html","id":"students-t-test","chapter":"14 Testing","heading":"14.2 Student's t-test","text":"Student's t-test uses t-distribution, small-sample size version normal distribution, tails fatter degrees freedome small. two basic types t-test encountered linear models.one sample t-test: takes mean sample compares null hypothesis zeroThe two sample t-test compares difference means two samples null hypothesis difference means two populations.general equation calculating t :\\[\nt = \\frac{difference}{SE}\n\\]calculation t-value essentially counting standard errors, rough rule thumb estimate difference twice large standard error confidence interval 95%, three times large standard error confidence interval 99%.approximate becomes less robust smaller sample sizes, sample sizes large t-distribution roughly equal normal (z) distribution. However, sample sizes small t-distribution shorter wider distribution (need larger standard errors capture 95% confidence interval).potential source confusion discussing t two values must considered. critical t value must exceeded test significant (e.g. generates P value less predefined \\(\\alpha\\)). critical value t defined df. observed  value t, value returned statistical test, calculated \\(\\frac{difference}{SE}\\). \\(observed~t > critical~t\\) result can declared significantly different threshold \\(\\alpha\\).spending lot time t default value generated linear model outputs, instead assuming normal distriubtion using z. Recall z distribution critical value P = 0.05 \\(1.96 * SE\\) (roughly double Standard Error), actually look figure , can see even 8 df distribution t starting look pretty close z distribution. values critical t degree freedom 30 presented belowSo far used mixture base R summary() function broom package tibbles produced broom::tidy(). Summary common way investigate model result, specific type R object (e.g. dataframe tibble), tidying results dataframe like structure can useful.\nUsing either method can can see include t-tests coefficient, summary explicity calls t, tidy() refers generically 'statistic'linear model summary automatically apply test every row table, sometimes important apriori tests defined hypothesis, sometimes .example second row table test planned perform, tests null hypothesis comparing average observed difference plant heights cross self-pollinated plants, calculates average difference (estimate), amount uncertainty (std. error), calculates observed t value determines probability observing effect least size (sample size) null hypothesis true.However, first row also performs t-test, tests null hypothesis intercept (mean height cross-pollinated plants) zero. comparison intended make, likely test particularly useful.Anyway observed difference plant heights 2.62 inches ± 1.07, produces observed value t :value t model summary.","code":"lm(y ~ 1)\n\nlm (height~1)\nx <- seq(-4, 4, length=100)\nhx <- dnorm(x)\n\ndegf <- c(1, 3, 8, 30)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\", \"black\")\nlabels <- c(\"df=1\", \"df=3\", \"df=8\", \"df=30\", \"normal\")\n\nplot(x, hx, type=\"l\", lty=2, xlab=\"x value\",\n     ylab=\"Density\", main=\"Comparison of t Distributions\")\n\nfor (i in 1:4){\n    lines(x, dt(x,degf[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Distributions\",\n       labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\nx <- seq(-4, 4, length=100)\nz_dist <- dnorm(x)\n\nvalues <- tibble(x,z_dist)\n\n# map_dfc combines values returned into a dataframe\nt <- map_dfc(degf, ~dt(x, .x))\ncolnames(t) <- degf\n\ncombined <- cbind(values,t)\n\ncombined %>% \n    pivot_longer(cols=!x, names_to=\"distribution\") %>% \n    mutate(distribution=factor(distribution, levels=c(\"z_dist\", \"1\", \"3\", \"8\", \"30\"))) %>%  \n  mutate(distribution=fct_recode(distribution, \"z distribution\" = \"z_dist\", \"df = 1\" = \"1\", \"df = 3\" = \"3\", \"df = 8\" = \"8\", \"df = 30\" = \"30\")) %>% \n  ggplot(aes(x=x, y=value, colour=distribution))+\n  geom_line(linetype=\"dashed\")+\n  theme_classic()\ndf <- c(1:30)\n\n# map_dbl forces returned values to be a single vector of numbers (rather than a list)\ncritical_t <- map_dbl(df, ~qt(p=0.05/2, df=.x, lower.tail=FALSE))\n\ntibble(df,critical_t) %>% \n  ggplot(aes(x=df, y=critical_t))+\n  geom_point()+\n  geom_line()+\n  geom_hline(aes(yintercept=1.96), linetype=\"dashed\", colour=\"red\")+\n  labs(x= \"Degrees of Freedom\",\n       y= expression(paste(\"Critical value of \", italic(\"t\"))))\nlsmodel1 <- lm(height ~ type, data = darwin)\nsummary(lsmodel1)## \n## Call:\n## lm(formula = height ~ type, data = darwin)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.1917 -1.0729  0.8042  1.9021  3.3083 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  20.1917     0.7592  26.596   <2e-16 ***\n## typeSelf     -2.6167     1.0737  -2.437   0.0214 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.94 on 28 degrees of freedom\n## Multiple R-squared:  0.175,  Adjusted R-squared:  0.1455 \n## F-statistic:  5.94 on 1 and 28 DF,  p-value: 0.02141\nbroom::tidy(lsmodel1)\ntidy_model1 <- broom::tidy(lsmodel1)\n\ntidy_model1[[2,2]] / tidy_model1[[2,3]]## [1] -2.437113"},{"path":"testing.html","id":"paired-t","chapter":"14 Testing","heading":"14.3 Paired t","text":"structure linear model far produced output standard two-sample Student's t-test. However, first calculated estimates hand - started making average paired differences height. generate equivalent paired t-test, simply add factor pairs linear model formula:Note made pair factor - pair 2 greater pair 1 - nott make sense treat number values.table coefficients suddenly looks lot complicated! now intercept height crossed plant pair 1:second row now compares mean heights Crossed Selfed plants pairThe second row now compares mean heights Crossed Selfed plants pairrows three 16 compare average difference pair (Crossed Selfed combined) pair 1rows three 16 compare average difference pair (Crossed Selfed combined) pair 1Again linear model computes every possible combination t-statistic P-value, however one care difference Cross Self-pollinated plant heights. ignore pair comparisons second row gives us paired t-test. 'difference height Cross Self-pollinated plants hold pairs constant.'completeness generate confidence intervals paired t-test.can see estimate mean difference identical 95% confidence intervals now slightly different. particular version actually increased level uncertainty including pair parameter.\nChoosing right model\n\nfuture sessions work model building simplification, case good priori reason include pair initial model, simple tests can see safe remove , appear adding explanation difference heights self cross-fertilised plants.\n","code":"\nlsmodel_darwin <- lm(height ~ type + factor(pair), data = darwin)\nsummary(lsmodel_darwin)## \n## Call:\n## lm(formula = height ~ type + factor(pair), data = darwin)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.4958 -0.9021  0.0000  0.9021  5.4958 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     21.7458     2.4364   8.925 3.75e-07 ***\n## typeSelf        -2.6167     1.2182  -2.148   0.0497 *  \n## factor(pair)2   -4.2500     3.3362  -1.274   0.2234    \n## factor(pair)3    0.0625     3.3362   0.019   0.9853    \n## factor(pair)4    0.5625     3.3362   0.169   0.8685    \n## factor(pair)5   -1.6875     3.3362  -0.506   0.6209    \n## factor(pair)6   -0.3750     3.3362  -0.112   0.9121    \n## factor(pair)7   -0.0625     3.3362  -0.019   0.9853    \n## factor(pair)8   -2.6250     3.3362  -0.787   0.4445    \n## factor(pair)9   -3.0625     3.3362  -0.918   0.3742    \n## factor(pair)10  -0.6250     3.3362  -0.187   0.8541    \n## factor(pair)11  -0.6875     3.3362  -0.206   0.8397    \n## factor(pair)12  -0.9375     3.3362  -0.281   0.7828    \n## factor(pair)13  -3.0000     3.3362  -0.899   0.3837    \n## factor(pair)14  -1.1875     3.3362  -0.356   0.7272    \n## factor(pair)15  -5.4375     3.3362  -1.630   0.1254    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.336 on 14 degrees of freedom\n## Multiple R-squared:  0.469,  Adjusted R-squared:  -0.09997 \n## F-statistic: 0.8243 on 15 and 14 DF,  p-value: 0.6434\ndarwin %>% \n  mutate(pair = as_factor(pair)) %>% \n  lm(height ~ type + pair, data = .) %>% \n  broom::tidy()\nlm(height ~ type + factor(pair), data = darwin) %>% \n  broom::tidy(., conf.int=T) %>% \n  slice(1:2) # just show first two rows\nm1 <- lm(height ~ type, data = darwin) %>% \n  broom::tidy(., conf.int=T) %>% \n  slice(2:2) %>% \n  mutate(model=\"unpaired\")\n\nm2 <- lm(height ~ type + factor(pair), data = darwin) %>% \n  broom::tidy(., conf.int=T) %>% \n  slice(2:2) %>% \n  mutate(model=\"paired\")\n\nrbind(m1,m2) %>% \n  ggplot(aes(model, estimate))+\n  geom_pointrange(aes(ymin=conf.high, ymax=conf.low))+\n  geom_hline(aes(yintercept=0), linetype=\"dashed\")+\n  theme_minimal()+\n  coord_flip()"},{"path":"testing.html","id":"effect-sizes","chapter":"14 Testing","heading":"14.4 Effect sizes","text":"discussed importance using confidence intervals talk effect sizes. 95% confidence intervals overlap intercept, indicates difference means significant \\(\\alpha\\) = 0.05. interestingly allows us talk 'amount difference' treatments, lower margin confidence intervals smallest/minimum effect size. response scale variables useful, can report example least 0.43 inch height difference self crossed fertilised plants \\(\\alpha\\) = 0.05.","code":""},{"path":"testing.html","id":"type-1-and-type-2-errors","chapter":"14 Testing","heading":"14.5 Type 1 and Type 2 errors","text":"repeatability results key part scientific method. Unfortunately often emphasis literature 'novel findings', means unusual/interesting results happen reach statistical significance may likely published. reality know set \\(\\alpha\\) = 0.05, run risk rejecting null hypothesis incorrectly 1 20 experiments (Type 1 error).Type 2 errors. Statistical tests provide probability making Type 1 error (rejecting null hypothesis incorrectly) form P. Type 2 errors? Keeping null hypothesis, rejecting ? finding effect.probability making Type 2 error known \\(1-\\beta\\), \\(\\beta\\) refers statistical 'power'. Working statistical power straightforward simple tests, becomes rapidly diffcult complexity analysis increases... important concept understand.side coin experimental power - strength experiment detect statistical effect one. Power expressed 1-\\(\\beta\\). want beta error typically less 20%. , want power 80%. 80% chance finding effect .\nexperiments/statistical analyses become statistically significant make sample size large enough. respect shows misleading significant result can . interesting result statistically significant, effect size tiny.\n","code":""},{"path":"testing.html","id":"repeatability","chapter":"14 Testing","heading":"14.6 Repeatability","text":"possible know single experiment whether made Type 1 Type 2 errors. However, time experiments eventually repeated literature builds allowing us synthesise evidence. try now & imagine scenario Darwin's experiment repeated another 20 times.example made loop assumes 'know' true mean difference crossed fertilised plants standard deviation 'population'(taken Darwin's experimental data ). loop creates 20 new sampling experiments, calculates estimated mean difference experiment","code":"\nset.seed(1234)\n\nmyList <- vector(\"list\", 20)\ny <- tibble()\n\nfor (i in 1:length(myList)) { \n\nx <-  rnorm(n=12, mean=2.6, sd=2.83)\ndata <- tibble(x)\ntemp <- lm(x~1, data=data) %>% \n  broom::tidy(conf.int=T) \ny <- rbind(y,temp)  \n\n}\n\ny$`experiment number` <- rep(1:20)\n\n# the new dataframe y contains the results of 20 new experiments"},{"path":"testing.html","id":"activity-1-experimental-repeatability","chapter":"14 Testing","heading":"14.7 Activity 1: Experimental Repeatability","text":"example nearly third experiments find statistically significant difference. less formal review research might tally P-values conclude inconsistent results literature.better way look estimates calculated confidence intervalsBy illustrating visually, clearer see results really inconsistent, negative effects inbreeding depression clear see experiments - simply observing effect sampling error.20 studies showed effect inbreeding depression, experiments identical levels uncertainty. can clearly see estimates intervals substantial improvement way report experiments, make comparisons across repeated studies valuable.","code":"\ny %>% \n  mutate(`p value < 0.05` = if_else(p.value > 0.049, \"non-significant\", \"significant\")) %>% \n  group_by(`p value < 0.05`) %>% \n  summarise(`number of experiments`=n())\ny %>% \n  ggplot(aes(x=`experiment number`, y=estimate))+\n  geom_pointrange(aes(ymin = conf.low, ymax=conf.high))+\n  labs(y = \"Estimated mean effect of outcrossing\")+\n  geom_hline(linetype=\"dashed\", yintercept=0.05)+\n  theme_minimal()"},{"path":"testing.html","id":"summary-3","chapter":"14 Testing","heading":"14.8 Summary","text":"chapter finally allowed us calculate P-values test statistical significance experiments using linear models. also compared linear model structures producing paired vs. unpaired t-test.However also learned appreciate potential issues around making Type 1 Type 2 errors, appreciation confidence intervals standardised effect sizes can used assess .single experiment never definitive, reliance reporting P-values uninformative can misleading. Instead reporting estimates confidence intervals allows us report levels uncertainty, provides results informative comparitive studies.","code":""},{"path":"regression.html","id":"regression","chapter":"15 Regression","heading":"15 Regression","text":"","code":""},{"path":"regression.html","id":"introduction-to-regression","chapter":"15 Regression","heading":"15.1 Introduction to Regression","text":"far used linear models analyses two 'categorical' explanatory variables e.g. t-tests. 'continuous' explanatory variable? need use regression analysis, luckily just another 'special case' linear model, can use lm() function already using, can interpret outputs way.","code":"\nlibrary(tidyverse)\nlibrary(rstatix)\nlibrary(performance)"},{"path":"regression.html","id":"linear-regression","chapter":"15 Regression","heading":"15.2 Linear regression","text":"Much like t-test generating linear model, regression analysis interpreting strength 'signal' (change mean values according explanatory variable), vs amount 'noise' (variance around mean).normally visualise regression analysis scatter plot, explanatory (predictor, independent) variable x-axis response (dependent) variable y-axis. Individual data points plotted, attempt draw straight-line relationship throught cloud data points. line 'mean', variability around mean captured calculated standard errors confidence intervals variance.equation linear regression model :\\[ y = + bx \\]\nmay also note basically identical equation straight fit line \\(y = mx +c\\).:y predicted value response variabley predicted value response variablea regression intercept (value y x = 0)regression intercept (value y x = 0)b slope regression lineb slope regression linex value explanatory variablex value explanatory variableThis formula explains mean, need include unexplained residual error term include measure uncertainty\\[ y = + bx + e \\]regression uses two values fit straight line. First need starting point, known regression intercept. categorical predictors mean value y one categories, regression mean value y x = 0. need gradient (value y changes value x changes). allows us draw regression line.linear model analysis estimates values intercept gradient order predict values y given values x.","code":""},{"path":"regression.html","id":"data","chapter":"15 Regression","heading":"15.3 Data","text":"going use example data Australian forestry industry, recording density hardness 36 samples wood different tree species. Wood density fundamental property relatively easy measure, timber hardness, quantified 'amount force required embed 0.444\" steel ball wood half diameter'.regression, can test biological hypothesis wood density can used predict timber hardness, use regression predict timber hardness new samples known density.Timber hardness quantified using 'Janka scale', data going use today comes originally R package SemiPar\nCheck data imported correctly make sure 'tidy' obvious errors missing data\n","code":""},{"path":"regression.html","id":"activity-1-exploratory-analysis","chapter":"15 Regression","heading":"15.4 Activity 1: Exploratory Analysis","text":"Wood density timber hardness appear positively related, relationship appears fairly linear. can look simple strength association dens hardness using correlation","code":"\njanka %>% \n  ggplot(aes(x=dens, y=hardness))+\n  geom_point()"},{"path":"regression.html","id":"activity-2-correlation---generate-pearsons-r","chapter":"15 Regression","heading":"15.5 Activity 2: Correlation - Generate Pearson's R","text":"Can work code needed generate Pearson's R? - Try using google search, check code answer solution.Hint try rstatix package?Correlation coefficients range -1 1 perfectly negative perfectly positive linear relationships. relationship appears strongly positive. Correlation looks association two variables, want go - arguing wood density causes higher values timber hardness. order test hypothesis need go correlation use regression.","code":"\n# cor() does not have a data option so need to use the with() function\nwith(janka, cor(dens, hardness))## [1] 0.9743345\nlibrary(rstatix)\n\njanka %>% \n  cor_test(dens, hardness)"},{"path":"regression.html","id":"regression-in-r","chapter":"15 Regression","heading":"15.6 Regression in R","text":"can fit regression model exactly way fit linear model Darwin's maize data. difference predictor variable continuous rather categorical.\ncareful ordering variables :\n\n\nleft 'tilde' response variable,\n\n\nleft 'tilde' response variable,\n\n\nright predictor.\n\n\nright predictor.\n\nGet wrong way round reverse hypothesis.\nlinear model estimate 'line best fit' using method 'least squares' minimise error sums squares (average distance data points regression line).can add regression line ggplots easily function geom_smooth().Q. blue line represents regression line, shaded interval 95% confidence interval band. notice width interval band move along regression line?95% confidence interval band narrowest middle widest either end regression line. ?performing linear regression, two types uncertainty prediction.First prediction overall mean estimate (ie center fit). second uncertainly estimate calculating slope.combine uncertainties prediction spread high low estimates. away center data get (either direction), uncertainty slope becomes large noticeable factor, thus limits widen.","code":"\njanka_ls1 <- lm(hardness ~ dens, data = janka) \n# specify linear model method for line fitting\n\njanka %>% \n  ggplot(aes(x=dens, y=hardness))+\n  geom_point()+\n  geom_smooth(method=\"lm\")"},{"path":"regression.html","id":"summary-4","chapter":"15 Regression","heading":"15.6.1 Summary","text":"output look familiar , output produced analysis maize data. Including column coefficient estimates, standard error, t-statistic P-value. first row intercept, second row difference mean intercept caused explanantory variable.\nmany ways intercept makes intuitive sense regression model difference model. intercept describes value y (timber hardness) x (wood density) = 0. standard error standard error calculated mean value. wrinkle value y impossible value - timber hardness obviously negative value (anti-hardness???). affect fit line, just means regression line (infinite straight line) can move impossible value ranges.\n\nOne way intercept can made valuable use technique known 'centering'. subtracting average (mean) value x every data point, intercept (x 0) can effectively right-shifted centre data.\n","code":"\nsummary(janka_ls1)## \n## Call:\n## lm(formula = hardness ~ dens, data = janka)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -338.40  -96.98  -15.71   92.71  625.06 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -1160.500    108.580  -10.69 2.07e-12 ***\n## dens           57.507      2.279   25.24  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 183.1 on 34 degrees of freedom\n## Multiple R-squared:  0.9493, Adjusted R-squared:  0.9478 \n## F-statistic:   637 on 1 and 34 DF,  p-value: < 2.2e-16\njanka_ls1 %>% \n  broom::tidy()"},{"path":"regression.html","id":"activity-3-mean-centered-regression","chapter":"15 Regression","heading":"15.7 Activity 3: Mean centered regression","text":"\nNote estimate row 2 - effect density timber hardness changed, intercept now represents estimated mean timber hardness mean wood density e.g. density \\(\\rho\\) = 45.73 average timber hardness janka scale 1469.\n","code":"\ndens_mean <- janka %>% \n  summarise(mean_dens=mean(dens))\n# 45.73333\n\njanka %>% \n  mutate(centered_dens = dens-pull(dens_mean)) %>% \n  lm(hardness ~ centered_dens, data = .) %>% \n  broom::tidy()"},{"path":"regression.html","id":"the-second-row","chapter":"15 Regression","heading":"15.7.1 the second row","text":"second row labelled 'dens'. Density explanatory variable, slope estimated . 57.5 value regression slope (standard error) - timber hardness predicted increase 57.5 janka scale every unit change density.According model summary, estimated change mean statistically significant - effect size sample size unlikely observe relationship null hypothesis (predict timber hardness wood density) true.","code":""},{"path":"regression.html","id":"confidence-intervals-2","chapter":"15 Regression","heading":"15.7.2 Confidence intervals","text":"Just like maize data, can produce upper lower bounds confidence intervals:52.962.157.52.28","code":"\nconfint(janka_ls1)##                   2.5 %     97.5 %\n## (Intercept) -1381.16001 -939.83940\n## dens           52.87614   62.13721\nbroom::tidy(janka_ls1, conf.int=T, conf.level=0.95)"},{"path":"regression.html","id":"effect-size","chapter":"15 Regression","heading":"15.7.3 Effect size","text":"regression model, can also produce standardised effect size. estimate 95% confidence intervals amount change observed, just like maize data can produce standardised measure strong relationship . value represented \\(R^2\\) : proportion variation data explained linear regression analysis.value \\(R^2\\) can found model summaries follows\nTable 15.1: R squared effect size\n","code":"\nsummary(janka_ls1)## \n## Call:\n## lm(formula = hardness ~ dens, data = janka)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -338.40  -96.98  -15.71   92.71  625.06 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -1160.500    108.580  -10.69 2.07e-12 ***\n## dens           57.507      2.279   25.24  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 183.1 on 34 degrees of freedom\n## Multiple R-squared:  0.9493, Adjusted R-squared:  0.9478 \n## F-statistic:   637 on 1 and 34 DF,  p-value: < 2.2e-16\njanka_ls1 %>% \n  broom::glance()"},{"path":"regression.html","id":"assumptions","chapter":"15 Regression","heading":"15.8 Assumptions","text":"Regression models make assumptions linear models - unexplained variation around regression line (residuals) approximately normally distributed, constant variance. can check way.Remember, residuals difference observed values fitted values predicted model. words vertical distance data point fitted value regression line. can take look another function broom package augment(). generates predicted value data point according regression, calculates residuals data point.plot , black fitted regression line red dashed lines representing residuals:can use augmented data really help us understand residual variance looks like, can used diagnose models. perfect model mean residual values = 0, incredibly unlikely ever occur. Instead like seethat 'normal distribution' residuals e.g. residuals close mean, fewer away rough z-distribution.'normal distribution' residuals e.g. residuals close mean, fewer away rough z-distribution.also want see homogeneity residuals e.g. bad model average error greater one end model . might mean uncertainty slope line large values small values vice versa.also want see homogeneity residuals e.g. bad model average error greater one end model . might mean uncertainty slope line large values small values vice versa.example functional, repetitive code - make function reduces amount code needed?example function want make:","code":"\npredict(janka_ls1)\n\nresid(janka_ls1)##         1         2         3         4         5         6         7         8 \n##  259.9152  265.6658  409.4325  472.6899  472.6899  507.1939  581.9525  719.9686 \n##         9        10        11        12        13        14        15        16 \n##  886.7379 1053.5073 1070.7593 1099.5126 1105.2633 1134.0166 1157.0193 1174.2713 \n##        17        18        19        20        21        22        23        24 \n## 1180.0220 1180.0220 1306.5366 1473.3060 1536.5633 1611.3220 1801.0940 1801.0940 \n##        25        26        27        28        29        30        31        32 \n## 1910.3567 2059.8741 2088.6274 2134.6328 2151.8848 2243.8954 2278.3994 2634.9408 \n##        33        34        35        36 \n## 2715.4502 2795.9595 2813.2115 2813.2115 \n##            1            2            3            4            5            6 \n##  224.0848370  161.3341695    3.5674826   44.3101404   76.3101404  140.8061355 \n##            7            8            9           10           11           12 \n##    5.0474583  -15.9685611   92.2620821 -139.5072748   -0.7592772  -79.5126146 \n##           13           14           15           16           17           18 \n##  104.7367180 -145.0166194    2.9807107 -164.2712918  -80.0219592  -50.0219592 \n##           19           20           21           22           23           24 \n##  -36.5366437 -293.3060005 -136.5633428  148.6779800  -91.0940467  208.9059533 \n##           25           26           27           28           29           30 \n##  -30.3567287  -79.8740831 -268.6274205 -114.6327603 -171.8847628   66.1045576 \n##           31           32           33           34           35           36 \n## -338.3994472  625.0591692  -15.4501754   94.0404799  -73.2115225  326.7884775\njanka_ls1 %>% \n  broom::augment() %>% \n  head()\naugmented_ls1 <- janka_ls1 %>% \n  broom::augment()\n\naugmented_ls1 %>% \n    ggplot(aes(x=dens, \n               y=.fitted))+\n    geom_line()+ \n  geom_point(aes(x=dens, \n                 y=hardness))+\n  geom_segment(aes(x=dens, \n                   xend=dens, \n                   y=.fitted, \n                   yend=hardness), \n               linetype=\"dashed\", colour=\"red\")\n# A line connecting all the data points in order \np1 <- augmented_ls1 %>% \n  ggplot(aes(x=dens, y=hardness))+\n  geom_line()+\n  ggtitle(\"Full Data\")\n\n# Plotting the fitted values against the independent e.g. our regression line\np2 <- augmented_ls1 %>% \n  ggplot(aes(x=dens, y=.fitted))+\n  geom_line()+\n  ggtitle(\"Linear trend\")\n\n# Plotting the residuals against the fitted values e.g. remaining variance\np3 <- augmented_ls1 %>% \n  ggplot(aes(x=.fitted, y=.resid))+\n  geom_hline(yintercept=0, colour=\"white\", size=5)+\n  geom_line()+\n  ggtitle(\"Remaining \\npattern\")\n\n\nlibrary(patchwork)\np1+p2+p3model_plot(data=augmented_ls1, \n            x=\"dens\", \n            y=\"hardness\", \n            title=\"Full data\")\nmodel_plot <- function(data=augmented_ls1, \n                       x=\"dens\", \n                       y=\"hardness\", \n                       title=\"Full data\"){\n  ggplot(aes(x=.data[[x]], \n             y=.data[[y]]), \n         data=data)+\n  geom_line()+\n    theme_bw()+\n      ggtitle(title)\n}\n\np1 <- model_plot()\np2 <- model_plot(y=\".fitted\", title=\"Linear prediction\")\np3 <- model_plot(y=\".resid\", title=\"Remaining pattern\")"},{"path":"regression.html","id":"normal-distribution-3","chapter":"15 Regression","heading":"15.8.1 Normal distribution","text":"can use model diagnostic plots used maize data.\ncan see mostly pretty good, just one two data points outside confidence intervals","code":"\nplot(janka_ls1, which=c(2,2))\nperformance::check_model(janka_ls1, check=c(\"normality\",\"qq\"))"},{"path":"regression.html","id":"equal-variance-1","chapter":"15 Regression","heading":"15.8.2 Equal variance","text":"can use model diagnostic plots used maize data.\nsee similar p3 plot constructed manually. plot constructed earlier 'raw' residuals function fitted values. plot produced now 'standardized residuals' - raw residual divided standard deviation.plots suggests residuals constant variance, broadly speaking amount variance y increases x increases. means less confidence predictions high values density. Later see can improve fit model","code":"\nplot(janka_ls1, which=c(1,3))\nperformance::check_model(janka_ls1, check=\"homogeneity\")"},{"path":"regression.html","id":"outliers-1","chapter":"15 Regression","heading":"15.8.3 Outliers","text":"can see just one potential outlier.positional order dataframe? Check data, make sense?","code":"\nplot(janka_ls1, which=c(4,5))\nperformance::check_model(janka_ls1, check=\"outliers\")"},{"path":"regression.html","id":"prediction","chapter":"15 Regression","heading":"15.9 Prediction","text":"Using coefficients intercept slope can make predictions new data.\nestimates intercept slope :Now imagine new wood samples density 65, can use equation linear regression predict timber hardness wood sample ?\\[ y = + bx \\]Rather work values manually, can also use coefficients model directlyBut time unlikely want work predicted values hand, instead can use functions like predict() broom::augment()","code":"\ncoef(janka_ls1)## (Intercept)        dens \n## -1160.49970    57.50667\n# a + bx\n\n-1160.49970 + 57.50667 * 65## [1] 2577.434\ncoef(janka_ls1)[1] + coef(janka_ls1)[2] * 65## (Intercept) \n##    2577.434\npredict(janka_ls1, newdata=list(dens=c(22,35,65)))##         1         2         3 \n##  104.6471  852.2339 2577.4342\nbroom::augment(janka_ls1, \n               newdata=tibble(dens=c(22,35,65)))"},{"path":"regression.html","id":"adding-confidence-intervals","chapter":"15 Regression","heading":"15.9.1 Adding confidence intervals","text":"","code":""},{"path":"regression.html","id":"standard-error","chapter":"15 Regression","heading":"15.9.1.1 Standard error","text":"","code":"\nbroom::augment(janka_ls1, newdata = tibble(dens=c(22,35,65)), se=TRUE)"},{"path":"regression.html","id":"confidence-intervals-3","chapter":"15 Regression","heading":"15.9.1.2 95% Confidence Intervals","text":"really like emmeans package - good producing quick predictions categorical data - can also continuous variables. default produce single mean-centered prediction. list can provided - produce confidence intervals standard.","code":"\nbroom::augment(janka_ls1, newdata=tibble(dens=c(22,35,65)), interval=\"confidence\")\nemmeans::emmeans(janka_ls1, \n                 specs = \"dens\", \n                 at = list(dens = c(22, 35, 65)))##  dens emmean   SE df lower.CL upper.CL\n##    22    105 62.1 34    -21.5      231\n##    35    852 39.1 34    772.8      932\n##    65   2577 53.5 34   2468.8     2686\n## \n## Confidence level used: 0.95"},{"path":"regression.html","id":"activity-4-prediction","chapter":"15 Regression","heading":"15.10 Activity 4: Prediction","text":"Hint - first make new R object contains predictions, work add two dataframes one plot.","code":"\npred_newdata <- broom::augment(janka_ls1, \n               newdata=tibble(dens=c(22,35,65)))\n\njanka %>% \n  ggplot(aes(x=dens, y=hardness))+\n  geom_point()+\n  geom_smooth(method=\"lm\")+\n  geom_point(data=pred_newdata, aes(y=.fitted, x=dens), colour=\"red\")+\n  geom_label(data=pred_newdata, (aes(y=(.fitted+10), x=(dens+3), label=round(.fitted, digits=0))))+\n  theme_bw()+\n  labs(x=\"Density\", y=\"Timber Hardness\")+\n  scale_x_continuous(limits=c(20,80), expand=expansion(add=c(0,5)))"},{"path":"regression.html","id":"summary-5","chapter":"15 Regression","heading":"15.11 Summary","text":"Linear model analyses can extend beyond testing differences means categorical groupings test relationships continuous variables. known linear regression, relationship explanatory variable response variable modelled equation straight line. intercept value y x = 0, often useful, can use 'mean-centered' values wish make intercept intuitive.\nlinear models, regression assumes unexplained variability around regression line, normally distributed constant variance.regression fitted possible predict values y values x, uncertainty around predictions can captured confidence intervals.","code":""},{"path":"anova.html","id":"anova","chapter":"16 ANOVA","heading":"16 ANOVA","text":"","code":""},{"path":"anova.html","id":"analysis-of-variance-anova","chapter":"16 ANOVA","heading":"16.1 Analysis of Variance (ANOVA)","text":"far used linear models analyses two 'categorical' explanatory variables e.g. t-tests, regression two 'continuous' variables. However, designs become complicated, number comparisons can quickly become overwhelming, working estimates intervals alone can become harder.designs become elaborate number pairwise t-tests rapidly increases, therefore risk false positives (Type errors). therefore useful complementary approach first asks support difference different means diving multiple comparisons. approach called analysis variance (ANOVA), although tends associated categorical data, see following chapters ANOVA just another type linear model, approach can also extended included continuous variables.","code":""},{"path":"anova.html","id":"maize-data","chapter":"16 ANOVA","heading":"16.2 Maize data","text":"simple linear model maize data :structure fitting linear model, one explanatory variable also known one-way ANOVA. general strategy ANOVA quantify overall variability data set divide variability within groups. can also refer 'signal--noise' ratio, variability explained slope linear model, vs unexplained variance.variation explained fitted linear model, confident can detected real effect estimates mean differences. method fitting model called ordinary least squares.least squares model first quantifies total amount variation (total sum squares, SST) measuring difference individual data points reference point (usually 'grand' mean, see ).Next model quantifies fitted slope, aims produce slope produces least amount squared residuals data points (sum squares regression/ANOVA, SSR/).leaves residual unexplained variation (sum squares error, SSE).way model splitting overall variability (SST) signal (SSR) noise (SSE):\\[ SST = SSR + SSE \\]Remember:SST = sum squared differences data points grand meanSST = sum squared differences data points grand meanSSR = sum squared differences grand mean predicted position linear modelSSR = sum squared differences grand mean predicted position linear modelSSE = sum squared differences predicted position observed positionSSE = sum squared differences predicted position observed position\nLeast squares quantifies ) total least squares, B) treatment least squares, C) error sum squares (SST, SSR, SSE). vertical lines measure distances, squared summed. SST calculated measuring intercept, SSR calculated measuring distance estimates intercept, SSE calculated measuring distance estimates\n","code":"lsmodel1 <- lm(height ~ type, data = darwin)"},{"path":"anova.html","id":"the-anova-table","chapter":"16 ANOVA","heading":"16.2.1 The ANOVA table","text":"want get ANOVA table linear model can use anova() function:Compare output get use summary() function. see F-value P-value df exactly . ANOVA table actually far less information , contains information biology (estimates difference, uncertainty standard errors etc.). amazing many times see tables reported, even though contain least interesting part analysis.can help us simplify effects two levels, need learn use appropriately.ANOVA table six columns two rows information.first column contains information source, signal/regression (first row) error/noise (second row).second column gives degrees freedom, first row number predictors(treatments) (k - 1, including intercept), second row residual degrees freedom (N - k).third column sum squares first row SSR, second row SSE (remember SST = SSR + SSE).fourth column mean sum squares MSR = SSR/(k-1) & MSE = SSE/(N-k). average amounts variability per treatment level.worth stopping briefly point remembering effectively pooled SSE treatments generate MSE. Linear models always use pooled variance approach, can give greater power detecting effects smaller sample sizes, reason need homogeneity variance assumption model.fifth column F statistic (signal--noise ratio). calculated dividing treatment variance residual error variance\\[ F =\\frac{SSR/(k-1)}{SSE/(N-k)} =  \\frac{MSR}{MSE} \\]\nexample F = 5.9, means estimated signal nearly six times larger estimated noise.can use F value sample size treatment levels calculate probability observing ratio signal noise null hypothesis effect treatment true.probability value can looked ANOVA table, calculated F distribution. F-test takes sample size account, probability assigned takes account degrees freedom signal noise.can see use R function pf() recreate exact P-value see ANOVA table.first three arguments F-value, degrees freedom signal, noise. last argument set two directional test.common see P-values reported supporting information (naked P-values). impossible interpret without knowing:test came fromwhat test came fromwhat observed value test waswhat observed value test wasthe degrees freedom.degrees freedom.good (conventional) way report result ANOVA :height cross-pollinated plants significantly taller height self-pollinated plants (F1,28 = 5.9, P = 0.02).know way reporting, emphasises statistical tests underlying biology. report tell us anything heights plants, estimated difference , measure uncertainty around .self pollinated maize plants measured average 17.6 [16-19.1] (mean[95% CI]) inches high, cross-pollinated plants mean height 20.2 [18.6-21.7] inches - difference 2.6 [-0.4-4.8] inches (one-way ANOVA: F1,28 = 5.9, P = 0.02).","code":"\nanova(lsmodel1)\npf(5.9395, 1, 28, lower.tail=FALSE)## [1] 0.02141466"},{"path":"anova.html","id":"two-way-anova","chapter":"16 ANOVA","heading":"16.3 Two-way ANOVA","text":"Two way ANOVA (might guess) includes two explanatory variables. Usually treatments interest, example stick including pair variable.can look table using anova() function againNote degrees freedom initially residuals, now 'used' new term complex model. SSE now used SSR explained pair term.\nalready able predict last time looked model structure, pairing really anything ( F< 1). pairing 'nothing' still expect F ratio ~ 1. However, can see actually quite bit lower , implies 'negative variance component' - actually increased relative proportion SSE compared SSR .\n\nmean squares regression smaller residuals implies problem experimental design. result undersampling (pairs needed), however also pairs sampled random.\n","code":"\nlsmodel2 <- lm(height ~ type + as.factor(pair), data = darwin)\nanova(lsmodel2)"},{"path":"anova.html","id":"summary-6","chapter":"16 ANOVA","heading":"16.4 Summary","text":"ANOVA tables can built linear model. tables partition variance signal(s) noise, can compared using F-test. complex analyses many pairwise comparisons performed, initial F-test can provide initial evidence whether differences , reducing risk overtesting false positives can generated.","code":""},{"path":"anova.html","id":"activity","chapter":"16 ANOVA","heading":"16.5 Activity","text":"Write short R based report (Rmd) using ANOVA test experimental hypothesis:Set new R project analysis - get talking GithubSet new R project analysis - get talking GithubImport, clean analyse dataImport, clean analyse dataTest experimental hypothesisTest experimental hypothesisProduce data visual summaryProduce data visual summaryProduce short write-upProduce short write-upNow time try put analysis skills action. instructions importing data setting new project answer question, temperature affect frogspawn development? chance practice:Q. frogspawn hatching time vary temperature?Imagine ran manipulative experiment.manipulative study one experimenter changes something experimental study system studies effect change.collected newly-layed frogspawn pond Italian Alps brought back lab, divided 60 water containers. 20 containers’ water temperature kept 13°C, 20 containers kept 18°C remaining 20 containers kept 25°C. high number replicates increases confidence expected difference groups due factor interested . , temperature.monitored water container recorded hatching times (days hatching eggs) spreadsheet (called frogs_messy_data.csv).response variable Hatching_time.response variable Hatching_time.explanatory variable Temperature, 3 levels: 13°C, 18°C 25°C.explanatory variable Temperature, 3 levels: 13°C, 18°C 25°C.want compare means 3 independent groups (13°C, 18°C 25°C temperature groups) one continuous response variable (Hatching time days) one categorical explanatory variable (Temperature). One-way ANOVA appropriate analysis!","code":""},{"path":"anova.html","id":"hypothesis","chapter":"16 ANOVA","heading":"16.5.1 Hypothesis","text":"Always make hypothesis prediction, delve data analysis.hypothesis tentative answer well-framed question, referring mechanistic explanation expected pattern. can verified via predictions, can tested making additional observations performing experiments.backed level knowledge study system.case, knowing frogspawn takes around 2-3 weeks hatch optimal temperatures (15-20°C), can hypothesize lower temperature, longer take frogspawn hatch. hypothesis can therefore : mean frogspawn hatching time vary temperature level. can predict given temperature range, highest temperature (25°C) hatching time reduced.setting R project, import tidy dataset.Hint: check data tidy format.multiple ways present data, equally valid, emphasising different concepts. example first figure uses boxplot data points illustrate differences. Remember median IQR essentially descriptive statistics, inferential.\nFigure 16.1: Frogspawn hatching times 13, 18 25 degrees Celsius. Boxplot displays median, hinges first third quartiles, whiskers extend hinge 1.5X interquartile range. Points represent individual frogspawns.\nWhereas next figure, uses emmeans() package produce estimate means confidence intervals lm() therefore produce inferential statistics, figure illustrates estimates model rather parameters sample.Neither method 'best'.\nFigure 10.4: Time hatching inversely related temperature frogspawn. Circles represent estimated mean hatching times 95% confidence intervals one-way ANOVA (F1,28 = 385.9, P < 0.001). Dashed lines indicate slope mean difference 13-18 degrees 13-25 degrees Celsius. Faded points represent individual data points.\nIncreasing temperatures clear effect reducing time taken frogspawn hatch (one-way ANOVA: F2,57 = 385.9, P < 0.001). 13\\(^\\circ\\) C mean time hatching 26.3 days [25.8-26.8 95% CI], reduced average 5.3 days [4.57 - 6.02] 18\\(^\\circ\\) C 10.1 days [9.37 - 10.82] 25\\(^\\circ\\) C.","code":"\n#___________________________----\n\n# SET UP ----\n## An analysis of the development time of frogspawn in response to water temperature ----\n#___________________________----\n\n# PACKAGES ----\nlibrary(tidyverse)\n#___________________________----\n\n# IMPORT DATA ----\nfrogs <- read_csv(\"data/frogs_messy_data.csv\")\n#___________________________----\n\n# TIDY DATA ----\nfrogs <- frogs %>% \n  rename(\"13\" = Temperature13,\n         \"18\" = Temperature18,\n         \"25\" = Temperature25,\n         frogspawn_id = `Frogspawn sample id`) %>% \n  pivot_longer(`13`:`25`, names_to=\"temperature\", values_to=\"days\") %>% \n  drop_na(days)\n#___________________________----\n# ANALYSIS ----\nlsmodel_frogs1 <- lm(days ~ temperature, data = frogs)\n\n# summary(lsmodel_frogs1)\n\n# anova(lsmodel_frogs1)\n\nbroom::tidy(lsmodel_frogs1, conf.int = T)\n#___________________________----\nplot(lsmodel_frogs1)\nperformance::check_model(lsmodel_frogs1,\n                         check = c(\"qq\", \"outliers\", \"homogeneity\"))"},{"path":"multivariate-linear-models.html","id":"multivariate-linear-models","chapter":"17 Multivariate linear models","heading":"17 Multivariate linear models","text":"far worked almost exclusively single explanatory variables either continuous (regression) categorical (t-test ANOVA). analyses one possible explanatory variable? Extra terms can easily incorporated linear models order test .","code":""},{"path":"multivariate-linear-models.html","id":"factorial-linear-models","chapter":"17 Multivariate linear models","heading":"17.1 Factorial linear models","text":"example data response ground plant biomass production grassland plots relation two resource addition treatments. addition Fertiliser soil addition Light grassland understorey. biomass limited nutrients soil, expect addition fertiliser increase production. biomass limited low levels light caused plant crowding expect addition light increase biomass.first check data look top rows, can see shows application non-application fertiliser light additions, four possible combinations present, known fully factorial design:control (F- L-, added light fertiliser)control (F- L-, added light fertiliser)fertiliser (F+ L-)fertiliser (F+ L-)light (F- L+)light (F- L+)addition (F+ L+)addition (F+ L+)Close inspection dataset shows data presented two ways:Column 1 shows status Fertiliser (F +/-) (two levels)Column 1 shows status Fertiliser (F +/-) (two levels)Column 2 shows status Light (L +/-) (two levels)Column 2 shows status Light (L +/-) (two levels)Column 3 shows whether fertiliser light applied (four levels, combination previous two columns)Column 3 shows whether fertiliser light applied (four levels, combination previous two columns)Column 4 shows biomassColumn 4 shows biomass","code":"\nbiomass <- read_csv(here::here(\"book\", \"files\", \"biomass.csv\"))\n# check the structure of the data\nglimpse(biomass)\n\n# check data is in a tidy format\nhead(biomass)\n\n# check variable names\ncolnames(biomass)\n\n# check for duplication\nbiomass %>% \n  duplicated() %>% \n  sum()\n\n# check for typos - by looking at impossible values\nbiomass %>% \n  summarise(min=min(Biomass.m2, na.rm=TRUE), \n            max=max(Biomass.m2, na.rm=TRUE))\n\n# check for typos by looking at distinct characters/values\nbiomass %>% \n  distinct(Fert)\n\nbiomass %>% \n  distinct(Light)\n\nbiomass %>% \n  distinct(FL)\n\n# missing values\nbiomass %>% \n  is.na() %>% \n  sum()\n\n# quick summary\n\nsummary(biomass)## Rows: 64\n## Columns: 4\n## $ Fert       <chr> \"F-\", \"F-\", \"F-\", \"F-\", \"F-\", \"F-\", \"F-\", \"F-\", \"F-\", \"F-\",~\n## $ Light      <chr> \"L-\", \"L-\", \"L-\", \"L-\", \"L-\", \"L-\", \"L-\", \"L-\", \"L-\", \"L-\",~\n## $ FL         <chr> \"F-L-\", \"F-L-\", \"F-L-\", \"F-L-\", \"F-L-\", \"F-L-\", \"F-L-\", \"F-~\n## $ Biomass.m2 <dbl> 254.2, 202.0, 392.4, 455.3, 359.1, 386.5, 355.2, 323.1, 373~## [1] \"Fert\"       \"Light\"      \"FL\"         \"Biomass.m2\"\n## [1] 0## [1] 0\n##      Fert              Light                FL              Biomass.m2   \n##  Length:64          Length:64          Length:64          Min.   :152.3  \n##  Class :character   Class :character   Class :character   1st Qu.:370.1  \n##  Mode  :character   Mode  :character   Mode  :character   Median :425.9  \n##                                                           Mean   :441.6  \n##                                                           3rd Qu.:517.2  \n##                                                           Max.   :750.4"},{"path":"multivariate-linear-models.html","id":"data-summary","chapter":"17 Multivariate linear models","heading":"17.2 Data summary","text":"64 observations four variables, last column response variable (biomass) three columns two different ways indicating experimental design.use column 3 - treating design though one-way ANOVA (four levels)use column 3 - treating design though one-way ANOVA (four levels)use columns 1 & 2 - treating factorial designIf use columns 1 & 2 - treating factorial designWe look two different ways analyse data , pros cons two approaches.","code":""},{"path":"multivariate-linear-models.html","id":"one-way-anova","chapter":"17 Multivariate linear models","heading":"17.3 One-way ANOVA","text":"\nFigure 6.2: Boxplot individual biomass values (black points) treatment means (red diamonds)\nPlotting data superimposing mean values produces graph shown . Now confident difference sample means, can begin linear model quantify test null hypothesis.use FL column predictor equivalent four-level one way ANOVA.can see control treatment (F- L-) intercept mean 356g standard error 23g. Light treatment adds average 30g biomass (close standard error estimated mean difference - 32.72g). contrast addition fertiliser adds 93g biomass.wanted get precise confidence intervals use broom::tidy(ls_1, conf.int = T) confint(ls1).can visualise differences coefficient plot, see clearly adding light produce slight increase mean biomass samples 95% confidence interval includes zero, real confidence consistent/true effect.\nFigure 17.1: Effects light fertiliser treatments biomass relative untreated control (error bars = 95% CI)\nfourth level - combined fertiliser light treatments? interaction (combined effect) light fertiliser expect average biomass difference caused light average biomass difference caused fertiliser add together approximately value found combined treatment.words one treatment effect size , another treatment effect size B, ANOVA predicts combination effect size combined treatments + B.example can see clearly combining separate treatments add combined value. mean biomass combined treatment well additive prediction.mean biomass combined treatment well expect additive effects alone. suggests may positive interaction (light fertiliser treatments produce sum effect greater predicted looking individual effects).Using one-way ANOVA design able accurately estimate mean difference controlled group combined treatment group. really say anything concrete strength interaction effect e.g. true interaction? confident can effect? strength interaction effect compare main effects?contrast one-way ANOVA approach, factorial design lets us test compare additive effects interaction effects","code":"\nls_1 <- lm(Biomass.m2 ~ FL, data = biomass)\nsummary(ls_1)## \n## Call:\n## lm(formula = Biomass.m2 ~ FL, data = biomass)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -233.619  -42.842    1.356   67.961  175.381 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   355.79      23.14  15.376  < 2e-16 ***\n## FLF-L+         30.12      32.72   0.921  0.36095    \n## FLF+L-         93.69      32.72   2.863  0.00577 ** \n## FLF+L+        219.23      32.72   6.699 8.13e-09 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 92.56 on 60 degrees of freedom\n## Multiple R-squared:  0.4686, Adjusted R-squared:  0.442 \n## F-statistic: 17.63 on 3 and 60 DF,  p-value: 2.528e-08\nGGally::ggcoef_model(ls_1,\n                      show_p_values=FALSE,\n                      signif_stars = FALSE,\n                     conf.level=0.95)\n# combine the average mean differences of the light effect and fertiliser effect\ncoef(ls_1)[2] + coef(ls_1)[3] \n\n# compare this to the average difference of the combined treatment\ncoef(ls_1)[4]##   FLF-L+ \n## 123.8187 \n##  FLF+L+ \n## 219.225"},{"path":"multivariate-linear-models.html","id":"testing-for-interactions","chapter":"17 Multivariate linear models","heading":"17.4 Testing for interactions","text":"\nFigure 17.2: Left illustration additive model, Right illustration model interaction effect.\ndata can best explained additive model, expect new terms shift intercept slope line remain . interaction effect changes relationship see different gradients.\nLook figure determine whether think evidence interaction effect?\nproduce interactive model, need use separate factors fertiliser light rather single fl factor. make model, include main effects Light Fert, additive model explains sufficient variance enough, suspect interaction term add Light:Fert written follows:Notice estimates mean differences previous one-way ANOVA model. fourth line now indicates much effect two factors interacting changes mean. Also note standard error larger, less power accurately estimate interaction main effect.use factorial combination, last line table coefficients estimates size interaction effect around 95g. combining light fertilisation treatments produced biomass equivalent additive predictions, estimate interaction zero. Instead 95g expect additive effects alone. means order work estimated biomass treatment light fertiliser must sum additive effects Light+ Fert interaction effect Light:Fert.","code":"\nbiomass %>% ggplot(aes(x=Fert, y=Biomass.m2, colour = Light, fill = Light, group = Light))+\n    geom_jitter(width=0.1) +\n    stat_summary(\n        geom = \"point\",\n        fun = \"mean\",\n        size = 3,\n        shape = 23\n    )+stat_summary(\n        geom = \"line\",\n        fun = \"mean\",\n        size = 1, linetype = \"dashed\"\n    )\nls_2 <- lm(Biomass.m2 ~ Fert + # main effect\n             Light + # main effect\n             Fert:Light, # interaction term\n           data = biomass)\n\nsummary(ls_2)## \n## Call:\n## lm(formula = Biomass.m2 ~ Fert + Light + Fert:Light, data = biomass)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -233.619  -42.842    1.356   67.961  175.381 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)      355.79      23.14  15.376  < 2e-16 ***\n## FertF+            93.69      32.72   2.863  0.00577 ** \n## LightL+           30.13      32.72   0.921  0.36095    \n## FertF+:LightL+    95.41      46.28   2.062  0.04359 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 92.56 on 60 degrees of freedom\n## Multiple R-squared:  0.4686, Adjusted R-squared:  0.442 \n## F-statistic: 17.63 on 3 and 60 DF,  p-value: 2.528e-08\nGGally::ggcoef_model(ls_2,\n                      show_p_values=FALSE,\n                      signif_stars = FALSE,\n                     conf.level=0.95)"},{"path":"multivariate-linear-models.html","id":"model-estimates-and-confidence-intervals","chapter":"17 Multivariate linear models","heading":"17.4.1 Model estimates and confidence intervals","text":"compare one-way ANOVA model, must add single terms interaction term, add combined treatment first model:\nmake mistake looking main effect light treatment, reporting effect uncertainty intervals cross zero. main effect light gives average effect across two fertiliser treatments. However, interaction effect, know tell whole story - whether light effect depends whether fertiliser applied.\n\n, significant interaction term, must consider main effects, regardless whether significant .\n","code":"\n# model 1\ncoef(ls_1)[4]\n\n# model 2\ncoef(ls_2)[2] + coef(ls_2)[3] + coef(ls_2)[4]##  FLF+L+ \n## 219.225 \n##  FertF+ \n## 219.225"},{"path":"multivariate-linear-models.html","id":"anova-tables","chapter":"17 Multivariate linear models","heading":"17.5 ANOVA tables","text":"made linear model interaction term, report whether interaction significant? report main effect terms interaction present?Start interactionIn previous chapters ran anova() function directly linear model. works well simple & 'balanced' designs (equal sample sizes level factor), can misleading 'unbalanced' designs models complex interactions.order report F statistic interaction effect, need carry F-test two models, one one without interaction effect. easy function drop1()F-test testing null hypothesis true interaction effect. significance test rejects null hypothesis (just). drop1() function also provides Akaike information criterion (AIC), alternative method model selection (later).now write follows:interactive effect light fertiliser treatments (ANOVA F1,60 = 4.25, P = 0.044) combining treatments produced substantially biomass (95.4g [95% CI: 2.8 - 188]) expected additive effects alone (Fertiliser 93.7g [28.2 - 159.2], Light 30.1g [-35.3 - 95.6]).make mistake just reporting statistics, interesting bit size effect (estimate) uncertainty (confidence intervals).\nRemember check assumptions full model\nMain effectsA good thing drop1() function interactions model, stops . interaction effect significant, main effects must included, even significant . can make models test main effects less important already know interaction term provides main result.decide include reports main effect estimates confidence intervals come full model, need produce interaction free model produce accurate F-values (especially unbalanced designs, see ).\ncan use reduced model get F values, reports estimates come full model.\n","code":"\ndrop1(ls_2, test = \"F\")\n# we have to remove the interaction term before we can keep using drop1()\n\nls_3 <- lm(Biomass.m2 ~ Fert + Light, data = biomass)\n\ndrop1(ls_3, test = \"F\")"},{"path":"multivariate-linear-models.html","id":"balancedunbalanced-designs","chapter":"17 Multivariate linear models","heading":"17.6 Balanced/Unbalanced designs","text":"\nunbalanced design run anova() function model, order variables included can effect e.g.\n\nlm(Fert + Light) give different anova table \n\nlm(Light + Fert)\nexamples , unlikely find much difference running drop1() function anova() complex reduced models. designs 'balanced' (equal numbers level predictor). designs balanced order matters use anova() - sum squares calculated sequentially (order formula), get different results depending order assemble predictors model!","code":""},{"path":"multivariate-linear-models.html","id":"practice","chapter":"17 Multivariate linear models","heading":"17.6.1 Practice","text":"start making deliberately unbalanced dataset","code":"\n# make three vectors and combine them into a new tibble\n\nheight <- c(50,57,91,94,102,110,57,71,85,105,120)\nsize <- c(rep(\"small\", 2), rep(\"large\", 4), rep(\"small\", 3), rep(\"large\", 2))\ntreatment <- c(rep(\"Control\", 6), rep(\"Removal\", 5))\n\nunbalanced <- tibble(height, size, treatment)\n\nunbalanced"},{"path":"multivariate-linear-models.html","id":"activity-1-sums-of-squares","chapter":"17 Multivariate linear models","heading":"17.7 Activity 1: Sums of Squares","text":"drop1 function drops one term model, adds back drops new one matter order included.","code":"\nmodel_1 <- lm(height ~ treatment + size, data = unbalanced)\nanova(model_1)\n\nmodel_2 <- lm(height ~ size + treatment, data = unbalanced)\nanova(model_2)\ndrop1(model_1)\ndrop1(model_2)"},{"path":"multivariate-linear-models.html","id":"post-hoc","chapter":"17 Multivariate linear models","heading":"17.8 post-hoc","text":"example unnecessary spend time looking pairwise comparisons four possible levels, interesting finding report strength interaction effect. possible generate estimated means, produce pairwise comparisons emmeans() package","code":"\nemmeans::emmeans(ls_2, specs = pairwise ~ Light + Fert + Light:Fert) %>% \n  confint()\n# including the argument pairwise in front of the ~ prompts the post-hoc pairwise comparisons.\n # $emmeans contains the estimate mean values for each possible combination (with confidence intervals)\n # $ contrasts contains tukey test post hoc comparisons between levels## $emmeans\n##  Light Fert emmean   SE df lower.CL upper.CL\n##  L-    F-      356 23.1 60      310      402\n##  L+    F-      386 23.1 60      340      432\n##  L-    F+      449 23.1 60      403      496\n##  L+    F+      575 23.1 60      529      621\n## \n## Confidence level used: 0.95 \n## \n## $contrasts\n##  contrast          estimate   SE df lower.CL upper.CL\n##  (L- F-) - (L+ F-)    -30.1 32.7 60     -117    56.35\n##  (L- F-) - (L- F+)    -93.7 32.7 60     -180    -7.22\n##  (L- F-) - (L+ F+)   -219.2 32.7 60     -306  -132.75\n##  (L+ F-) - (L- F+)    -63.6 32.7 60     -150    22.90\n##  (L+ F-) - (L+ F+)   -189.1 32.7 60     -276  -102.63\n##  (L- F+) - (L+ F+)   -125.5 32.7 60     -212   -39.06\n## \n## Confidence level used: 0.95 \n## Conf-level adjustment: tukey method for comparing a family of 4 estimates"},{"path":"multivariate-linear-models.html","id":"continuous-linear-models","chapter":"17 Multivariate linear models","heading":"17.9 Continuous Linear Models","text":"previous section looked interaction two categorical variables, can also examine interactions factor continuous variable. Often referred ANCOVA.data experimental study effects low-level atmospheric pollutants drought agricultural yields. experiment aimed see yields soya bean (William variety), affected stress Ozone levels. task first determine whether evidence interaction effect, drop term model report estimates confidence intervals simplified model.","code":"\npollution <- read_csv(here::here(\"book\", \"files\", \"pollution.csv\"))"},{"path":"multivariate-linear-models.html","id":"activity-2-build-your-own-analysis","chapter":"17 Multivariate linear models","heading":"17.10 Activity 2: Build your own analysis","text":"Try make much progress can without checking solutions. Click boxes need help/check working","code":"\n# check the structure of the data\nglimpse(pollution)\n\n# check data is in a tidy format\nhead(pollution)\n\n# check variable names\ncolnames(pollution)\n\n# check for duplication\npollution %>% \n  duplicated() %>% \n  sum()\n\n# check for typos - by looking at impossible values\n# quick summary\n\nsummary(biomass)\n\n# check for typos by looking at distinct characters/values\npollution %>% \n  distinct(Stress)\n\n\n# missing values\nbiomass %>% \n  is.na() %>% \n  sum()## Rows: 30\n## Columns: 4\n## $ Stress  <chr> \"Well-watered\", \"Well-watered\", \"Well-watered\", \"Well-watered\"~\n## $ SO2     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.02, 0.02, 0.02, 0.02, 0.02, 0.~\n## $ O3      <dbl> 0.02, 0.05, 0.07, 0.08, 0.10, 0.02, 0.05, 0.07, 0.08, 0.10, 0.~\n## $ William <dbl> 8.623533, 8.690642, 8.360071, 8.151910, 8.032685, 8.535426, 8.~## [1] \"Stress\"  \"SO2\"     \"O3\"      \"William\"\n## [1] 0\n##      Fert              Light                FL              Biomass.m2   \n##  Length:64          Length:64          Length:64          Min.   :152.3  \n##  Class :character   Class :character   Class :character   1st Qu.:370.1  \n##  Mode  :character   Mode  :character   Mode  :character   Median :425.9  \n##                                                           Mean   :441.6  \n##                                                           3rd Qu.:517.2  \n##                                                           Max.   :750.4## [1] 0\npollution %>% \n  ggplot(aes(x = O3, y = William))+\n  geom_point()+\n  geom_smooth(method = \"lm\")+\n  facet_wrap(~ Stress)+\n    labs(x = expression(paste(Ozone~mu~L~L^-1)),\n       y = expression(paste(Log~Yield~(kg~ha^-1))))\nWilliam_ls1 <- lm(William ~ O3 + Stress + O3:Stress, data = pollution)\n\nWilliam_ls1 %>% \n    broom::tidy(conf.int = T)"},{"path":"multivariate-linear-models.html","id":"check-the-model-fit","chapter":"17 Multivariate linear models","heading":"17.10.1 Check the model fit","text":"","code":"\nperformance::check_model(William_ls1)"},{"path":"multivariate-linear-models.html","id":"simplify-the-model","chapter":"17 Multivariate linear models","heading":"17.10.2 Simplify the model","text":"Testing dropping interaction term significantly reduce variance explainedMaking simpler modelGet F values simpler modelReport estimates confidence intervals new model","code":"\ndrop1(William_ls1, test = \"F\")\nWilliam_ls2 <- lm(William ~ O3 + Stress, data = pollution) \ndrop1(William_ls2, test = \"F\")\nWilliam_ls2 %>% \n    broom::tidy(conf.int = T)"},{"path":"multivariate-linear-models.html","id":"section","chapter":"17 Multivariate linear models","heading":"17.10.2.1 ","text":"Making simpler model","code":"\nWilliam_ls2 <- lm(William ~ O3 + Stress, data = pollution) "},{"path":"multivariate-linear-models.html","id":"section-1","chapter":"17 Multivariate linear models","heading":"17.10.2.2 ","text":"Get F values simpler model","code":"\ndrop1(William_ls2, test = \"F\")"},{"path":"multivariate-linear-models.html","id":"section-2","chapter":"17 Multivariate linear models","heading":"17.10.2.3 ","text":"Report estimates confidence intervals new model","code":"\nWilliam_ls2 %>% \n    broom::tidy(conf.int = T)"},{"path":"multivariate-linear-models.html","id":"summary-7","chapter":"17 Multivariate linear models","heading":"17.11 Summary","text":"Always good hypothesis including interactionAlways good hypothesis including interactionWhen models significant interaction effects must always consider main terms even significant themselvesWhen models significant interaction effects must always consider main terms even significant themselvesReport F values interactions priorityReport F values interactions priorityIF interactions significant estimates come full model, F-values come reduced model (main effects). interaction terms significant can removed (model simplification).interactions significant estimates come full model, F-values come reduced model (main effects). interaction terms significant can removed (model simplification).Use drop1() avoid mistakes using unbalanced experiment designUse drop1() avoid mistakes using unbalanced experiment designAlways report estimates effect sizes - important bit - easy lose sight models get complicatedAlways report estimates effect sizes - important bit - easy lose sight models get complicated","code":""},{"path":"complex-models.html","id":"complex-models","chapter":"18 Complex models","heading":"18 Complex models","text":"","code":""},{"path":"complex-models.html","id":"designing-a-model","chapter":"18 Complex models","heading":"18.1 Designing a Model","text":"introduced fruitfly dataset Partridge Farquhar (1981)7. understanding sexual selection reproductive biology fruit flies, know well established 'cost' reproduction terms reduced longevity female fruitflies. data experiment designed test whether increased sexual activity affects lifespan male fruitflies.flies used outbred stock, sexual activity manipulated supplying males either new virgin females day, previously mated females ( Inseminated, remating rates lower), provide females (Control). groups otherwise treated identically.type: type female companion (virgin, inseminated, control(partners = 0))type: type female companion (virgin, inseminated, control(partners = 0))longevity: lifespan dayslongevity: lifespan daysthorax: length thorax micrometres (proxy body size)thorax: length thorax micrometres (proxy body size)sleep: percentage day spent sleepingsleep: percentage day spent sleeping","code":""},{"path":"complex-models.html","id":"hypothesis-1","chapter":"18 Complex models","heading":"18.2 Hypothesis","text":"start formal analysis think clearly sensible parameters test. example, interested effect sexual activity longevity. possible factors may also affect longevity include model well, think hard terms might reasonably expected interact sexual activity affect longevity.exercise just asked try think logically suitable predictors. formal investigation support evidence possibletype - definitely included.type - definitely included.thorax - size flies determine longevity. Carreira et al (2009)8thorax - size flies determine longevity. Carreira et al (2009)8sleep - sleep easily help determine longevity. Thompson et al (2020)9sleep - sleep easily help determine longevity. Thompson et al (2020)9type:sleep - amount sleep (rest) helps promote longevity change depending much activity fly engages awake. Chen et al (2017)10type:sleep - amount sleep (rest) helps promote longevity change depending much activity fly engages awake. Chen et al (2017)10","code":""},{"path":"complex-models.html","id":"checking-the-data","chapter":"18 Complex models","heading":"18.3 Checking the data","text":"now import, clean tidy data. Making sure tidy format, variables useful names, mistakes, missing data typos.Based variables decided test start simple visualisations, understand distribution data, investigate visually relationships wish test.full two--two plot entire dataset, try follow specific plots.","code":"\nGGally::ggpairs(fruitfly)"},{"path":"complex-models.html","id":"activity-1-think-about-your-data","chapter":"18 Complex models","heading":"18.4 Activity 1: Think about your data","text":"Think carefully plots make investigate potential differences relationships wish investigate - examples hidden behind dropdowns.first figure - can investigate whether obvious difference longevities males across three treatments\nFigure 18.1: density distribution longevity across three sexual activity treatments\nQ like size affects longevity? YesNoIn first figure - can investigate whether obvious difference longevities males across three treatments\nFigure 18.2: scatterplot longevity body size (thorax (mm)). trend line added - often good idea look data points without lead conclusion line\nQ like size affects longevity? YesNo\nFigure 18.2: scatterplot thorax longevity - colours indicate treatment types. time included line, help determine think slopes different group\nQ look like size affects longevity differently treatment groups? YesNoHere look though larger flies longer lifespan smaller flies. appears little difference angle slopes groups. mean test model, may decide worth including.also interested potential effect sleep activity, can construct scatter plot sleep longevity, including treatment covariate.\nFigure 18.2: scatter plot proportion time spent sleeping longevity linear model trendline. Points represent individual flies, colours represent treatments.\nplots - trendlines moving direction? YesNoInvestigating can help us determine much evidence potential effect sleep, evidence whether might additive effect one interacts three treatments?","code":"\ncolours <- c(\"cyan\", \"darkorange\", \"purple\")\n\nfruitfly %>% \n  ggplot(aes(x = longevity, y = type, fill = type))+\n  geom_density_ridges(alpha = 0.5)+\n  scale_fill_manual(values = colours)+\n  theme_minimal()+\n  theme(legend.position = \"none\")\nfruitfly %>% \n  ggplot(aes(x = thorax, y = longevity))+\n  geom_point()+\n  theme_minimal()+\n  theme(legend.position = \"none\")\ncolours <- c(\"cyan\", \"darkorange\", \"purple\")\n\nfruitfly %>% \n  ggplot(aes(x=thorax, y = longevity, group = type, colour = type))+\n  geom_point( alpha = 0.6)+\n  geom_smooth(method = \"lm\",\n            se = FALSE)+\n  scale_colour_manual(values = colours)+\n  theme_minimal()\nfruitfly %>% \n  ggplot(aes(x=sleep, y = longevity, group = type, colour = type))+\n  geom_point( alpha = 0.6)+\n  geom_smooth(method = \"lm\",\n            se = FALSE)+\n  scale_colour_manual(values = colours)+\n  theme_minimal()"},{"path":"complex-models.html","id":"designing-a-model-1","chapter":"18 Complex models","heading":"18.5 Designing a model","text":"\ninclude interaction term, numbers produced much less mean estimate just combined main effects.\n\nincluded interaction effect number terms quite long takes consideration understand. can see individual estimates appear interaction strong effect (estimate) appear different null hypothesis interaction effect. use F test look overall effect sure.\n","code":"\n# a full model\nflyls1 <- lm(longevity ~ type + thorax + sleep + type:sleep, data = fruitfly)\n\nflyls1 %>% \n  broom::tidy()# intercept\ncoef(flyls1)[1] + \n  \n# 1*coefficient for virgin treatment  \ncoef(flyls1)[3] + \n  \n# 0.79 * coefficient for thorax size  \n(coef(flyls1)[4]*0.79) + \n  \n# 22 * coefficient for sleep  \n(coef(flyls1)[5]*22) + \n# 22 * 1 * coefficient for interaction\n(coef(flyls1)[7]*22*1)## typeVirgin:sleep \n##        -2.473406"},{"path":"complex-models.html","id":"model-checking-collinearity","chapter":"18 Complex models","heading":"18.6 Model checking & collinearity","text":"start playing terms model, check see even good way fitting measuring data. check assumptions model met.","code":"\nperformance::check_model(flyls1)"},{"path":"complex-models.html","id":"activity-2-model-checking","chapter":"18 Complex models","heading":"18.7 Activity 2: Model checking","text":"Question - assumption homogeneity variance met? YesNoMostly - reference line fairly flat (slight curve).Mostly - reference line fairly flat (slight curve).looks though might increasing heterogeneity larger values, though minor.looks though might increasing heterogeneity larger values, though minor.VERDICT, pretty much ok, fine making inferences.slight curvature indicate might get better fit transformation, perhaps missing variable included model improve residuals. instance overly concerned. See great explainer intepreting residuals11.Question - residuals normally distributed? YesNoYes - QQplot looks pretty good, minor indication right skew, nothing worry .Interpreting QQ plotsQuestion - issue Collinearity? YesNoThis graph clearly shows collinearity. unusual include interaction term, see evidence collinearity terms part interaction take another look12.can collinearity main effects? 1) Nothing 2) Transform 3) Drop one terms.check_performance() function produces visual summary Variance Inflation Factor produced vif() function. measure standard error estimated coefficient. larger (greater 5 10), indicates model problems estimating coefficient. affect model predictions, makes difficult determine estimate change predictor.","code":"\ncar::vif(flyls1)##                 GVIF Df GVIF^(1/(2*Df))\n## type       12.478906  2        1.879508\n## thorax      1.052967  1        1.026142\n## sleep       8.750764  1        2.958169\n## type:sleep 38.749001  2        2.494969"},{"path":"complex-models.html","id":"data-transformations","chapter":"18 Complex models","heading":"18.8 Data transformations","text":"common issues trying fit simple linear regression models response variable normal violates modelling assumption. two things can case:Variable transformation e.g lm(sqrt(x) ~ y, data = data)\nCan sometimes fix linearity\nCan sometimes fix non-normality heteroscedasticity (.e non-constant variance)\nVariable transformation e.g lm(sqrt(x) ~ y, data = data)Can sometimes fix linearityCan sometimes fix linearityCan sometimes fix non-normality heteroscedasticity (.e non-constant variance)Can sometimes fix non-normality heteroscedasticity (.e non-constant variance)Generalized Linear Models (GLMs) change error structure (.e assumption residuals need normal - see next week.)Generalized Linear Models (GLMs) change error structure (.e assumption residuals need normal - see next week.)","code":""},{"path":"complex-models.html","id":"boxcox","chapter":"18 Complex models","heading":"18.8.1 BoxCox","text":"\nBoxCox gets name two inventors, George Box David Cox. Implemented MASS package, applied linear model sytematically applies transformations raising y variable power (lambda).\n\nR output MASS::boxcox() function plots maximum likelihood curve (95% confidence interval - drops dotted lines) best transformation fitting data model.\n\nTable 18.1: Common Box-Cox Transformations\n\nFigure 10.3: standard curve fitted maximum likelihood, dashed lines represent 95% confidence interval range picking 'best' transformation dependent variable\nQuestion - fit model improve square root transformation? YesNo","code":"\n# run this, pick a transformation and retest the model fit\nMASS::boxcox(flyls1)\nflyls_sqrt <- lm(sqrt(longevity) ~ type + thorax + sleep + type:sleep, data = fruitfly)\n\nperformance::check_model(flyls_sqrt)"},{"path":"complex-models.html","id":"model-selection","chapter":"18 Complex models","heading":"18.9 Model selection","text":"Based ANOVA table, appear strong rationale keeping interaction term model (AIC F-test). Therefore can confidently remove interaction, simplifying model making interpretation easier.Question - drop sleep model? YesNoThere good reason remove non-significant interaction terms model, complicate estimates make interpretations difficult. main effects things little ambiguous.main aim prediction, makes sense cautious retain non-significant terms, extra terms make difference R^2 model.focus hypothesis testing, removal non-significant terms can help produce 'true' model, optional. Generally speaking often simpler leave main effects model (carefully considered terms included first place).","code":"\n# use drop1 function to remove top-level terms\ndrop1(flyls1, test = \"F\")\nflyls2 <- lm(longevity ~ type + thorax + sleep, data = fruitfly)\n\ndrop1(flyls2, test = \"F\")"},{"path":"complex-models.html","id":"posthoc","chapter":"18 Complex models","heading":"18.10 Posthoc","text":"Using emmeans package easy way produce estimate mean values (rather mean differences) different categories emmeans. term pairwise included also include post-hoc pairwise comparisons levels tukey test contrasts.\ncontinuous variables (sleep thorax) - emmeans set mean value within dataset, comparisons constant categories average value continuous variables.\n","code":"\nemmeans::emmeans(flyls2, specs = pairwise ~ type + thorax + sleep)## $emmeans\n##  type        thorax sleep emmean   SE  df lower.CL upper.CL\n##  Control      0.821  23.5   61.3 2.26 120     56.8     65.8\n##  Inseminated  0.821  23.5   64.9 1.59 120     61.8     68.1\n##  Virgin       0.821  23.5   48.0 1.59 120     44.9     51.2\n## \n## Confidence level used: 0.95 \n## \n## $contrasts\n##  contrast                                            estimate   SE  df t.ratio\n##  Control 0.82096 23.464 - Inseminated 0.82096 23.464    -3.63 2.77 120 -1.309 \n##  Control 0.82096 23.464 - Virgin 0.82096 23.464         13.25 2.76 120  4.796 \n##  Inseminated 0.82096 23.464 - Virgin 0.82096 23.464     16.87 2.25 120  7.508 \n##  p.value\n##  0.3929 \n##  <.0001 \n##  <.0001 \n## \n## P value adjustment: tukey method for comparing a family of 3 estimates"},{"path":"complex-models.html","id":"activity-3-write-up","chapter":"18 Complex models","heading":"18.11 Activity 3: Write-up","text":"tested hypothesis sexual activity costly male Drosophila melanogaster fruitflies. Previous research indicated sleep deprived males less attractive females, indicate levels sexual activity might affected sleep impact effect longevity, included interaction term full model. Body size also know affect lifespan, included covariate mode.small interaction effect decreased lifespan increasing sleep treatment groups compared control samples, significantly different effect (F2,118 = 0.512, P = 0.6), therefore dropped full model (Table 15.1).\nTable 18.2: Linear model coefficients\nsignificant overall effect treatment male longevity (Linear model: F2,120 = 30.1, P < 0.001), males paired virgin females lowest mean longevity (48 days, [95%CI: 44.9 - 51.2]) (holding body size sleep constant), compared control males (61.3 days [56.8 - 65.8]) males paired inseminated females (64.9 days [61.8 - 68.1 days]).Post hoc analysis showed differences statistically significant males paired control females compared inseminated (Tukey test: t120 = 4.8, P < 0.001) virgin groups (t120 = 7.5, P < 0.001), overall evidence difference inseminated virgin groups (t120 = -1.309 P < 0.3929) (Figure 19.4).Comparing treatment effects predictors longevity body size sleep, found sleep small effect longevity (mean change -0.05 days [-0.18 - 0.07]) significantly different effect (Linear model: F1,120 = 0.68, P = 0.41). Body size (taken thorax length) significant predictor longevity (F1,120 = 121, P < 0.001), 0.1 mm increase body size adding 14.4 days individual lifespan [11.8 - 17]. appears though body size stronger effect longevity treatment, indicating measurable cost sexual activity males, may less severe females (compared ), less severe measurable predictors.\nFigure 18.3:  scatter plot longevity body size across three treatments differening male sexual activity. Fitted model slopes reduced linear model (main effects thorax size, sleep treatment group), 95% confidence intervals, circles individual data points. Marginal plots density plot distributions thorax length longevity split treatments.\n","code":"\nlibrary(kableExtra)\nflyls2 %>% broom::tidy(conf.int = T) %>% \n select(-`std.error`) %>% \nmutate_if(is.numeric, round, 2) %>% \nkbl(col.names = c(\"Predictors\",\n                    \"Estimates\",\n                    \"Z-value\",\n                    \"P\",\n                    \"Lower 95% CI\",\n                    \"Upper 95% CI\"),\n      caption = \"Linear model coefficients\", \n    booktabs = T) %>% \n   kable_styling(full_width = FALSE, font_size=16)"},{"path":"complex-models.html","id":"summary-8","chapter":"18 Complex models","heading":"18.12 Summary","text":"chapter worked scientific knowledge develop testable hypotheses built statistical models formally assess . now working pipeline tackling complex datasets, developing insights producing explaining robust linear models.","code":""},{"path":"complex-models.html","id":"checklist-3","chapter":"18 Complex models","heading":"18.12.1 Checklist","text":"Think carefully hypotheses test, use scientific knowledge background reading support thisThink carefully hypotheses test, use scientific knowledge background reading support thisImport, clean understand dataset: use data visuals investigate trends determine clear support hypothesesImport, clean understand dataset: use data visuals investigate trends determine clear support hypothesesFit linear model, including interaction terms cautionFit linear model, including interaction terms cautionInvestigate fit model, understand parameters may never perfect, classic patterns residuals may indicate poorly fitting model - sometimes can fixed careful consideration missing variables data transformationInvestigate fit model, understand parameters may never perfect, classic patterns residuals may indicate poorly fitting model - sometimes can fixed careful consideration missing variables data transformationTest removal interaction terms model, look AIC significance testsTest removal interaction terms model, look AIC significance testsMake sure understand output model summary, sense check graphs madeMake sure understand output model summary, sense check graphs madeThe direction size effects priority - produce estimates uncertainties. Make sure observations clear.direction size effects priority - produce estimates uncertainties. Make sure observations clear.Write-significance test results, taking care report just significance (required parts significance test). know report? Within complex model - reporting t indicate slope line single term intercept, F overall effect predictor across levels, post-hoc wish compare across levels.Write-significance test results, taking care report just significance (required parts significance test). know report? Within complex model - reporting t indicate slope line single term intercept, F overall effect predictor across levels, post-hoc wish compare across levels.Well described tables figures can enhance results sections - take time make sure informative attractive.Well described tables figures can enhance results sections - take time make sure informative attractive.","code":""},{"path":"complex-models.html","id":"supplementary-code","chapter":"18 Complex models","heading":"18.13 Supplementary code","text":"sjPlot really nice package helps produce model summaries automatically\n          1\n          \n           \n          CI = Confidence Interval\n          ","code":"\nlibrary(sjPlot)\ntab_model(flyls2)\nlibrary(gtsummary)\ntbl_regression(flyls2)"},{"path":"generalized-linear-models.html","id":"generalized-linear-models","chapter":"19 Generalized Linear Models","heading":"19 Generalized Linear Models","text":"","code":""},{"path":"generalized-linear-models.html","id":"motivation","chapter":"19 Generalized Linear Models","heading":"19.1 Motivation","text":"previous workshop seen linear models powerful modelling tool.\nHowever, satisfy following assumptions:linear relationship predictors mean response value.Variances equal across predicted values response (homoscedatic)Errors normally distributed.Samples collected random.omitted variables importanceIf assumptions 1-3 violated can often transform response variable\ntry fix (Box-Cox & transformation).\nHowever, lot cases either possible (e.g binary output)\nwant explicitly model underlying distribution (e.g count data).\nInstead, can use Generalized Linear Models (GLMs) let us change error structure (assumption 3) something normal distribution.","code":""},{"path":"generalized-linear-models.html","id":"generalised-linear-models-glms","chapter":"19 Generalized Linear Models","heading":"19.2 Generalised Linear Models (GLMs)","text":"Generalised Linear Models (GLMs) :linear predictor.linear predictor.error/variance structure.error/variance structure.link function (like 'internal' transformation).link function (like 'internal' transformation).first (1) familiar, everything comes ~ linear model formula. equation \\(\\beta_0 + \\beta_1\\). second (2) also familiar, variance measures error structure model \\(\\epsilon\\). ordinary least squares model uses normal distribution, GLMs able use wider range distributions including poisson, binomial Gamma. third component (3) less familiar, link function equivalent transformation ordinary least squares model. However, rather transforming data, transform predictions made linear predictors. Common link functions log square root.\nMaximum Likelihood - Generalised Linear Models fit regression line finding parameter values best fit model data. similar way ordinary least squares finds line best fit reducing sum squared errors. fact data normally distributed residuals, particular form maximum likelihood least squares.\n\nHowever normal (gaussian) distribution good model lots types data, binary data, good example one investigate workshop.\n\nMaximum likelihood provides generalized approach model fitting includes, broader , least squares.\n\nadvantage least squares method using can generate precise equations fit line. contrast calculations GLMs (beyond scope course) approximate, essentially multiple potential best fit lines made compared .\n\nsee two main differences GLM output:\n\nmodel one mean variance calculated separately (e.g. normal distributions), uncertainty estimates use t distribution; compare complex simplified models (using anova() drop1()) use F-test.\n\nHowever, provide distributions mean variance expected change together (Poisson Binomial), calculate uncertainty estimates using z distribution, compare models chi-square distribution.\nsimple linear regression model used far special cases GLM:equivalent toCompared lm(), glm() function takes additional argument called family, \nspecifies error structure link function.default link function normal (Gaussian) distribution identity, transformation neededi.e. mean \\(\\mu\\) :\\[\n\\mu = \\beta_0 + \\beta_1 X\n\\]Defaults usually good choices (shown bold ):exactly . surprising, maximum likelihood fitted ordinary least squares model.","code":"lm(height ~ weight)glm(height ~ weight, family=gaussian(link=identity))\nflyls <- lm(longevity ~ type + thorax + sleep, data = fruitfly)\nsummary(flyls)## \n## Call:\n## lm(formula = longevity ~ type + thorax + sleep, data = fruitfly)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -28.153  -6.836  -2.191   7.196  29.046 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     -56.04502   11.17882  -5.013 1.87e-06 ***\n## typeInseminated   3.62796    2.77122   1.309    0.193    \n## typeVirgin      -13.24603    2.76198  -4.796 4.70e-06 ***\n## thorax          144.43008   13.11616  11.012  < 2e-16 ***\n## sleep            -0.05281    0.06383  -0.827    0.410    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 11.23 on 120 degrees of freedom\n## Multiple R-squared:  0.6046, Adjusted R-squared:  0.5914 \n## F-statistic: 45.88 on 4 and 120 DF,  p-value: < 2.2e-16\nflyglm <- glm(longevity ~ type + thorax + sleep, \n             family = gaussian(link = \"identity\"),\n             data = fruitfly)\nsummary(flyglm)## \n## Call:\n## glm(formula = longevity ~ type + thorax + sleep, family = gaussian(link = \"identity\"), \n##     data = fruitfly)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -28.153   -6.836   -2.191    7.196   29.046  \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     -56.04502   11.17882  -5.013 1.87e-06 ***\n## typeInseminated   3.62796    2.77122   1.309    0.193    \n## typeVirgin      -13.24603    2.76198  -4.796 4.70e-06 ***\n## thorax          144.43008   13.11616  11.012  < 2e-16 ***\n## sleep            -0.05281    0.06383  -0.827    0.410    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for gaussian family taken to be 126.0381)\n## \n##     Null deviance: 38253  on 124  degrees of freedom\n## Residual deviance: 15125  on 120  degrees of freedom\n## AIC: 966.2\n## \n## Number of Fisher Scoring iterations: 2"},{"path":"generalized-linear-models.html","id":"section-3","chapter":"19 Generalized Linear Models","heading":"19.2.0.1 ","text":"exactly . surprising, maximum likelihood fitted ordinary least squares model.","code":"\nflyglm <- glm(longevity ~ type + thorax + sleep, \n             family = gaussian(link = \"identity\"),\n             data = fruitfly)\nsummary(flyglm)## \n## Call:\n## glm(formula = longevity ~ type + thorax + sleep, family = gaussian(link = \"identity\"), \n##     data = fruitfly)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -28.153   -6.836   -2.191    7.196   29.046  \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     -56.04502   11.17882  -5.013 1.87e-06 ***\n## typeInseminated   3.62796    2.77122   1.309    0.193    \n## typeVirgin      -13.24603    2.76198  -4.796 4.70e-06 ***\n## thorax          144.43008   13.11616  11.012  < 2e-16 ***\n## sleep            -0.05281    0.06383  -0.827    0.410    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for gaussian family taken to be 126.0381)\n## \n##     Null deviance: 38253  on 124  degrees of freedom\n## Residual deviance: 15125  on 120  degrees of freedom\n## AIC: 966.2\n## \n## Number of Fisher Scoring iterations: 2"},{"path":"generalized-linear-models.html","id":"workflow-for-fitting-a-glm","chapter":"19 Generalized Linear Models","heading":"19.3 Workflow for fitting a GLM","text":"Exploratory data analysisChoose suitable error termChoose suitable mean function (link function)Fit model\nResidual checks model fit diagnostics\nRevise model (transformations etc.)\nResidual checks model fit diagnosticsRevise model (transformations etc.)Model simplification requiredCheck final model \ntransform data e.g. log sqrt, changes mean variance time (everything gets squished ). might fine, can lead difficult model fits need reduce unequal variance leads change (often curvature) way predictors fit response variable.\n\nGLMs model mean variability independently. link function produces transformation predictors mean, relationship mean data points modeled separately.\n","code":""},{"path":"generalized-linear-models.html","id":"poisson-regression-for-count-data-or-rate-data","chapter":"19 Generalized Linear Models","heading":"19.4 Poisson regression (for count data or rate data)","text":"Count rate data ubiquitous life sciences (e.g number parasites per microlitre blood, number species counted particular area). type data discrete non-negative.\ncases assuming response variable normally distributed typically sensible.\nPoisson distribution lets us model count data explicitly.Recall simple linear regression case (.e GLM Gaussian error structure identity link). sake clarity consider single explanatory variable \\(\\mu\\) mean Y:\\[\n\\begin{aligned}\n\\mu & = \\beta_0 + \\beta_1X\n\\end{aligned}\n\\]mean function unconstrained, .e value \\(\\beta_0 + \\beta_1X\\) can range \\(-\\infty\\) \\(+\\infty\\). want model count data therefore want constrain mean positive . Mathematically can taking logarithm mean (log default link Poisson distribution). assume count data variance Poisson distributed (discrete, non-negative distribution), obtain Poisson regression model (consistent statistics literature rename \\(\\mu\\) \\(\\lambda\\)):\\[\n\\begin{aligned}\nY & \\sim \\mathcal{Pois}(\\lambda) \\\\\n\\log{\\lambda} & = \\beta_0 + \\beta_1X\n\\end{aligned}\n\\]Note - relationship mean data modelled Poisson variance. relationship predictors mean modelled log transformation.Poisson distribution following characteristics:Discrete variable, defined range \\(0, 1, \\dots, \\infty\\).single rate parameter \\(\\lambda\\), \\(\\lambda > 0\\).Mean = \\(\\lambda\\)Variance = \\(\\lambda\\)model variance equal mean - mean increases variance.Poisson regression case assume mean variance .\nHence, mean increases, variance increases also (heteroscedascity).\nmay may sensible assumption watch ! Just Poisson distribution usually fits well count data, mean Gaussian distribution always work.Recall link function predictors mean rules logarithms (\\(\\log{\\lambda} = k\\)(value predictors), \\(\\lambda = e^k\\)):\\[\n\\begin{aligned}\n\\log{\\lambda} & = \\beta_0 + \\beta_1X \\\\\n\\lambda & = e^{\\beta_0 + \\beta_1X }\n\\end{aligned}\n\\]\nThus effectively modelling observed counts (original scale) using exponential mean function.","code":""},{"path":"generalized-linear-models.html","id":"example-cuckoos","chapter":"19 Generalized Linear Models","heading":"19.5 Example: Cuckoos","text":"study Kilner et al. (1999), authors\nstudied begging rate nestlings relation total mass brood reed warbler chicks cuckoo chicks.\nquestion interest :nestling mass affect begging rates different species?data columns :Mass: nestling mass chick gramsBeg: begging calls per 6 secsSpecies: Warbler CuckooThere seem relationship mass begging calls \ndifferent species. tempting fit linear model data.\nfact, authors\noriginal paper ; reed warbler chicks (solid circles, dashed fitted line) \ncuckoo chick (open circles, solid fitted line):model inadequate. predicting negative begging calls within \nrange observed data, clearly make sense.Let us display model diagnostics plots linear model.residuals plot depicts strong \"funnelling\" effect, highlighting model assumptions violated.\ntherefore try different model structure.response variable case classic count data: discrete bounded zero (.e negative counts). therefore try Poisson model using canonical log link function mean:\\[\n    \\log{\\lambda} = \\beta_0 + \\beta_1 M_i + \\beta_2 S_i + \\beta_3 M_i S_i\n\\]\\(M_i\\) nestling mass \\(S_i\\) dummy variable\\[\nS_i = \\left\\{\\begin{array}{ll}\n        1 & \\mbox{$$ warbler},\\\\\n        0 & \\mbox{otherwise}.\n        \\end{array}\n        \\right.\n\\]term \\(M_iS_i\\) interaction term. Think additional explanatory variable model.\nEffectively lets us different slopes different species (without interaction term assume \nspecies slope relationship begging rate mass, intercept differ).mean regression lines two species look like :Cuckoo (\\(S_i=0\\))\\[\n\\begin{aligned}\n    \\log{\\lambda} & = \\beta_0 + \\beta_1 M_i + (\\beta_2 \\times 0)  + (\\beta_3 \\times M_i \\times 0)\\\\\n    \\log{\\lambda} & = \\beta_0 + \\beta_1 M_i\n\\end{aligned}\n\\]Intercept = \\(\\beta_0\\), Gradient = \\(\\beta_1\\)Intercept = \\(\\beta_0\\), Gradient = \\(\\beta_1\\)Warbler (\\(S_i=1\\))Warbler (\\(S_i=1\\))\\[\n\\begin{aligned}\n    \\log{\\lambda} & = \\beta_0 + \\beta_1 M_i + (\\beta_2 \\times 1)  + (\\beta_3 \\times M_i \\times 1)\\\\\n    \\log{\\lambda} & = \\beta_0 + \\beta_1 M_i + \\beta_2 + \\beta_3M_i\\\\\n\\end{aligned}\n\\]Fit model interaction term R:Note appears negative interaction effect Species:Mass, indicating Begging calls increase mass much expect Warblers compared Cuckoos.##Activity 1: Plot mean regression line species:Hint: Use broom::augment. fit model log scale, get fitted generalized linear response (Y log scale). lines straight. get exponential curve scale original data, specify type.predict = response straight line log-scaled version data. Try :","code":"\ncuckoo <- read_csv(here::here(\"book\", \"files\", \"cuckoo.csv\"))\nhead(cuckoo)\nggplot(cuckoo, aes(x=Mass, y=Beg, colour=Species)) + geom_point()\n## Fit model\n## There is an interaction term here, it is reasonable to think that how calling rates change with size might be different between the two species.\ncuckoo_ls1 <- lm(Beg ~ Mass+Species+Mass:Species, data=cuckoo) \nperformance::check_model(cuckoo_ls1, \n                         check = c(\"homogeneity\",\n                                   \"qq\"))\ncuckoo_glm1 <- glm(Beg ~ Mass + Species + Mass:Species, data=cuckoo, family=poisson(link=\"log\"))\n\nsummary(cuckoo_glm1)## \n## Call:\n## glm(formula = Beg ~ Mass + Species + Mass:Species, family = poisson(link = \"log\"), \n##     data = cuckoo)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -7.5178  -2.8298  -0.6672   1.5564   6.0631  \n## \n## Coefficients:\n##                      Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)          0.334475   0.227143   1.473  0.14088    \n## Mass                 0.094847   0.007261  13.062  < 2e-16 ***\n## SpeciesWarbler       0.674820   0.259217   2.603  0.00923 ** \n## Mass:SpeciesWarbler -0.021673   0.008389  -2.584  0.00978 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 970.08  on 50  degrees of freedom\n## Residual deviance: 436.05  on 47  degrees of freedom\n## AIC: 615.83\n## \n## Number of Fisher Scoring iterations: 6"},{"path":"generalized-linear-models.html","id":"variable-scale","chapter":"19 Generalized Linear Models","heading":"19.5.1 Variable scale","text":"","code":"\n# using augment allows you to generate fitted outcomes from the regression, make sure to set the predictions onto the response scale in order to 'back transform` the data onto the original scale\n\nbroom::augment(cuckoo_glm1, type.predict = \"response\") %>% \nggplot(aes(x=Mass, y=.fitted, colour=Species)) + \n  geom_point() +\n  geom_line()+\n  scale_colour_manual(values=c(\"green3\",\"turquoise3\"))+\n  theme_minimal()"},{"path":"generalized-linear-models.html","id":"log-scale","chapter":"19 Generalized Linear Models","heading":"19.5.2 Log scale","text":"Compare new Poisson model fits ordinary least squares model. can see although homogeneity variance far perfect, curvature model drastically reduced (makes sense now model fitted exponential data), qqplot within acceptable confidence intervals.reminder interpret regression coefficients model interaction termIntercept = \\(\\beta 0\\) (intercept reference baseline log mean number begging calls cuckoos mass 0)Intercept = \\(\\beta 0\\) (intercept reference baseline log mean number begging calls cuckoos mass 0)Mass = \\(\\beta1\\) (slope: change log mean count begging calls every gram bodyweight cuckoos)Mass = \\(\\beta1\\) (slope: change log mean count begging calls every gram bodyweight cuckoos)SpeciesWarbler = \\(\\beta2\\) (log mean increase/decrease begging call rate warblers relative cuckoos)SpeciesWarbler = \\(\\beta2\\) (log mean increase/decrease begging call rate warblers relative cuckoos)Mass:SpeciesWarbler =\\(\\beta3\\) (log mean increase/decrease slope warblers relative cuckoos)Mass:SpeciesWarbler =\\(\\beta3\\) (log mean increase/decrease slope warblers relative cuckoos)\nPoisson distribution variance fixed mean using z scores. Estimates log scale link function - means S.E. confidence intervals\n","code":"\nbroom::augment(cuckoo_glm1) %>% \nggplot(aes(x=Mass, y=.fitted, colour=Species)) + \n  geom_point() +\n  geom_line()+\n  scale_colour_manual(values=c(\"green3\",\"turquoise3\"))+\n  theme_minimal()\nperformance::check_model(cuckoo_glm1, \n                         check = c(\"homogeneity\",\n                                   \"qq\"))\nsummary(cuckoo_glm1)## \n## Call:\n## glm(formula = Beg ~ Mass + Species + Mass:Species, family = poisson(link = \"log\"), \n##     data = cuckoo)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -7.5178  -2.8298  -0.6672   1.5564   6.0631  \n## \n## Coefficients:\n##                      Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)          0.334475   0.227143   1.473  0.14088    \n## Mass                 0.094847   0.007261  13.062  < 2e-16 ***\n## SpeciesWarbler       0.674820   0.259217   2.603  0.00923 ** \n## Mass:SpeciesWarbler -0.021673   0.008389  -2.584  0.00978 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 970.08  on 50  degrees of freedom\n## Residual deviance: 436.05  on 47  degrees of freedom\n## AIC: 615.83\n## \n## Number of Fisher Scoring iterations: 6"},{"path":"generalized-linear-models.html","id":"estimates-and-intervals","chapter":"19 Generalized Linear Models","heading":"19.6 Estimates and Intervals","text":"Remember Poisson model fitting variance using Poisson Normal distribution. also relating predictors response variable \"log-link\" means need exponentiate estimates get scale response (y) variable. model estimates logn(y).Luckily tidy models broom can specify want put model predictions response variable scale specifying exponentiate = T remove log transformation, allow easy calculation confidence intervals.","code":"\nexp(coef(cuckoo_glm1)[1]) ### Intercept - Incidence rate at Mass=0, and Species = Cuckoo\n\nexp(coef(cuckoo_glm1)[2]) ### Change in the average incidence rate with Mass \n\nexp(coef(cuckoo_glm1)[3]) ### Change in the incidence rate intercept when Species = Warbler and Mass = 0\n \nexp(coef(cuckoo_glm1)[4]) ### The extra change in incidence rate for each unit increase in Mass when Species = Warbler (the interaction effect)## (Intercept) \n##    1.397207 \n##    Mass \n## 1.09949 \n## SpeciesWarbler \n##       1.963679 \n## Mass:SpeciesWarbler \n##           0.9785598\nbroom::tidy(cuckoo_glm1, \n            exponentiate = T, \n            conf.int = T)"},{"path":"generalized-linear-models.html","id":"interpretation","chapter":"19 Generalized Linear Models","heading":"19.6.1 Interpretation","text":"important remember whether describing results log-link scale original scale. usually make sense provide answers original scale, means must first exponentiate relationship response predictors described writing results.\ndefault coefficients model summary log scale, additive can added subtracted (just like ordinary least squares regression) work log-estimates. exponentiate terms model get values 'response' scale, now changes 'rate' multiplicative.\n\nAlso remember Poisson models 'fixed variance' z- Chisquare distributions used instead t- F.\nexample wished infer relationship begging rates mass two species.hypothesised rate begging chicks increase body size increased. Interestingly found significant interaction effect mass species, Warbler chicks increased calling rate mass rate 0.98 [95%CI: 0.96-0.99] Cuckoo chicks (Poisson GLM: \\(\\chi^2\\)1,47 = 6.77, P = 0.009). meant hatching Warbler chicks start mean call rate higher parasitic brood mates, quickly reverses grow.","code":"\n# For a fixed  mean-variance model we use a Chisquare distribution\ndrop1(cuckoo_glm1, test = \"Chisq\")\n\n# emmeans can be another handy function - if you specify response then here it provideds the average call rate for each species, at the average value for any continuous measures - so here the average call rate for both species at an average body mass of 20.3\n\nemmeans::emmeans(cuckoo_glm1, specs = ~ Species:Mass, type = \"response\")##  Species Mass  rate    SE  df asymp.LCL asymp.UCL\n##  Cuckoo  20.3  9.61 0.884 Inf      8.03      11.5\n##  Warbler 20.3 12.15 0.658 Inf     10.93      13.5\n## \n## Confidence level used: 0.95 \n## Intervals are back-transformed from the log scale"},{"path":"generalized-linear-models.html","id":"overdispersion","chapter":"19 Generalized Linear Models","heading":"19.7 Overdispersion","text":"one extra check need apply Poisson model overdispersionPoisson (binomial models) assume variance equal mean.However, residual deviance bigger residual degrees freedom variance expect prediction mean model.Overdispersion Poisson models can diagnosed \\(\\frac{residual~deviance}{residual~degrees~~freedom}\\) example 'summary()' \\(\\frac{436}{47} = 9.3\\)Overdispersion statistic values > 1 = OverdispersedOverdispersion result larger expected variance mean Poisson distribution, clearly issue model!Luckily simple fix fit quasi-likelihood model accounts , think \"quasi\" \"sort completely\" Poisson.can see, none estimates changed, standard errors (therefore confidence intervals) , accounts greater expected uncertainty saw deviance, applies cautious estimate uncertainty. interaction effect appears longer significant \\(\\alpha\\) = 0.05, now wider standard errors.\nnow estimating variance , test statistics reverted t distributions anova drop1 functions specify F-test .\n","code":"\ncuckoo_glm2 <- glm(Beg ~ Mass+Species+Mass:Species, data=cuckoo, family=quasipoisson(link=\"log\"))\n\nsummary(cuckoo_glm2)## \n## Call:\n## glm(formula = Beg ~ Mass + Species + Mass:Species, family = quasipoisson(link = \"log\"), \n##     data = cuckoo)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -7.5178  -2.8298  -0.6672   1.5564   6.0631  \n## \n## Coefficients:\n##                     Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)          0.33448    0.63129   0.530    0.599    \n## Mass                 0.09485    0.02018   4.700  2.3e-05 ***\n## SpeciesWarbler       0.67482    0.72043   0.937    0.354    \n## Mass:SpeciesWarbler -0.02167    0.02332  -0.930    0.357    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for quasipoisson family taken to be 7.7242)\n## \n##     Null deviance: 970.08  on 50  degrees of freedom\n## Residual deviance: 436.05  on 47  degrees of freedom\n## AIC: NA\n## \n## Number of Fisher Scoring iterations: 6"},{"path":"generalized-linear-models.html","id":"activity-2-write-up","chapter":"19 Generalized Linear Models","heading":"19.8 Activity 2: Write-up","text":"used Poisson log-link Generalized Linear Model quasi-likelihoods account overdispersion analyse begging call rates Warbler Cuckoo chicks. species chick included categorical predictor mass included continuous predictor.initial model also included interaction term species mass, removed final model removal term significantly alter fit model (ANOVA).","code":""},{"path":"generalized-linear-models.html","id":"logistic-regression-for-binary-data","chapter":"19 Generalized Linear Models","heading":"19.9 Logistic regression (for binary data)","text":"response variable binary, can use glm binomial error distributionSo far considered continuous discrete data response variables. response categorical variable (e.g passing failing exam, voting yes referendum, whether egg successfully fledged predated, infected/uninfected, alive/dead)?can model probability \\(p\\) particular class function \nexplanatory variables.type binary data assumed follow Bernoulli distribution (special case Binomial) following characteristics:\\[\nY \\sim \\mathcal{Bern}(p)\n\\]Binary variable, taking values 0 1 (yes/, pass/fail).probability parameter \\(p\\), \\(0 < p < 1\\).Mean = \\(p\\)Variance = \\(p(1 - p)\\)Let us now place Gaussian (simple linear regression), Poisson logistic models next :\\[\n\\begin{aligned}\nY & \\sim \\mathcal{N}(\\mu, \\sigma^2) &&& Y  \\sim \\mathcal{Pois}(\\lambda) &&& Y  \\sim \\mathcal{Bern}(p)\\\\\n\\mu & = \\beta_0 + \\beta_1X &&& \\log{\\lambda} = \\beta_0 + \\beta_1X &&& ?? = \\beta_0 + \\beta_1X\n\\end{aligned}\n\\]Now need fill ?? appropriate term. Similar Poisson regression case,\nsimply model probabiliy \\(p = \\beta_0 + \\beta_1X\\), \\(p\\) negative.\n\\(\\log{p} = \\beta_0 + \\beta_1X\\) work either, \\(p\\) greater 1. Instead \nmodel log odds \\(\\log\\left(\\frac{p}{1 - p}\\right)\\) linear function. logistic regression model looks\nlike :\\[\n\\begin{aligned}\nY  & \\sim \\mathcal{Bern}(p)\\\\\n\\log\\left(\\frac{p}{1 - p}\\right) &  = \\beta_0 + \\beta_1 X\n\\end{aligned}\n\\], note still \"\" fitting straight lines data, time log odds space.\nshorthand notation write \\(\\log\\left(\\frac{p}{1 - p}\\right) = \\text{logit}(p) = \\beta_0 + \\beta_1 X\\).can also re-arrange equation get expression \\(p\\)\\[\np = \\frac{e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\n\\]Note \\(p\\) can vary 0 1.implement logistic regression model R, choose family=binomial(link=logit) (Bernoulli distribution special case Binomial distribution).Challenger DisasterIn 1985, NASA made decision send first civilian space.decision brought huge amount public attention STS-51-L mission, Challenger’s 25th trip space school teacher Christa McAuliffe’s 1st. afternoon January 28th, 1986 students around America tuned watch McAuliffe six astronauts launch Cape Canaveral, Florida. 73 seconds flight, shuttle experienced critical failure broke apart mid air, resulting deaths seven crewmembers: Christa McAuliffe, Dick Scobee, Judy Resnik, Ellison Onizuka, Ronald McNair, Gregory Jarvis, Michael Smith.investigation incident, discovered failure caused O-ring solid rocket booster. Additionally, revealed incident foreseeable.half worksheet discuss right statistical model predicted critical failure O-ring day.data columns :oring_tot: Total number orings flightoring_tot: Total number orings flightoring_dt : number orings failed flightoring_dt : number orings failed flighttemp: Outside temperature date flighttemp: Outside temperature date flightflight order flightsflight order flightsIt frequently discussed issue temperature might play role critical safety o-rings shuttles.\nOne biggest mistakes made assessing flight risk Challenger look flights failure occurredFrom concluded temperature appear affect o-ring risk failure, o-ring failures detected range different temperatures.However compare full data available different picture emerges.include flights without incident incident, can see clear relationship temperature risk o-ring failure. argued clear presentation data allowed even casual observer determine high risk disaster.However want understand actual relationship temperature risk several issues fitting linear model - data integer, bounded zero (model predicts negative failure rates within observed data range).consider suitable Poisson model - really interested determining binary risk flight o-ring failure vs. failure. implement GLM Binomial distribution.can use dplyr generate binary column incident '0' fail '1' anything >0.Fitting binary GLMSo now fitting following model\\[\n Y \\sim Bern(p)\n\\]\n\\[\n\\log\\left[ \\frac { P( \\operatorname{oring\\_binary} = fail) }{ 1 - P( \\operatorname{oring\\_binary} = fail) } \\right] = \\beta_{0} + \\beta_{1}(\\operatorname{temp})\n\\]R look like :Intercept = \\(\\beta_{0}\\) = 23.77When temperature 0°F mean log-odds 23.77 [95%CI: 7.24- 58.19] failure incident O-ringsTemp = \\(\\beta_{1}\\) = -0.37 [95%CI: -0.87 - -0.12]every rise temperature 1°F, log-odds critical incident fall 0.37.","code":"glm(response ~ explanatory, family=binomial(link=logit))\nhead(challenger)\nchallenger %>% \n  filter(oring_dt > 0) %>% \nggplot(aes(y=oring_dt, x=temp))+geom_point()+\n  ggtitle(\"Temperature on flight launches where an O-ring incident occurred\")\nchallenger %>% \nggplot(aes(y=oring_dt, \n           x=temp))+\n  geom_point()+\n  geom_smooth(method=\"lm\")+\n  ggtitle(\"All launch data\")\nchallenger <- challenger %>% \n  mutate(oring_binary = ifelse(oring_dt =='0', 0, 1))\nbinary_model <- glm(oring_binary~temp, family=binomial, data=challenger)\nbinary_model %>% \n  broom::tidy(conf.int=T)\nbinary_model <- glm(oring_binary~temp, family=binomial, data=challenger)"},{"path":"generalized-linear-models.html","id":"interpreting-model-coefficients","chapter":"19 Generalized Linear Models","heading":"19.9.1 Interpreting model coefficients","text":"first consider dealing odds \\(\\frac{p}{1-p}\\) instead just \\(p\\). contain information, choice somewhat arbitrary, however ’ve using probabilities long feels unnatural switch odds. good reasons , however. Odds \\(\\frac{p}{1-p}\\) can take value 0 ∞ part translation \\(p\\) unrestricted domain already done (\\(P\\) restricted 0-1). Take look examples :use binomial model, produce 'log-odds', produces fully unconstrained linear regression anything less 1, can now occupy infinite negative value -∞ ∞.\\[\\log\\left(\\frac{p}{1-p}\\right)    =   \\beta_{0}+\\beta_{1}x_{1}+\\beta_{2}x_{2}\n\\]\\[\\frac{p}{1-p} =   e^{\\beta_{0}}e^{\\beta_{1}x_{1}}e^{\\beta_{2}x_{2}}\n\\]can interpret \\(\\beta_{1}\\) \\(\\beta_{2}\\) increase log odds every unit increase \\(x_{1}\\) \\(x_{2}\\). alternatively interpret \\(\\beta_{1}\\) \\(\\beta_{2}\\) using notion one unit change \\(x_{1}\\) percent change \\(e^{\\beta_{1}}\\) odds. say, \\(e^{\\beta_{1}}\\) odds ratio change.want find Odds log-odds head ","code":""},{"path":"generalized-linear-models.html","id":"probability","chapter":"19 Generalized Linear Models","heading":"19.10 Probability","text":"powerful use logisitic regression prediction. Can predict probability event occuring using data?","code":""},{"path":"generalized-linear-models.html","id":"activity-3-make-predictions","chapter":"19 Generalized Linear Models","heading":"19.10.1 Activity 3: Make predictions","text":"Can use prediction functions predict() broom::augment() look models predictions O-ring failure data? Bonus points can convert log-odds probability?","code":"\npredict(binary_model, type = \"response\")##           1           2           3           4           5           6 \n## 0.394769696 0.130776531 0.178373050 0.238538593 0.311308842 0.067388639 \n##           7           8           9          10          11          12 \n## 0.047687994 0.130776531 0.946495574 0.662129014 0.130776531 0.007941202 \n##          13          14          15          16          17          18 \n## 0.311308842 0.987128767 0.311308842 0.023485304 0.130776531 0.002657203 \n##          19          20          21          22          23 \n## 0.016393905 0.005516836 0.023485304 0.016393905 0.924582363\nbroom::augment(binary_model, \n               type.predict = \"response\")"},{"path":"generalized-linear-models.html","id":"emmeans-1","chapter":"19 Generalized Linear Models","heading":"19.10.2 Emmeans","text":"use emmeans() function convert log-odds estimate probability o-ring failure mean value x (temperature). add confidence intervals!log-odds probability actually relate?equation work probability using exponent linear regression equation:\\[\nP(\\operatorname{risk failure }  X=69)\\left[ \\frac{e^{23.77+(-0.37 \\times 69.6)}}{1+e^{23.77+(-0.37 \\times 69.6)}} \\right]\n\\]produces following result can confirm risk o-ring failure average day 0.15","code":"\nemmeans::emmeans(binary_model, specs=~temp, type=\"response\")##  temp prob     SE  df asymp.LCL asymp.UCL\n##  69.6 0.15 0.0985 Inf    0.0373     0.445\n## \n## Confidence level used: 0.95 \n## Intervals are back-transformed from the logit scale\nodds_at_69.6 <- exp(coef(binary_model)[1]+coef(binary_model)[2]*69.6)\n# To convert from odds to a probability, divide the odds by one plus the odds\n\nprobability <-  odds_at_69.6/(1+odds_at_69.6)\nprobability## (Intercept) \n##   0.1483717"},{"path":"generalized-linear-models.html","id":"changes-in-probability","chapter":"19 Generalized Linear Models","heading":"19.10.3 Changes in probability","text":"useful rule--thumb can divide--four rule.can described maximum difference probability unit change \\(X\\) \\(\\beta/4\\).example maximum difference probability one degree change Temp \\(-0.37/4 = -0.09\\)maximum difference probability failure corresponding one degree change 9%Remember want augment data model, can use augment() function, remembering specify type.predict = \"response get probabilities o-ring failure (log odds).Annoyingly limitation augment function produce 95% CI predictions glms. written short function \nworry lot get head around - main thing use code produce 95% CI.Alternatively can also calculation via emmeans","code":"\nbroom::augment(binary_model, \n               type.predict=\"response\", \n               se_fit = T) %>% \n  head()\naugment_glm <- function(mod, predict = NULL){\n  fam <- family(mod)\n  ilink <- fam$linkinv\n  \n  broom::augment(mod, newdata = predict, se_fit=T)%>%\n    mutate(.lower = ilink(.fitted - 1.96*.se.fit),\n           .upper = ilink(.fitted + 1.96*.se.fit), \n           .fitted=ilink(.fitted))\n}\n\naugment_glm(binary_model)\nemmeans::emmeans(binary_model, \n                 specs = ~ temp, \n                 at=list(temp=c(66:27)), \n                 type='response') ##  temp     prob         SE  df asymp.LCL asymp.UCL\n##    66 0.394770 0.17018097 Inf  0.139034  0.724865\n##    65 0.484853 0.19701707 Inf  0.167060  0.815387\n##    64 0.575932 0.21823406 Inf  0.190739  0.886694\n##    63 0.662129 0.22770706 Inf  0.210461  0.935096\n##    62 0.738753 0.22299102 Inf  0.227046  0.964568\n##    61 0.803166 0.20584013 Inf  0.241266  0.981259\n##    60 0.854818 0.18057075 Inf  0.253727  0.990288\n##    59 0.894693 0.15192302 Inf  0.264874  0.995033\n##    58 0.924582 0.12364996 Inf  0.275030  0.997482\n##    57 0.946496 0.09807106 Inf  0.284428  0.998731\n##    56 0.962301 0.07624709 Inf  0.293240  0.999364\n##    55 0.973568 0.05837488 Inf  0.301592  0.999682\n##    54 0.981533 0.04416262 Inf  0.309579  0.999841\n##    53 0.987129 0.03310075 Inf  0.317275  0.999921\n##    52 0.991045 0.02462725 Inf  0.324734  0.999961\n##    51 0.993777 0.01821445 Inf  0.332003  0.999981\n##    50 0.995679 0.01340624 Inf  0.339114  0.999990\n##    49 0.997001 0.00982751 Inf  0.346096  0.999995\n##    48 0.997920 0.00717951 Inf  0.352970  0.999998\n##    47 0.998558 0.00522962 Inf  0.359755  0.999999\n##    46 0.999000 0.00379955 Inf  0.366464  0.999999\n##    45 0.999307 0.00275431 Inf  0.373111  1.000000\n##    44 0.999520 0.00199257 Inf  0.379705  1.000000\n##    43 0.999667 0.00143888 Inf  0.386253  1.000000\n##    42 0.999769 0.00103733 Inf  0.392763  1.000000\n##    41 0.999840 0.00074671 Inf  0.399239  1.000000\n##    40 0.999889 0.00053676 Inf  0.405687  1.000000\n##    39 0.999923 0.00038534 Inf  0.412110  1.000000\n##    38 0.999947 0.00027631 Inf  0.418510  1.000000\n##    37 0.999963 0.00019791 Inf  0.424891  1.000000\n##    36 0.999974 0.00014160 Inf  0.431253  1.000000\n##    35 0.999982 0.00010122 Inf  0.437600  1.000000\n##    34 0.999988 0.00007228 Inf  0.443931  1.000000\n##    33 0.999992 0.00005158 Inf  0.450247  1.000000\n##    32 0.999994 0.00003677 Inf  0.456549  1.000000\n##    31 0.999996 0.00002619 Inf  0.462837  1.000000\n##    30 0.999997 0.00001865 Inf  0.469112  1.000000\n##    29 0.999998 0.00001327 Inf  0.475372  1.000000\n##    28 0.999999 0.00000943 Inf  0.481619  1.000000\n##    27 0.999999 0.00000670 Inf  0.487850  1.000000\n## \n## Confidence level used: 0.95 \n## Intervals are back-transformed from the logit scale\naugment_glm(binary_model) %>% \n  ggplot(aes(x=temp, y=oring_binary))+geom_line(aes(x=temp, y=.fitted))+\n  geom_ribbon(aes(ymin=.lower, ymax=.upper), alpha=0.2)"},{"path":"generalized-linear-models.html","id":"predictions","chapter":"19 Generalized Linear Models","heading":"19.11 Predictions","text":"day Challenger launched outside air temperature 36°FWe can use augment add model new data - make predictions risk o-ring failure","code":""},{"path":"generalized-linear-models.html","id":"activity-4-more-predictions","chapter":"19 Generalized Linear Models","heading":"19.11.1 Activity 4: More predictions","text":"First - make new dataset temperature day Challenger Launch 36°FWe can see fitted model, O-ring failure day Challenger launch predicted probability >0.999 [95%CI: 0.43-1]","code":"\nnew_data <- tibble(temp=36, oring_binary=1)\n\n\naugment_glm(binary_model, new_data)"},{"path":"generalized-linear-models.html","id":"assumptions-1","chapter":"19 Generalized Linear Models","heading":"19.12 Assumptions","text":"standard model checks plot() used binomial glms, usually mess!Luckily performance package detects alters checks. Pay particular attention binned residuals plot - best estimate possible overdispersion (requiring quasi-likelihood check). case likely enough data robust checks","code":"\nperformance::check_model(binary_model)"},{"path":"generalized-linear-models.html","id":"activity-5-write-up","chapter":"19 Generalized Linear Models","heading":"19.12.1 Activity 5: Write-up","text":"write findings analysis?Analysis: used Binomial logit-link Generalized Linear Model analyse effect temperature likelihood O-ring failure.analyses carried R (ver 4.1.3) (R Core Team 2021) following packages; tidyverse (Wickham et al 2019).Results: found significant negative relationship temperature probability o-ring failure (logit-odds = -0.37 [95%CI: -0.88 - -0.12], z = -2.1, d.f = 21, P = 0.036). average temperature 69.6°F probability o-ring failure estimated 0.15[0.03-0.45], rose near certainty failure 0.99[0.43-1] 36°F.Note use drop1( test = \"Chisq\") , one, continuous variable, can also report directly summary table.","code":"\ndrop1(binary_model, test=\"Chisq\")"},{"path":"generalized-linear-models.html","id":"summary-9","chapter":"19 Generalized Linear Models","heading":"19.13 Summary","text":"GLMs powerful flexible.can used fit wide variety data types.Model checking becomes trickier.Extensions include:mixed models;survival models;generalized additive models (GAMs).information Poisson Binomial GLMs check :https://bookdown.org/dereksonderegger/571/11-binomial-regression.html#confidence-intervals-1https://bookdown.org/ronsarafian/IntrotoDS/glm.html#poisson-regression","code":""},{"path":"generalized-linear-models.html","id":"final-checklist","chapter":"19 Generalized Linear Models","heading":"19.14 Final checklist","text":"Think carefully hypotheses test, use scientific knowledge background reading support thisThink carefully hypotheses test, use scientific knowledge background reading support thisImport, clean understand dataset: use data visuals investigate trends determine clear support hypothesesImport, clean understand dataset: use data visuals investigate trends determine clear support hypothesesDecide appropriate error structure model (Gaussian = continuous, Poisson = count, Binomial = binary)Decide appropriate error structure model (Gaussian = continuous, Poisson = count, Binomial = binary)Start canonical link functions, can altered neededStart canonical link functions, can altered neededFit (generalized) linear model, including interaction terms cautionFit (generalized) linear model, including interaction terms cautionInvestigate fit model, understand parameters may never perfect, classic patterns residuals may indicate poorly fitting model - sometimes can fixed careful consideration missing variables data transformationInvestigate fit model, understand parameters may never perfect, classic patterns residuals may indicate poorly fitting model - sometimes can fixed careful consideration missing variables data transformationCheck overdispersion models variance estimated independently mean (Poisson Binomial) - may use quasi-likelihood fittingCheck overdispersion models variance estimated independently mean (Poisson Binomial) - may use quasi-likelihood fittingTest removal interaction terms model, look AIC significance tests (Remember test = \"F\" Gaussian Quasilikelihood models, \"Chisq\" Poisson Binomial models)Test removal interaction terms model, look AIC significance tests (Remember test = \"F\" Gaussian Quasilikelihood models, \"Chisq\" Poisson Binomial models)Make sure understand output model summary, sense check graphs made - estimates need converting back original response scale?Make sure understand output model summary, sense check graphs made - estimates need converting back original response scale?direction size effects priority - produce estimates uncertainties. Make sure observations clear.direction size effects priority - produce estimates uncertainties. Make sure observations clear.Write-significance test results, taking care report just significance (required parts significance test). know report? Within complex model - reporting t/z indicate slope line single term intercept, F/Chi overall effect predictor across levels, post-hoc wish compare across levels.Write-significance test results, taking care report just significance (required parts significance test). know report? Within complex model - reporting t/z indicate slope line single term intercept, F/Chi overall effect predictor across levels, post-hoc wish compare across levels.Well described tables figures can enhance results sections - take time make sure informative attractive.Well described tables figures can enhance results sections - take time make sure informative attractive.","code":""},{"path":"mixed-models.html","id":"mixed-models","chapter":"20 Mixed models","heading":"20 Mixed models","text":"Advanced Topics still development","code":""},{"path":"mixed-models.html","id":"what-is-mixed-modelling-and-why-do-we-need-it","chapter":"20 Mixed models","heading":"20.1 What is mixed modelling and why do we need it?","text":"Ecological biological data often complicated messy. can lots grouping factors like populations, data collection sites mean data clusters data points truly independent. mixed models useful, combine fixed random effects help us deal messy data, structured data, help us save degrees freedom. incredibly useful, frequently tricky implement well!","code":""},{"path":"mixed-models.html","id":"fixed-effects","chapter":"20 Mixed models","heading":"20.1.1 Fixed effects","text":"far statistics dealt fixed effectsFixed effects variables constant, constant effect individual. example can argue effect species average body mass constant, change. argued variables change time, research experimental purposes constant. assume values fixed variable one study values another study.","code":""},{"path":"mixed-models.html","id":"random-effects","chapter":"20 Mixed models","heading":"20.1.2 Random effects","text":"Random effects, opposite fixed effects. variables unpredictable effects, example sample sites. perfectly plausible data collected within different sites similar data different sites.Unlike fixed effects assume values samples drawn larger population values. often interested explicit effect variable, expect effect dependent variable wish account . number grouping variables, example:Study-siteStudy-siteRepeated measurements individualRepeated measurements individualExperimental replicationsExperimental replications","code":""},{"path":"mixed-models.html","id":"the-data","chapter":"20 Mixed models","heading":"20.2 The data","text":"going look bacterial growth four different growth media. ran experiment five times, five different microbial growth cabinets","code":"\nhead(bacteria)"},{"path":"mixed-models.html","id":"simple-model","chapter":"20 Mixed models","heading":"20.3 Simple model","text":"","code":""},{"path":"mixed-models.html","id":"covariates","chapter":"20 Mixed models","heading":"20.4 Covariates","text":"","code":""},{"path":"mixed-models.html","id":"mixed-model","chapter":"20 Mixed models","heading":"20.5 Mixed model","text":"","code":""},{"path":"mixed-models.html","id":"random-slopes","chapter":"20 Mixed models","heading":"20.5.1 Random slopes","text":"Rats data - ExeterPlot scatterplot Alcohol vs TotalPhenols colour data points WineType\nSomething","code":"\nplot(iris)\nplot(cars)"},{"path":"generalised-additive-models.html","id":"generalised-additive-models","chapter":"21 Generalised Additive Models","heading":"21 Generalised Additive Models","text":"","code":""},{"path":"survival-models.html","id":"survival-models","chapter":"22 Survival models","heading":"22 Survival models","text":"","code":""},{"path":"unsupervised-machine-learning.html","id":"unsupervised-machine-learning","chapter":"23 Unsupervised Machine Learning","heading":"23 Unsupervised Machine Learning","text":"","code":""},{"path":"power-analysis.html","id":"power-analysis","chapter":"24 Power analysis","heading":"24 Power analysis","text":"statistical power hypothesis test probability detecting effect, true effect present detect.Power can calculated reported completed experiment comment confidence one might conclusions drawn results study. can also used tool estimate number observations sample size required order detect effect experiment.tutorial, discover importance statistical power hypothesis test now calculate power analyses power curves part experimental design.completing tutorial, know:Statistical power probability hypothesis test finding effect effect found.Statistical power probability hypothesis test finding effect effect found.power analysis can used estimate minimum sample size required experiment, given desired significance level, effect size, statistical power.power analysis can used estimate minimum sample size required experiment, given desired significance level, effect size, statistical power.calculate plot power analysis Student’s t test R order effectively design experiment.calculate plot power analysis Student’s t test R order effectively design experiment.","code":""},{"path":"power-analysis.html","id":"why-do-we-need-statistical-power","chapter":"24 Power analysis","heading":"24.1 Why do we need statistical power?","text":"interpreting statistical power, seek experiential setups high statistical power.Low Statistical Power: Large risk committing Type II errors, e.g. false negative.Low Statistical Power: Large risk committing Type II errors, e.g. false negative.High Statistical Power: Small risk committing Type II errors.High Statistical Power: Small risk committing Type II errors.common design experiments statistical power 80% better, e.g. 0.80. means 20% probability encountering Type II error (alternative hypothesis true).","code":""},{"path":"power-analysis.html","id":"what-is-statistical-power","chapter":"24 Power analysis","heading":"24.2 What is statistical power?","text":"Statistical power one piece puzzle four related parts; :Effect Size. quantified magnitude result present population. Effect size calculated using specific statistical measure, Pearson’s correlation coefficient relationship variables Cohen’s d difference groups.Effect Size. quantified magnitude result present population. Effect size calculated using specific statistical measure, Pearson’s correlation coefficient relationship variables Cohen’s d difference groups.Sample Size. number observations sample.Sample Size. number observations sample.Significance. significance level used statistical test, e.g. \\(\\alpha\\). Often set 5% 0.05.Significance. significance level used statistical test, e.g. \\(\\alpha\\). Often set 5% 0.05.Statistical Power. probability accepting alternative hypothesis true \\(1-\\beta\\).Statistical Power. probability accepting alternative hypothesis true \\(1-\\beta\\).","code":""},{"path":"power-analysis.html","id":"standardised-effect-size","chapter":"24 Power analysis","heading":"24.3 Standardised effect size","text":"","code":""},{"path":"power-analysis.html","id":"cohens-d","chapter":"24 Power analysis","heading":"24.3.1 Cohen's D","text":"Cohens d standardized effect size measuring difference two group means. effect size use carrying t-tests.\nTable 24.1: Cohen's D\nunpaired t-test, see can use following equations manually calculate d.using models Chapter 14.Unpaired t-test - difference means divided pooled standard deviation:\\[ \\frac{mean~difference}{SD_{pooled}} =  \\frac{mean~difference}{\\sqrt{(n_1-1)s_1^2+(n_2-1)s_2^2 \\n_1 + n_2-2}}\\]\ntry work hand first, investigate functions can make process faster.Can calculate mean difference pooled standard deviation ?","code":"lm(height ~ type, data = darwin)\n\nsummary_darwin <- darwin %>% \n  group_by(type) %>% \n  summarise(mean = mean(height),\n            sd = sd(height),\n            n = n())\nsummary_darwin\nsummary_darwin %>% \n    mutate(variance = sd^2) %>% \n    mutate(per_sample_var = variance * (n-1)) %>% \n  summarise(sd_pooled = sqrt(sum(per_sample_var)/sum(n-2)),\n            mean_diff = diff(mean))\n2.61/3.05## [1] 0.8557377"},{"path":"power-analysis.html","id":"cohens-d-from-a-linear-model","chapter":"24 Power analysis","heading":"24.3.2 Cohen's D from a linear model","text":"time, calculate values hand. Instead range functions allow us :","code":"\nlibrary(effectsize)\n\n# simple t-test\nlsmodel1 <- lm(height ~ type, data = darwin)\n\nt_to_d(2.437, df_error = 28, paired = F)\n\n# paired t-test\nlsmodel2 <- lm(height ~ type +factor(pair), data = darwin)\n\nt_to_d(2.456, df_error=27, paired=T)"},{"path":"power-analysis.html","id":"power","chapter":"24 Power analysis","heading":"24.4 Power","text":"necessarily need report effect sizes write-, fairly rare see included paper. useful report confidence intervals original measurement scale. provide two important pieces information.experiments/statistical analyses become statistically significant make sample size large enough. respect shows misleading significant result can . interesting result statistically significant, effect size tiny. Even without reporting d can start thinking whether confidence intervals indicate result interesting.experiments/statistical analyses become statistically significant make sample size large enough. respect shows misleading significant result can . interesting result statistically significant, effect size tiny. Even without reporting d can start thinking whether confidence intervals indicate result interesting.Type 2 errors. Statistical tests provide probability making Type 1 error (rejecting null hypothesis incorrectly) form P. Type 2 errors? Keeping null hypothesis, rejecting ? finding effect.Type 2 errors. Statistical tests provide probability making Type 1 error (rejecting null hypothesis incorrectly) form P. Type 2 errors? Keeping null hypothesis, rejecting ? finding effect.probability making Type 2 error known \\(1-\\beta\\), \\(\\beta\\) refers statistical 'power'. Working statistical power straightforward simple tests, becomes rapidly diffcult complexity analysis increases... important concept understand.two potential uses Power analysisWorking statistical power analysis post hoc determine likely missed effect ( seeThis useful paper.Working statistical power analysis post hoc determine likely missed effect ( seeThis useful paper.Working sample size need experiment make sure reach desired power. Often common \\(\\beta\\) value 0.8, much way common \\(\\alpha\\) 0.05, arbitrary target, means can tolerate risk failing reject null 20% experiments produce significant result.Working sample size need experiment make sure reach desired power. Often common \\(\\beta\\) value 0.8, much way common \\(\\alpha\\) 0.05, arbitrary target, means can tolerate risk failing reject null 20% experiments produce significant result.n, d, sig.level power - put values three arguments return value fourth e.g. can work power two sample t-test ?pwr.t.test(n = NULL, d = NULL, sig.level = 0.05, power = NULL,\ntype = c(\"two.sample\"),\nalternative = c(\"two.sided\"))n = number observations per sample(d = Effect sizesig.level = agreed alphaFrom can see even though test find significant difference heights groups, power test optimal.can also see wanted detect smaller effects inbreeding reliably, need much larger sample size.Now know pwr.t.test() function works - Can make simple iteration check power lower effect size (d) 0.2 two-sided t-test sample sizes 0-1000 increasing 10 time?","code":"\nlibrary(pwr)\nlibrary(simr)\nlibrary(pwr)\n# Calculate the power of our model \ntest.power <- pwr.t.test(n = 15, d = 0.92, sig.level = 0.05)\n\n# Calculate the sample size we need to get power of 0.8 for a medium effect size (d = 0.5)\n\nsamp.size <- pwr.t.test(d = 0.5, sig.level = 0.05, power = 0.8)\nsample_size <- seq(0,1000, by=10)\n\noutput <- list(length(sample_size))\n\n\nfor (i in 1:length(sample_size)) { \n  \n  sample <- pwr.t.test(n=sample_size[i], d=0.2, sig.level=0.05)\n  output[[i]] <- sample\n  \n #     if(i %% 1==0){    # The %% operator is the remainder, this handy if line prints a number every time it completes a loop\n #   print(i)\n  #  }\n}\n\nsample_list <- as.list(sample_size)\n\nnames(output) <- sample_size\n\n#  now you should be able to call any sample size and check statistical power!\n\n# output$`30`"},{"path":"iteration.html","id":"iteration","chapter":"25 Iteration","heading":"25 Iteration","text":"’ve seen write function can used create concise re-usable operations can applied multiple times script without copy paste, functions really come combined iteration. Iteration process running operation group objects, minimising code replication.","code":""},{"path":"iteration.html","id":"data-structures","chapter":"25 Iteration","heading":"25.1 Data structures","text":"Functional programming R requires good understanding types data structure available R. quick introduction","code":""},{"path":"iteration.html","id":"vector","chapter":"25 Iteration","heading":"25.1.1 Vector","text":"","code":"\nvector_one <- (1:3)\n\nvector_two <- c(\"apples\", \"bananas\", \"pears\")"},{"path":"iteration.html","id":"list","chapter":"25 Iteration","heading":"25.1.2 List","text":"","code":"\nnew_list <- list(vector_one, vector_two)\n\nnames(new_list) <- c(\"numbers\", \"fruit\")"},{"path":"iteration.html","id":"matrix","chapter":"25 Iteration","heading":"25.1.3 Matrix","text":"","code":"\nnew_matrix <- cbind(vector_one, vector_two)\n\nis.matrix(new_matrix)\n\n\nmatrix(nrow = 2, ncol = 2)## [1] TRUE\n##      [,1] [,2]\n## [1,]   NA   NA\n## [2,]   NA   NA"},{"path":"iteration.html","id":"dataframe","chapter":"25 Iteration","heading":"25.1.4 Dataframe","text":"","code":"\nnew_dataframe <- data.frame(vector_one, vector_two)"},{"path":"iteration.html","id":"tibble","chapter":"25 Iteration","heading":"25.1.5 tibble","text":"","code":"\nnew_tibble <- tibble(vector_one, vector_two)"},{"path":"iteration.html","id":"simple-iteration-functions","chapter":"25 Iteration","heading":"25.2 Simple iteration functions","text":"","code":""},{"path":"iteration.html","id":"rep","chapter":"25 Iteration","heading":"25.2.1 rep()","text":"function rep() lets repeat first argument set number times.default amount repetition times = print entire vector start finish repeat.second argument vector number elements first vector, repeat specified values eachOr use argument rep first element first followed second etc.think happen set times 3 2?","code":"\nrep(1:5, 5)\n\nrep(c(\"Adelie\", \"Gentoo\", \"Chinstrap\"), 2)##  [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n## [1] \"Adelie\"    \"Gentoo\"    \"Chinstrap\" \"Adelie\"    \"Gentoo\"    \"Chinstrap\"\nrep(c(\"Adelie\", \"Gentoo\", \"Chinstrap\"), c(2, 1, 3))## [1] \"Adelie\"    \"Adelie\"    \"Gentoo\"    \"Chinstrap\" \"Chinstrap\" \"Chinstrap\"\nrep(c(\"Adelie\", \"Gentoo\", \"Chinstrap\"), each = 3)## [1] \"Adelie\"    \"Adelie\"    \"Adelie\"    \"Gentoo\"    \"Gentoo\"    \"Gentoo\"   \n## [7] \"Chinstrap\" \"Chinstrap\" \"Chinstrap\"\nrep(c(\"Adelie\", \"Gentoo\", \"Chinstrap\"), times = 2, each = 3)##  [1] \"Adelie\"    \"Adelie\"    \"Adelie\"    \"Gentoo\"    \"Gentoo\"    \"Gentoo\"   \n##  [7] \"Chinstrap\" \"Chinstrap\" \"Chinstrap\" \"Adelie\"    \"Adelie\"    \"Adelie\"   \n## [13] \"Gentoo\"    \"Gentoo\"    \"Gentoo\"    \"Chinstrap\" \"Chinstrap\" \"Chinstrap\""},{"path":"iteration.html","id":"seq","chapter":"25 Iteration","heading":"25.2.2 seq()","text":"function seq() useful generating sequence numbers pattern.Use seq() create vector integers 0 10.initially similar just making vector withBut seq extra functions. can set argument count numbers 1 (default). Use seq() create vector numbers 0 100 10s.also argument length., useful want know many steps divide something ","code":"\nseq(1,5)## [1] 1 2 3 4 5\nc(1:5)## [1] 1 2 3 4 5\nseq(0, 100, by = 10)##  [1]   0  10  20  30  40  50  60  70  80  90 100\nseq(0, 100, length.out = 12)##  [1]   0.000000   9.090909  18.181818  27.272727  36.363636  45.454545\n##  [7]  54.545455  63.636364  72.727273  81.818182  90.909091 100.000000"},{"path":"iteration.html","id":"replicate","chapter":"25 Iteration","heading":"25.2.3 replicate()","text":"Replicate first example function whose purpose iterate functionsFor example rnorm function generates numbers normal distribution.Nesting inside replicate() function repeat command specified number timesHere introduce two approaches iterative operations - using loops using package purrr.loops iterate code across series inputs, less common R programming languages. Nevertheless, introduce learning tool referencefor loops iterate code across series inputs, less common R programming languages. Nevertheless, introduce learning tool referenceThe purrr package tidyverse approach iterative operations - works “mapping” function across many inputs (values, columns, datasets, etc.)purrr package tidyverse approach iterative operations - works “mapping” function across many inputs (values, columns, datasets, etc.)","code":"\nreplicate(3, # times to replicate function\n          expr = rnorm(n = 5, \n                       mean = 1,\n                       sd = 1))##           [,1]      [,2]        [,3]\n## [1,] 1.0309455 0.3613668  0.58217414\n## [2,] 1.0797760 0.4598443 -0.05562899\n## [3,] 0.4520928 2.0347071  1.30014660\n## [4,] 0.9912560 1.4328771  0.92325916\n## [5,] 2.6118530 2.3299945  2.94314882"},{"path":"iteration.html","id":"for-loops","chapter":"25 Iteration","heading":"25.3 For Loops","text":"loops essential part many programming languages, often less utilised R ability apply functions elements vector. However, include completeness.loop three core parts:sequence items iterate throughThe sequence items iterate throughThe operations conduct per item sequenceThe operations conduct per item sequenceThe container results (optional)container results (optional)basic syntax : (item sequence) {operations using item}. Note parentheses curly brackets. results printed console, stored container R object.simple loop example . every number vector add 2. container object , results function printed directly console.make slightly complicated function - first making new tibble, first four vectors - made 10 numbers randomly generated roughly close 0 mean s.d. 1. combine make tibbleEach vector randomly generated actual averages slightly different, can test :code works, repetitive, applying function .simple loopNow run loop:time mean calculate one column df stored element previously empty output vector.() loops useful quickly iterating list, R prefers store everything new object loop iteration, loops can become quite slow complex, running many processes many iterations. alternative apply family functions base R purrr::map tidyverse broadly can used alternative loops.","code":"for(i in list){\n    # PERFORM SOME ACTION\n}\nfor (num in c(1,2,3,4,5)) {  # the SEQUENCE is defined (numbers 1 to 5) and loop is opened with \"{\"\n  print(num + 2)             # The OPERATIONS (add two to each sequence number and print)\n}                            # The loop is closed with \"}\"                            ## [1] 3\n## [1] 4\n## [1] 5\n## [1] 6\n## [1] 7[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\nset.seed(1234)\n\n# a simple tibble\ndf <- tibble(\n  a =  rnorm(10),\n  b =  rnorm(10),\n  c =  rnorm(10),\n  d = rnorm(10)\n)\n\ndf\nmean(df$a)\n\nmean(df$b)\n\nmean(df$c)\n\nmean(df$d)## [1] -0.3831574\n## [1] -0.1181707\n## [1] -0.3879468\n## [1] -0.7661931\noutput <- vector(\"double\", ncol(df))  # 1. output having a predefined empty vector of the right size works best, here we choose to make the vector \"double\" specifying that it is empty and ready to receive number values, ncol(df) means that the vector will be as long as the number of columns in our tibble \noutput## [1] 0 0 0 0\nfor (i in seq_along(df)) {            # 2. sequence - determines what to loop over - here we are looping along df, rather than down the length of each vector\n  \n  output[[i]] <- mean(df[[i]])      # 3. body - each time the loop runs it allocates a value to output, \n}\noutput## [1] -0.3831574 -0.1181707 -0.3879468 -0.7661931"},{"path":"iteration.html","id":"activity-1-loop-exercise","chapter":"25 Iteration","heading":"25.3.1 Activity 1: Loop exercise","text":"made function converts values normal distribution z scores:Assuming column dataframe df comes different population. use loop apply function column independently?Hint copy df new object z_df z_df <- df destination tibble new z scores.","code":"\nz_score <- function(x) {\n  (x - min(x, na.rm = TRUE)) /  \n  diff(range(x, na.rm = TRUE))\n}\nz_df <- df\n\nfor (i in 1:ncol(df)) { # loop through each element\n  z_df[i] <- z_score(df[[i]]) #apply function and store in out[]\n}\nz_df"},{"path":"iteration.html","id":"apply","chapter":"25 Iteration","heading":"25.4 apply","text":"can perform exactly action apply - apply functions R allow iteration without use loop constructs. can used input list matrix.MARGIN = 1 means apply function rowsMARGIN = 2 means apply function columns","code":"\napply(df, MARGIN = 2,  z_score)##               a          b         c         d\n##  [1,] 0.3319492 0.15265375 0.7821670 1.0000000\n##  [2,] 0.7647291 0.00000000 0.4733256 0.5192783\n##  [3,] 1.0000000 0.06506096 0.4981101 0.4480343\n##  [4,] 0.0000000 0.31129943 0.9430704 0.5114592\n##  [5,] 0.8089534 0.57344857 0.3729606 0.1678518\n##  [6,] 0.8313814 0.26011813 0.0000000 0.3084450\n##  [7,] 0.5162933 0.14274906 1.0000000 0.0000000\n##  [8,] 0.5244878 0.02553760 0.2098653 0.2556247\n##  [9,] 0.5192926 0.04721860 0.7084006 0.5745131\n## [10,] 0.4243735 1.00000000 0.2532211 0.5222322\nis.matrix(apply(df, 2,  z_score))\n\nis.data.frame(apply(df, 2,  z_score))"},{"path":"iteration.html","id":"map","chapter":"25 Iteration","heading":"25.5 map","text":"map tidyverse equivalent apply work well %>% extended functions works better tibbles dataframesThe basic syntax map(.x = SEQUENCE, .f = FUNCTION, ARGUMENTS). bit detail:.x = inputs upon .f function iteratively applied - e.g. vector jurisdiction names, columns data frame, list data frames.x = inputs upon .f function iteratively applied - e.g. vector jurisdiction names, columns data frame, list data frames.f = function apply element .x input - function like print() already exists, custom function define. function often written tilde ~ (details ).\nnotes syntax:.f = function apply element .x input - function like print() already exists, custom function define. function often written tilde ~ (details ).\nnotes syntax:function needs arguments specified, can written parentheses tilde (e.g. .f = mean). provide arguments value iteration, provide within map() outside .f = argument, na.rm = T map(.x = my_list, .f = mean, na.rm=T).function needs arguments specified, can written parentheses tilde (e.g. .f = mean). provide arguments value iteration, provide within map() outside .f = argument, na.rm = T map(.x = my_list, .f = mean, na.rm=T).can use .x (simply .) within .f = function placeholder .x value iterationYou can use .x (simply .) within .f = function placeholder .x value iterationUse tilde syntax (~) greater control function - write function normal parentheses, : map(.x = my_list, .f = ~mean(., na.rm = T)). Use syntax particularly value argument change iteration, value .x .Use tilde syntax (~) greater control function - write function normal parentheses, : map(.x = my_list, .f = ~mean(., na.rm = T)). Use syntax particularly value argument change iteration, value .x .output usingmap() list - list object class like vector whose elements can different classes. , list produced map() contain many data frames, many vectors, many single values, even many lists! alternative versions map() explained produce types outputs (e.g. map_dfr() produce data frame, map_chr() produce character vectors, map_dbl() produce numeric vectors).Basic map() always return list, othr variants return different data types.Unlike apply map return one type data, removing potential changing data types occasionally happens using apply.Thre different ways applyig syntax map function","code":"\nmap_df(.x = df, \n       .f = z_score)\n\ndf %>% \n  map_df(z_score)\n\ndf %>% \n    map_df(~z_score(.))"},{"path":"iteration.html","id":"anonymous-functions-1","chapter":"25 Iteration","heading":"25.6 Anonymous functions","text":"previous chapter introduced anonymous functions, plan use function outside particular iteration example, might choose just write directly","code":"\nmap_df(.x = df, \n       .f = function(x) {\n  (x - min(x, na.rm = TRUE)) /  \n  diff(range(x, na.rm = TRUE))\n       }\n)"},{"path":"iteration.html","id":"exercise-for-for-loops","chapter":"25 Iteration","heading":"25.6.1 Exercise for For Loops","text":"part exercise real world example using simple () loops create graphs. data comes Living Planet Index, holds data various vertebrate species collected 1974 2014.First import data:take look using functions loops help us build figures.now four separate R objects holding data four bird species, standard approach might make four figures looking abundance time.want look four plots can use layout functions package patchwork.ok, arguably still requires lot code repetition. used lines code four times recreate four plots functionally . want make changes look plots make four separate edits & mistakes can easily creep .want apply loop, easiest thing first make objects R list:loop length list:now new object my_plots list containing four plots. loop allowed us code details figures , iterate across four different groups.want write loop save four plots - can modify script ?","code":"\nLPI_UK <- read_csv(\"data/LPI_data_loops.csv\")\n# Pick 4 species and make scatterplots with a simple regression model fits that show how the population has varied through time\n\n# Careful with the spelling of the names, it needs to match the names of the species in the LPI.UK dataframe\n\nhouse_sparrow <- filter(LPI_UK, Common.Name == \"House sparrow\")\ngreat_tit <- filter(LPI_UK, Common.Name == \"Great tit\")\ncorn_bunting <- filter(LPI_UK, Common.Name == \"Corn bunting\")\nmeadow_pipit <- filter(LPI_UK, Common.Name == \"Meadow pipit\")\nhouse_sparrow_scatter <- ggplot(house_sparrow, aes (x = year, y = abundance)) +\n    geom_point(size = 2, colour = \"#00868B\") +                                                \n    geom_smooth(method = lm, colour = \"#00868B\", fill = \"#00868B\") +          \n    theme_classic() +\n    labs(y = \"Abundance\\n\", x = \"\", title = \"House sparrow\")\n\ngreat_tit_scatter <- ggplot(great_tit, aes (x = year, y = abundance)) +\n    geom_point(size = 2, colour = \"#00868B\") +                                                \n    geom_smooth(method = lm, colour = \"#00868B\", fill = \"#00868B\") +          \n    theme_classic() +\n    labs(y = \"Abundance\\n\", x = \"\", title = \"Great tit\")\n\ncorn_bunting_scatter <- ggplot(corn_bunting, aes (x = year, y = abundance)) +\n    geom_point(size = 2, colour = \"#00868B\") +                                                \n    geom_smooth(method = lm, colour = \"#00868B\", fill = \"#00868B\") +          \n    theme_classic() +\n    labs(y = \"Abundance\\n\", x = \"\", title = \"Corn bunting\")\n\nmeadow_pipit_scatter <- ggplot(meadow_pipit, aes (x = year, y = abundance)) +\n    geom_point(size = 2, colour = \"#00868B\") +                                                \n    geom_smooth(method = lm, colour = \"#00868B\", fill = \"#00868B\") +          \n    theme_classic() +\n    labs(y = \"Abundance\\n\", x = \"\", title = \"Meadow pipit\")\n# put at the top of your script\nlibrary(patchwork)\n\nlayout <- \"AABB\n           CCDD\"\n\nhouse_sparrow_scatter+\n  great_tit_scatter+\n  corn_bunting_scatter+\n  meadow_pipit_scatter+\n  plot_layout(design=layout)\nSp_list <- list(house_sparrow, great_tit, corn_bunting, meadow_pipit)\nmy_plots <- list(length(Sp_list))\n\nfor (i in 1:length(Sp_list)) {                                    \n  # For every item along the length of Sp_list we want R to perform the following functions\n  data <- as.data.frame(Sp_list[i])                               \n  # Create a dataframe for each species\n  sp.name <- unique(data$Common.Name)                             \n  # Create an object that holds the species name, so that we can title each graph\n  plot <- ggplot(data, aes (x = year, y = abundance)) +               \n    # Make the plots and add our customised theme\n    geom_point(size = 2, colour = \"#00868B\") +                              \n    geom_smooth(method = lm, colour = \"#00868B\", fill = \"#00868B\") +        \n    theme_classic() +\n    labs(y = \"Abundance\\n\", x = \"\", title = sp.name)\n \n   # makes a list of all the plots generates\n  my_plots[[i]] <- plot \n  \n\n\n}\nwrap_plots(my_plots)+\n  plot_layout(design=layout) \n#wrap_plots function from patchwork can take a list of ggplots\nfor (i in 1:length(Sp_list)) {                                    \n  # For every item along the length of Sp_list we want R to perform the following functions\n  data <- as.data.frame(Sp_list[i])                               \n  # Create a dataframe for each species\n  sp.name <- unique(data$Common.Name)                             \n  # Create an object that holds the species name, so that we can title each graph\n  plot <- ggplot(data, aes (x = year, y = abundance)) +               \n    # Make the plots and add our customised theme\n    geom_point(size = 2, colour = \"#00868B\") +                                                \n    geom_smooth(method = lm, colour = \"#00868B\", fill = \"#00868B\") +          \n    theme_classic() +\n    labs(y = \"Abundance\\n\", x = \"\", title = sp.name)\n  \n    if(i %% 1==0){    # The %% operator is the remainder, this handy if line prints a number every time it completes a loop\n    print(i)\n    }\n# use paste to automatically add filename\n  ggsave(plot, file=paste(\"figure/\", sp.name, \".png\", sep=''), dpi=900) \n}"},{"path":"iteration.html","id":"automating-analyses-with-map","chapter":"25 Iteration","heading":"25.7 Automating analyses with map","text":"","code":""},{"path":"iteration.html","id":"writing-a-dataframe-into-multiple-csv-files","chapter":"25 Iteration","heading":"25.7.1 Writing a dataframe into multiple csv files","text":"’ll also use purrr::map() take character values Class column assigning names list. map() transforms input applying function element input, returns vector length input. immediate example, input list_of_dfs apply function dplyr::pull() extract Class variable data frame. repeat approach convert Class character type .character() take single value unique():Exporting list data frames multiple CSV files take lines code, relatively straightforward. three main steps:Define function tells R names CSV file , ’ve called output_csv() . data argument take data frame whilst names argument take character string form part file name individual CSV file.Define function tells R names CSV file , ’ve called output_csv() . data argument take data frame whilst names argument take character string form part file name individual CSV file.Create named list names match arguments function ’ve just defined (data names), contain objects like pass function respective arguments. case, list_of_dfs provide three data frames, names(list_of_dfs) provide names three data frames. necessary running pmap(), view basically super-powered version map() lets iterate multiple inputs simultaneously.Create named list names match arguments function ’ve just defined (data names), contain objects like pass function respective arguments. case, list_of_dfs provide three data frames, names(list_of_dfs) provide names three data frames. necessary running pmap(), view basically super-powered version map() lets iterate multiple inputs simultaneously.map() iterate two sets inputs output_csv() (inputs used arguments), writes three CSV files file names want. “writing” function, either use write_csv() readr (part tidyverse) fwrite() data.table, depending workflow / style.map() iterate two sets inputs output_csv() (inputs used arguments), writes three CSV files file names want. “writing” function, either use write_csv() readr (part tidyverse) fwrite() data.table, depending workflow / style.","code":"\nLPI_list <- LPI %>% \n  group_split(Class)\n [1] \"Actinopterygii\"            \"Amphibia\"                  \"Aves\"                      \"Cephalaspidomorphi\"       \n [5] \"Cetacea\"                   \"Chondrichthyes\"            \"Elasmobranchii\"            \"Holocephali\"              \n [9] \"Mammalia\"                  \"Myxini\"                    \"Perciformes\"               \"Reptilia\"                 \n[13] \"Sarcopterygii\"             \"Testudinidae\"              \"updated by Nancy - Feb/02\"\n\nLPI_list %>% \n  map(~write_csv(.x, \n  paste0(\"data/\", .x$Class[1], \".csv\")))"},{"path":"iteration.html","id":"reading-multiple-csv-files-into-one-object","chapter":"25 Iteration","heading":"25.7.2 Reading multiple csv files into one object","text":"method reading CSV files directory slightly different, ’ll need find way identify create character vector names files want load R. , ’ll use list.files(), produces character vector names files directories named directory:code takes list files, pipes map_df() function runs read_csv file, outputs everything 'nested' dataframe.","code":"\ndata_path <- \"data/\"\n\nlist.files(path = data_path, \n           pattern = \"*.csv\") [1] \"class-Actinopterygii.csv\"     \"class-Amphibia.csv\"           \"class-Aves.csv\"               \"class-Cephalaspidomorphi.csv\"\n [5] \"class-Cetacea.csv\"            \"class-Chondrichthyes.csv\"     \"class-Elasmobranchii.csv\"     \"class-Holocephali.csv\"       \n [9] \"class-Mammalia.csv\"           \"class-Myxini.csv\"             \"class-Perciformes.csv\"        \"class-Reptilia.csv\"          \n[13] \"class-Sarcopterygii.csv\"      \"class-Testudinidae.csv\"\n\ndata <- files %>%\n    map(~read_csv(.)) %>%    # read in all the files individually, using\n    # the function read_csv() from the readr package\n    reduce(rbind)        # reduce with rbind into one dataframe\ndata\n# Keep info on where data came from\n\ndata <- tibble(filename = files) %>% \n  mutate(file_contents = \n           map(filename, \n               ~ read_csv(file.path(data_path, .))))\n\ndata\nunnest(data)"},{"path":"iteration.html","id":"plotting-with-map","chapter":"25 Iteration","heading":"25.7.3 Plotting with map","text":"","code":"\nLPI_UK %>% \n    filter(Common.Name == \"House sparrow\" | \n               Common.Name == \"Great tit\" | \n               Common.Name == \"Corn bunting\" | \n               Common.Name == \"Meadow pipit\" ) %>% \n    group_by(Common.Name) %>% \n    nest() %>% \n    mutate(plots = map(data, ~ ggplot(., aes (x = year, y = abundance)) +              \n            geom_point(size = 2, colour = \"#00868B\") +                                                \n            geom_smooth(method = lm, colour = \"#00868B\", fill = \"#00868B\") +          \n            labs(y = \"Abundance\\n\", x = \"\")))"},{"path":"iteration.html","id":"activity-4-test-yourself","chapter":"25 Iteration","heading":"25.8 Activity 4: Test yourself","text":"Question 1. Predict output following executed R:4, 5, 101, 5, 94, 8, 12Question 2. Predict output following executed R:5, 6, 73, 4, 5, 6, 73, 4Question 3. Write function adds two numbers divides results 2.Question 4. Recode values datase. example, survey age data, may want convert crazy values (like anything 0 100) NA. Write function called recode.integer() 3 arguments: x, lb, ub. ’ll assume x numeric vector. function look values x, convert values lb ub NA, return resulting vector. function action:hints: multiple ways solve .","code":"\nfoo=function(d,n,max){\n   nums=seq(from=1, by=d, length.out=n)\n   return(nums[nums <= max])\n}\nfoo(4,5,10)\nfum=function(a,b) {\n  a = a[a<b]\n  return(a)\n}\n\nfum(3:7,(1:5)^2)\naddtwo <- function(num1, num2){\n(num1 + num2)/2\n}\nvector <- c(-5:30)\nrecode.integer(x = vector,\n               lb = 0,\n               ub = 10)\nrecode.integer <- function(x, lb, ub){\n  x[x<lb] <- NA\n  x[x>ub] <- NA\n  return(x)\n}\nrecode.integer <- function(x, lb, ub){\n    x <- x %>% as_tibble() %>% \n      mutate(value = replace(value, value<lb, NA)) %>% \n      mutate(value = replace(value, value>ub, NA))\nreturn(x)}\n\nrecode.numeric <- function(x, lb, ub){\nx <- if_else(x < lb, NA_integer_, x)\nx <- if_else(x > ub, NA_integer_, x)\nreturn(x)\n}"},{"path":"iteration.html","id":"activity-5","chapter":"25 Iteration","heading":"25.9 Activity 5","text":"hungry map() check blogpost","code":""},{"path":"iteration.html","id":"summary-10","chapter":"25 Iteration","heading":"25.10 Summary","text":"Making functions iterations advanced R skills, can often seem daunting. expect implement course, want give insight core programming skills might interested want develop.links may find usefulRStudio education cheat sheet purrRStudio education cheat sheet purrR4DS - intro programmingR4DS - intro programmingEpiR handbookEpiR handbook","code":""},{"path":"installing-r.html","id":"installing-r","chapter":"A Installing R","heading":"A Installing R","text":"","code":""},{"path":"installing-r.html","id":"why-should-i-install-r-on-my-computer","chapter":"A Installing R","heading":"A.1 Why should I install R on my computer?","text":"R StudioCloud cuts lot installation problems means packages functions need already installed. However, requires internet connection use.Eventually continue R Data Science journey probably want R RStudio computer.great detailed walkthrough videos Danielle Narvarro YouTube re: install R Windows Mac.","code":""},{"path":"installing-r.html","id":"windows","chapter":"A Installing R","heading":"A.2 Windows","text":"using Windows, download install following:RR StudioRToolsOnce installed three programs, restart computer. , open RStudio (R) run code:install tidyverse package computer. problems installing R, please book GTA session able help installation problems.","code":"\ninstall.packages(\"tidyverse\")"},{"path":"installing-r.html","id":"mac","chapter":"A Installing R","heading":"A.3 Mac","text":"using Mac, download install following:RR StudioXQuartzIf issues installing R Mac, first, recommend watch walkthrough Danielle Navarro.issues Mac, may find video helpful walkthrough video. Additionally, using Mac Catalina OS, also recommend read troubleshooting guideOnce installed three programs, restart computer. , open RStudio (R) run code:install tidyverse package computer. problems installing R, please book GTA session able help installation problems.","code":"\ninstall.packages(\"tidyverse\")"},{"path":"installing-r.html","id":"chromebooks","chapter":"A Installing R","heading":"A.4 Chromebooks","text":"Please note currently install R Chromebook, please use R StudioCloud.\n## RStudio SettingsThere settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. Foe example, Lisa prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"using-rstudio-on-your-computer","chapter":"A Installing R","heading":"A.5 Using RStudio on your computer","text":"Functionally difference using RStudio computer, just mindful setting projects, files located computer. top tips:Set folder Documents folder R projects. Within folder make sure unique analysis project subfolder.","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"A Installing R","heading":"A.6 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2021b) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"updating-r-rstudio-and-packages.html","id":"updating-r-rstudio-and-packages","chapter":"B Updating R, RStudio, and packages","heading":"B Updating R, RStudio, and packages","text":"time--time, updated version R, RStudio, packages use (e.g., ggplot) become available. Remember separate, different process come different considerations. recommend updating latest version three start academic year.","code":""},{"path":"updating-r-rstudio-and-packages.html","id":"updating-rstudio","chapter":"B Updating R, RStudio, and packages","heading":"B.1 Updating RStudio","text":"RStudio easiest component update. Typically, updates RStudio affect code, instead add new features, like spell-check upgrades RStudio can . usually little downside updating RStudio easy .Click Help - Check updates\nFigure B.1: Updating RStudio\nupdate available, prompt download can install usual.","code":""},{"path":"updating-r-rstudio-and-packages.html","id":"updating-packages","chapter":"B Updating R, RStudio, and packages","heading":"B.2 Updating packages","text":"Package developers occasionally release updates packages. typically add new functions package, fix amend existing functions. aware package updates may cause previous code stop working. tend happen minor updates packages, occasionally major updates, can serious issues developer made fundamental changes code works. reason, recommend updating packages beginning academic year (semester) - assessment deadline just case!update individual package, easiest way use install.packages() function, always installs recent version package.update multiple packages, indeed packages, RStudio provides helpful tools. Click Tools - Check Package Updates. dialogue box appear can select packages wish update. aware select packages, may take time unable use R whilst process completes.\nFigure B.2: Updating packages RStudio\nOccasionally, might problem packages seemingly refuse update, , rlang vctrs cause end trouble. packages likely every explicitly load, required beneath surface R things like knit Markdown files etc.try update package get error message says something like Warning install.packages : installation package ‘vctrs’ non-zero exit status perhaps Error loadNamespace(, c(lib.loc, .libPaths()), versionCheck = vI[[]]) :  namespace 'rlang' 0.4.9 loaded, >= 0.4.10 required one solution found manually uninstall package, restart R, install package new, rather trying update existing version. installr package also useful function uninstalling packages.","code":"\ninstall.packages(\"tidyverse\")\n# Load installr\nlibrary(installr)\n\n# Uninstall the problem package\nuninstall.packages(\"package_name\")\n\n# Then restart R using session - restart R\n# Then install the package fresh\n\ninstall.packages(\"package\")"},{"path":"updating-r-rstudio-and-packages.html","id":"updating-r","chapter":"B Updating R, RStudio, and packages","heading":"B.3 Updating R","text":"Finally, may also wish update R . key thing aware update R, just download latest version website, lose packages. easiest way update R cause huge headache use installr package. use updateR() function, series dialogue boxes appear. fairly self-explanatory full step--step guide available use installr, important bit select \"Yes\" asked like copy packages older version R.always, issues, please ask.","code":"\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Load installr\nlibrary(installr)\n\n# Run the update function\nupdateR()"},{"path":"exporting-files-from-the-server.html","id":"exporting-files-from-the-server","chapter":"C Exporting files from the server","heading":"C Exporting files from the server","text":"using RStudio Cloud, may need export files share people submit assignments.First, make sure saved changes made file. clicking \"File - Save\", Ctrl + S, clicking save icon. changes saved, save icon greyed . new unsaved changes, able click icon.Select file download files pane (bottom right) ticking box next , click \"- Export\" save file computer.R installed, try open .R files computer. , open Word, Endnote similar, may corrupt code. open file R R Studio installed.want double check file definitely right one submit assignment, can re-upload server open make sure answers .","code":""},{"path":"symbols.html","id":"symbols","chapter":"D Symbols","heading":"D Symbols","text":"\nFigure D.1: Image James Chapman/Soundimals\n","code":""},{"path":"baser.html","id":"baser","chapter":"E Base R vs. Tidyverse","heading":"E Base R vs. Tidyverse","text":"worked primarily tidyverse tools course. many advantages tidyverse tools data wrangling simplicity human readability, actually nothing tidyverse similarly achieved baseR commands. interested comparing contrasting check examples .use iris dataset, dataset comes baseR (just type iris).","code":"\nlibrary(tidyverse)"},{"path":"baser.html","id":"extract-variables","chapter":"E Base R vs. Tidyverse","heading":"E.1 Extract variables","text":"","code":"\niris$Sepal.Length # single variable\niris[, c(\"Species\", \"Petal.Width\")] # by name\niris[, c(5, 4)]  # by column index\nselect(iris, Species)\nselect(iris, Species, Petal.Width) # by name\nselect(iris, 5, 4)  # by column index"},{"path":"baser.html","id":"make-new-variables","chapter":"E Base R vs. Tidyverse","heading":"E.2 Make new variables","text":"Extract observations (rows)","code":"\niris$Petal.Ratio <- iris$Petal.Length/iris$Petal.Width\n\niris$Sepal.Ratio <- iris$Sepal.Length/iris$Sepal.Width\nmutate(iris, \n       Petal.Ratio = Petal.Length/Petal.Width,\n       Sepal.Ratio = Sepal.Length/Sepal.Width)\n# Using [,]\niris[iris$Petal.Width > 0.5 & iris$Species == \"setosa\", ]\n\n# Using subset (works very much like dplyr::filter)\nsubset(iris, Petal.Width > 0.5 & Species == \"setosa\")\nfilter(iris, Petal.Width > 0.5 & Species == \"setosa\")"},{"path":"baser.html","id":"arrange-observations-rows","chapter":"E Base R vs. Tidyverse","heading":"E.3 Arrange observations (rows)","text":"","code":"\n# descending order of species (alphabetic) followed by ascending order of Petal.Width\niris[order(rev(iris$Species), iris$Petal.Width) , ]\n# descending order of species (alphabetic) followed by ascending order of Petal.Width\narrange(iris, desc(Species), Petal.Width) "},{"path":"baser.html","id":"summarise-observations-rows","chapter":"E Base R vs. Tidyverse","heading":"E.4 Summarise observations (rows)","text":"","code":"\n# Manually create a data.frame\ndata.frame(Petal.Length.mean = mean(iris$Petal.Length),\n           Petal.Length.sd = sd(iris$Petal.Length),\n           Sepal.Length.mean = mean(iris$Sepal.Length),\n           Sepal.Length.sd = sd(iris$Sepal.Length))\nsummarise(iris, \n          Petal.Length.mean = mean(Petal.Length),\n          Petal.Length.sd = sd(Petal.Length),\n          Sepal.Length.mean = mean(Sepal.Length),\n          Sepal.Length.sd = sd(Sepal.Length))"},{"path":"baser.html","id":"grouped-operations","chapter":"E Base R vs. Tidyverse","heading":"E.5 Grouped operations","text":"","code":"\n# First operate in the data.frame by group (split-apply)\nmtcars_by <- by(mtcars, \n   INDICES = list(mtcars$cyl, mtcars$gear),\n   FUN = function(x){\n     data.frame(cyl = unique(x$cyl),\n                gear = unique(x$gear),\n                mpg.mean = mean(x$mpg),\n                mpg.sd = sd(x$mpg),\n                wt.mean = mean(x$wt),\n                wt.sd = sd(x$wt))\n   })\n\n# Then combine the results into a data.frame\ndo.call(rbind, mtcars_by)\nmtcars %>% \n  group_by(cyl, gear) %>% \n  summarise(mpg.mean = mean(mpg),\n            mpg.sd = sd(mpg),\n            wt.mean = mean(wt),\n            wt.sd = sd(wt)) %>% \n  ungroup() # remove any groupings from downstream analysis"},{"path":"baser.html","id":"create-new-columns-as-calculations","chapter":"E Base R vs. Tidyverse","heading":"E.6 Create new columns as calculations","text":"","code":"\n# First operate in the data.frame by group (split-apply)\niris_by <- by(iris, \n              INDICES = iris$Species, \n              FUN = function(x){\n                x$Petal.Width.centered <- x$Petal.Width - mean(x$Petal.Width)\n                return(x)\n              })\n\n# Then combine the results into a data.frame\ndo.call(rbind, iris_by)\niris %>% \n  group_by(Species) %>% \n  mutate(Petal.Width.centered = Petal.Width - mean(Petal.Width)) %>% \n  ungroup() # remove any groupings from downstream analysis"},{"path":"baser.html","id":"filter-rows-with-conditions-evaluated-by-group","chapter":"E Base R vs. Tidyverse","heading":"E.7 Filter rows with conditions evaluated by group","text":"","code":"\n# First operate in the data.frame by group (split-apply)\nwidest_petals <- by(iris, \n                    INDICES = iris$Species, \n                    FUN = function(x){\n                      x[x$Petal.Width == max(x$Petal.Width), ] \n                    })\n\n# Then combine the results into a data.frame\ndo.call(rbind, widest_petals)\niris %>% \n  group_by(Species) %>% \n  filter(Petal.Width == max(Petal.Width))"},{"path":"baser.html","id":"pivot-data","chapter":"E Base R vs. Tidyverse","heading":"E.8 Pivot data","text":"","code":"\nreshape(iris, \n        varying = c(\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"),\n        timevar = \"trait\",\n        idvar = \"id\",\n        v.names = \"measurement\",\n        direction = \"long\")\niris %>% \n pivot_longer(cols = Sepal.Length:Petal.Width, values_to = \"measurement\", names_to = \"trait\" )"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit, provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
